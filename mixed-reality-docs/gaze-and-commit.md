---
title: Head 注視とコミット
description: Head 注視し、コミットの入力モデルの概要
author: caseymeekhof
ms.author: cmeekhof
ms.date: 03/31/2019
ms.topic: article
ms.localizationpriority: high
keywords: 複合現実、視線の先を対象とする操作、視線の先をデザインします。
ms.openlocfilehash: a84465de3479bf3da2131b94dd522539cd7de6e9
ms.sourcegitcommit: c20563b8195c0c374a927b96708d958b127ffc8f
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 05/21/2019
ms.locfileid: "65974876"
---
# <a name="head-gaze-and-commit"></a>Head 注視とコミット
Head 注視し、コミットが転送ポイント、head、(ヘッド-方向) の方向を持つオブジェクトを対象とする場合、入力モデルとなどを入力し、セカンダリに操作しているエア タップ手のジェスチャと音声コマンドの"Select"です。 間接的な操作、つまり到達腕以外ではコンテンツと対話するための使用に適して使用してモデルを「まで」の入力と見なされます。

## <a name="device-support"></a>デバイスのサポート

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><strong>入力モデル</strong></td>
        <td><a href="hololens-hardware-details.md"><strong>HoloLens (第 1 世代)</strong></a></td>
        <td><strong>HoloLens 2</strong></td>
        <td><a href="immersive-headset-hardware-details.md"><strong>イマーシブ ヘッドセット</strong></a></td>
    </tr>
     <tr>
        <td>Head 注視とコミット</td>
        <td>推奨 ✔️</td>
        <td>✔️ お勧めします (3 番目の選択 -<a href="interaction-fundamentals.md">他のオプションを参照してください</a>)。</td>
        <td>➕ 代替オプション</td>
    </tr>
</table>

## <a name="head-gaze"></a>Head 視線入力
Mixed reality ヘッドセットでは、位置とユーザーの頭の向きを使用して、そのヘッド方向ベクトルを決定します。 このユーザーの目の間で直接からまっすぐ指すレーザーと考えることができます。 これは非常に粗い近似のユーザーが検索されます。 アプリケーションは、仮想または実際のオブジェクトをこの射線が交差して、ユーザーに知らせると、現在対象にするには、その場所にカーソルを描画します。

ヘッドの視線入力だけでなく、HoloLens 2 のようないくつかの複合現実ヘッドセットには、視線目視線入力ベクトルを生成するシステムにはが含まれます。 これは、ユーザーが検索しているにきめ細かい測定値を提供します。 視線の先を作成し、目視線の先を使用して相互作用をコミットすることはできますが、これは、非常にさまざまなデザインの制約で個別に説明する一連の[視線記事](eye-tracking.md)します。

## <a name="commit"></a>コミット
オブジェクトまたは UI 要素を対象とした後は、ユーザーは対話するか、セカンダリ入力を使用するのには、「クリックして」。 これは、モデルのコミットの手順と呼ばれます。 次のコミット方法がサポートされています。

- エア タップのジェスチャ
- 音声コマンドの"Select"、または対象となる音声コマンドのいずれかを読み上げる
- 1 つのボタンを押して、 [HoloLens Clicker](hardware-accessories.md#hololens-clicker)
- Xbox ゲームパッドの 'A' ボタンを押します
- Xbox アダプティブ コント ローラーの 'A' ボタンを押します

### <a name="head-gaze-and-air-tap-gesture"></a>Head 注視しエア タップ ジェスチャ
エア タップは、垂直に保持して手のアイコンをタップするジェスチャです。 エア タップを実行するには、準備完了の位置に、人差し指を発生させるし、親指ピンチ、バックアップを解放する際、人差し指を発生させます。 HoloLens 1 では、エア タップは、最も一般的なセカンダリ入力です。

![準備が位置し、タップまたはクリック モーション指](images/readyandpress.jpg)<br>

エア タップも HoloLens 2 では、使用し、元のバージョンで緩和されました。 Pinches のほぼすべての型はサポートされています、手が垂直化も。 これにより、ユーザーについて説明し、ジェスチャを実行するため、はるかに簡単です。  この新しいエア タップでは、既存のアプリケーションは HoloLens 2 の再コンパイルした後、新しい動作を自動的に取得されますので、同じ API を使って古いものが置き換えられます。

### <a name="head-gaze-and-select-voice-command"></a>Head 注視し、"Select"音声指示コマンド
音声コマンドを実行すると、複合現実での主要な対話方法の 1 つです。 システムを制御する場合は、非常に強力な「自在」メカニズムを提供します。 音声の相互作用モデルの異なる種類があります。

- 「クリック」作動またはセカンダリの入力としてコミットを実行する"Select"を汎用のコマンドを使用します。
- 実行して、セカンダリ入力としてアクションへのコミットを許可する「閉じる」か"より大きな"などのオブジェクト コマンド。
- ターゲットを必要としない「最初に移動」のようなグローバル commnads します。
- メッセージ交換のユーザー インターフェイスまたはエンティティ、AI 自然言語の機能を搭載する Cortana のようにします。
- カスタム commnads

詳細と使用可能なコマンドと使用方法の comprenhesive 一覧を検索するには、チェック アウト、[音声コマンド実行](voice-design.md)ガイダンス。


### <a name="head-gaze-and-hololens-clicker"></a>Head 注視し、HoloLens Clicker
HoloLens Clicker HoloLens 専用に構築された最初の周辺機器は、HoloLens の 1 Development Edition に含まれています。 HoloLens Clicker を最小限の手の動きをクリックし、セカンダリ入力としてコミットできます。 HoloLens clicker は、HoloLens 1 または 2 の Bluetooth 低エネルギー (BTLE) を使用してに接続します。

![](images/hololens-clicker-500px.jpg)<br>
HoloLens Clicker

詳細情報と、デバイスをペアリングする手順を参照して[ここ](hardware-accessories.md#pairing-bluetooth-accessories)




### <a name="head-gaze-and-xbox-wireless-controller"></a>Head 注視と Xbox のワイヤレス コント ローラー
Xbox のワイヤレス コント ローラーは、A ボタンを使用して入力セカンダリとして"click"作動を実行できます。 デバイスは、移動に役立つ操作および制御する、システムの既定のセットにマップされます。 コント ローラーをカスタマイズする場合は、アクセサリの Xbox アプリを使用して、Xbox のワイヤレス コント ローラーを構成します。

![](images/xboxcontroller.jpg)<br>
Xbox のワイヤレス コント ローラー

[お使いの PC と Xbox コント ローラーのペアリング](hardware-accessories.md#pairing-bluetooth-accessories)


### <a name="head-gaze-and-xbox-adaptive-controller"></a>Head 視線入力、および Xbox のアダプティブ コント ローラー
主に、モビリティを限られたプレイヤーがゲームのニーズを満たすように設計、Xbox アダプティブ コント ローラーは、Mixed Reality をよりアクセスできるようにする統合されたハブのデバイスです。

アダプティブ Xbox コント ローラーは、A ボタンを使用して入力セカンダリとして"click"作動を実行できます。 デバイスは、移動に役立つ操作および制御する、システムの既定のセットにマップされます。 コント ローラーをカスタマイズする場合は、アクセサリの Xbox アプリを使用して、Xbox アダプティブ コント ローラーを構成します。

![](images/xbox-adaptive-controller-devices.jpg)<br>
Xbox アダプティブ コント ローラー

スイッチ、ボタン、マウント、ジョイスティックは自分で一意にするカスタム コント ローラーのエクスペリエンスを作成するなどの外部のデバイスを接続します。 3.5 mm ジャック、および USB ポート経由で接続して補助デバイスでは、ボタン、スティックおよびトリガーの入力が制御されます。

![](images/xbox-adaptive-controller-ports.jpg)<br>
Xbox アダプティブ コント ローラーのポート

[手順については、デバイスをペアリングするには](hardware-accessories.md#pairing-bluetooth-accessories)

<a href=https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller>詳細については使用可能な Xbox サイト</a>


# <a name="head-gaze-design-guidelines"></a>Head 注視デザイン ガイドライン
> [!NOTE]
> 視線の設計に固有のガイダンスについて[近日](index.md)します。

## <a name="head-gaze-targeting"></a>ヘッド-視線の先の対象とします。
すべての対話は、ユーザーの入力モードに関係なく、対話する要素を対象とする機能に基づいて構築します。 Windows Mixed Reality でこれは、一般に、ユーザーの視線の先を使用します。
エクスペリエンスを正常に使用するユーザーを有効にするには、ユーザーの目的、およびユーザーの実際のインテントのシステムの計算については、できる限り忠実に従う必要があります。 程度にシステムがユーザーの意図した操作を解釈する正しく、満足度が増えるとパフォーマンスが向上します。


## <a name="target-sizing-and-feedback"></a>ターゲットのサイズ変更とフィードバック
視線入力ベクトルは正しく対象とするために使用するのには繰り返し示されていますが、gross ターゲット (取得若干大きくターゲット) に最も適した多くの場合。 1.5 に 1 度の最小のターゲットのサイズは、3 度のターゲットが多くの場合より高速化を使用する場合、ほとんどのシナリオで成功したユーザーの操作を許可する必要があります。 注いる対象ユーザーは 3D 要素の場合でも 2D 領域では効果的にサイズどのプロジェクションが直面する、ターゲット設定可能な領域があります。 要素が「アクティブ」(こと、ユーザーが対象にすること) があるいくつかの注目すべきキューが非常に役立つ - これを含めることができますを提供する処理などの表示「ホバー」効果やオーディオのハイライト、 をクリックまたは要素を使用してカーソルの配置をオフにします。

![2 つのメーター距離にある最適なターゲット サイズ](images/gazetargeting-size-1000px.jpg)<br>
*2 つのメーター距離にある最適なターゲット サイズ*

![視線の先の対象となるオブジェクトを強調表示の例](images/gazetargeting-highlighting-640px.jpg)<br>
*視線の先の対象となるオブジェクトを強調表示の例*

## <a name="target-placement"></a>ターゲットの配置
ユーザーは、多くの場合、(通常は約監視レベル) にフォーカスがメインの周囲の領域で、注意のほとんどに重点を置いて、視野で非常に高または非常に低配置されている UI 要素を検索する失敗します。 目のレベルによって適切なバンドでほとんどのターゲットを配置することができます。 ユーザーの傾向を与え、比較的小さな視覚的な領域 (ビジョンの attentional コーンは 10 度では約) いつでも、概念的に関連している度合いをまとめて UI 要素をグループに重点を活用できますから注意順行連鎖の動作項目のユーザーとして領域を通じて、視線の先に移動します。 UI を設計するときは、HoloLens、イマーシブ ヘッドセットとビューのフィールドに潜在的な大規模なバリエーションに注意してください。

![Galaxy エクスプ ローラーで対象とする簡単視線の先のグループ化された UI 要素の例](images/gazetargeting-grouping-1000px.jpg)<br>
*Galaxy エクスプ ローラーで対象とする簡単視線の先のグループ化された UI 要素の例*

## <a name="improving-targeting-behaviors"></a>ターゲットの動作の向上
何かを対象とするユーザーの意図を確認 (または密接に近似)、「ニアミス」が正しくを対象としていた場合と同様の対話に試行を受け入れるように非常に便利ですができます。 複合現実エクスペリエンスに組み込むことが成功したメソッドのいくつかあります。

### <a name="head-gaze-stabilization-gravity-wells"></a>Head 注視安定化 ("重力 wells")
これが有効にする時間のほとんどまたはすべて。 この手法は、自然な head/ネック ジッター可能性のあるユーザーを削除します。 検索読み上げの動作が原因も移動します。

### <a name="closest-link-algorithms"></a>最も近いリンク アルゴリズム
これらは、スパースの対話型コンテンツ領域に最適な機能します。 対話する試行がユーザーを決定することができます可能性が高い場合は、単に一定レベルのインテントを想定して、ターゲットの能力を補うことができます。

### <a name="backdatingpostdating-actions"></a>Backdating 遅延アクション
このメカニズムは、速度が必要なタスクに役立ちます。 ユーザーは、一連の対象とする、アクティブ化の最適経路の速度で移動する場合に役に立ちますいくつかの目的を想定し、ユーザーがいたフォーカスで若干の前後に若干 (50 ミリ秒の前に、/後が有効であったでタップのターゲットに対して操作を実行する手順を実行されなかったを許可します。初期のテスト)。

### <a name="smoothing"></a>スムージング
このメカニズムは、パスの移動、ヘッドの移動を自然な特性のため若干のジッター/補助の削減に役立ちます。 パスのモーション、時間の経過と共にではなく、動きの距離のサイズでスムーズに円滑化するとき

### <a name="magnetism"></a>磁力
このメカニズムはターゲットに向かって、カーソルを描画するか、単に (視覚的またはない) かどうかに hitboxes を増やす「リンクでは最も近い」アルゴリズムの一般的なバージョンとして考えることができます可能性の高い目標を実現するユーザーに、使用する対話型のレイアウトの知識優れたアプローチ ユーザーのものです。 これは、小規模のターゲットの非常に強力なことができます。

### <a name="focus-stickiness"></a>フォーカスの持続性
フォーカスを移す対話型の要素の近くに判断する、現在フォーカスが要素に、バイアスを提供します。 これは自然なノイズを含む 2 つの要素間の中間に浮動小数点の動作の切り替えが不規則のフォーカスの削減に役立ちます。


## <a name="composite-gestures"></a>複合のジェスチャ
アプリでは、複数の個々 のタップを認識できます。 結合をタップして保持して、リリース、手の動きより複雑な複合ジェスチャを実行できます。 これらの複合または高レベルのジェスチャは、低レベル空間からの入力データ (エア タップと Bloom) 開発者がアクセスできるに作成します。

### <a name="air-tap"></a>エア タップ
エア タップのジェスチャ (およびその他のジェスチャは以下) は、特定のタップにのみ対応します。 メニューや把握などの他のタップを検出するために、アプリは、上記 2 つの重要なコンポーネントのジェスチャのセクションで説明されている下位レベルの相互作用を直接使用する必要があります。

### <a name="tap-and-hold"></a>タップ アンド ホールド
保留中のエア タップの下向きの指の位置だけ維持です。 エア タップ アンド ホールドの組み合わせは、さまざまなより複雑な「クリックしてドラッグ」の対話など、アクティブ化することではなくオブジェクトのピックアップ arm 移動と組み合わせたときに、またはコンテキスト メニューを表示するなどの"mousedown"セカンダリ対話できます。
任意拡張のジェスチャの実行中に、手の形の姿勢を緩和しやすいユーザーとしてただし、このジェスチャの設計にできる場合に、注意を使用してください。

### <a name="manipulation"></a>操作
移動、サイズを変更する場合、1:1 ユーザーの手の動きに反応するホログラム ホログラムを回転操作のジェスチャを使用できます。 このような 1 対 1 の動きの 1 つの用途は、描画またはペイントの世界では、ユーザーにです。
操作のジェスチャの初期ターゲットは、視線入力または参照によって行う必要があります。 タップ アンド ホールドの開始、オブジェクトのすべての操作が、処理を手動で移動すると、操作中にユーザーを解放します。

### <a name="navigation"></a>ナビゲーション
ナビゲーションのジェスチャでは、仮想ジョイスティックのように動作し、放射状メニューなどの UI ウィジェットを移動に使用できます。 タップし、ジェスチャが開始され、手を中心に最初のキーを押して、正規化された 3D キューブ内に保持します。 0 の開始点の 1 に、値-1 から X、Y、Z 軸に沿った手を移動できます。
ナビゲーションは、velocity ベースの継続的なスクロールまたはズーム ジェスチャ、マウスの中央ボタンをクリックし、マウスを上下に移動して 2D の UI をスクロールすると同様の作成に使用できます。

レールを使用したナビゲーションは、その軸で特定のしきい値に達するまでは、特定の軸での動きを認識する機能を指します。 1 つ以上の軸での移動が有効な場合、アプリケーションで、開発者など、便利ですが、これはのみ、アプリケーションが X、Y 軸の間でナビゲーション ジェスチャを認識するように構成が指定されても場合 rails 軸 X。 ここでシステムが認識手の動きで X 軸の X 軸の rails (ガイド) が虚数部内にある限り、手の形の移動には、Y 軸もが発生した場合。

2D のアプリ内でユーザーは、スクロール、ズーム、またはアプリ内でドラッグ縦型ナビゲーション ジェスチャを使用できます。 これは、同じ種類のタッチ ジェスチャをシミュレートするためにアプリを仮想指タッチを挿入します。 ユーザーは、ボタンを選択するか、'< スクロール/ドラッグ/ズーム > Tool' を言ってのいずれかのアプリ上にあるバー上のツール間で切り替えることで行われますがこれらのアクションを選択できます。

[詳細については、複合のジェスチャ](gestures.md#composite-gestures)

## <a name="gesture-recognizers"></a>ジェスチャ レコグナイザー

ジェスチャ認識を使用して 1 つの利点は、現在のターゲット ホログラムが受け入れることができるジェスチャのジェスチャ認識エンジンを構成することができます。 プラットフォームでは、これらの特定のサポートされているジェスチャを区別するために必要な曖昧のみを行います。 そうすることだけエア タップをサポートするホログラムは任意の長さのキーを押してからリリースまでの時間を受け入れることができます、ホログラム中をサポートしています をタップし、の両方を保持できます後を昇格させる保留をタップして、ホールド時間のしきい値。

## <a name="hand-recognition"></a>手の形の認識
HoloLens では、デバイスに表示されているいずれかまたは両方のハンドの位置を追跡して手のジェスチャを認識します。 HoloLens では、(背面人差し指をに向けてして手のアイコン) の準備完了状態または押された状態 (背面インデックス指でに向けてして手のアイコン) のいずれかにいるときに手が表示されます。 手が他が発生する場合、それら、HoloLens は無視されます。
各ハンドの HoloLens を検出すると、(向き) なしの位置と、押された状態にアクセスすることができます。 して手のアイコンは、ジェスチャのフレームの端に近いが再び HoloLens が表示できる場所を取得するには、その手を移動する方法を把握できるように、ユーザーに表示できる方向ベクトルも与えられます。

## <a name="gesture-frame"></a>ジェスチャ フレーム
HoloLens のジェスチャは、フレーム内で"ジェスチャ"、(非常に大まかにウェストと肩の間での鼻) からジェスチャ検知カメラが適切に参照できる範囲内でして手のアイコン必要があります。 ユーザーは、認識操作の成功と独自の快適性の両方が (多くのユーザーが最初と仮定ジェスチャ フレームが HoloLens、これにより、ビュー内であるし、対話するには多く自分の腕を保持する必要があります) のこの領域でトレーニングを受ける必要があります。 HoloLens Clicker を使用する場合は、手をジェスチャ フレーム内である必要はありません。

継続的なジェスチャの場合具体的がユーザーの中には、(中に何らかの holographic オブジェクトを移動するなど) の中間のジェスチャ、ジェスチャのフレームの外部で手に移動し、目的の結果を失うことのリスクです。

考慮すべき 3 つのことがあります。

- ジェスチャのフレームの存在とおおよその境界 (これは、HoloLens のセットアップ中については) でユーザー教育します。

- ときに、ジェスチャが近づいて/重大な程度失わジェスチャが望ましくない結果に至るまで、アプリケーション内でジェスチャ フレーム境界のユーザーに通知します。 調査によれば、このような通知システムのキーの品質を評価し、HoloLens のシェルがこの (ビジュアルでは、どの境界の交差が行われて方向を示す、中央のカーソルで) 通知の種類の良い例を提供します。

- ジェスチャのフレームの境界線の重大な影響を最小限に抑える必要があります。 一般はジェスチャの結果が、境界で停止していることが逆になっていないを意味します。 たとえば場合は、ユーザーが、部屋の holographic によってオブジェクトを移動、移動はジェスチャ フレームは、違反が発生したが、開始点は返されませんを停止する必要があります。 ユーザーは、可能性がありますし、いくつかのストレスが発生するが可能性があります、境界がより迅速に理解していなくてたびに完全な意図した操作を再起動します。


## <a name="see-also"></a>関連項目
* [手で直接操作](direct-manipulation.md)
* [手を使ったポイントとコミット](point-and-commit.md)
* [本能的な操作](interaction-fundamentals.md)
* [ヘッド視線入力とドウェル](gaze-and-dwell.md)
* [音声コマンド](voice-design.md)





