---
title: 目注視とコミット
description: 目注視し、コミットの入力モデルの概要
author: sostel
ms.author: sostel
ms.date: 05/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: 実際には、入力、目の視線入力、目を対象とする、HoloLens 2、目に基づく選択を混在、目の追跡
ms.openlocfilehash: 9cc27f24e1275223f33becd1ff0ec6bdf5b43a57
ms.sourcegitcommit: 60060386305eabfac2758a2c861a43c36286b151
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 05/31/2019
ms.locfileid: "66455088"
---
# <a name="eye-gaze-and-commit"></a><span data-ttu-id="f1a02-104">目注視とコミット</span><span class="sxs-lookup"><span data-stu-id="f1a02-104">Eye-gaze and commit</span></span>
<span data-ttu-id="f1a02-105">HoloLens 2 では、ヘッド視線の先ではなく目視線の先を使用して高速かつ快適にコミット (&)、視線の先を作成する機会があります。</span><span class="sxs-lookup"><span data-stu-id="f1a02-105">With HoloLens 2, we have the great opportunity to make gaze & commit faster and more comfortable by using eye gaze instead of head gaze.</span></span> <span data-ttu-id="f1a02-106">これにより、共通の拡張を[ヘッド注視し、コミット](gaze-and-commit.md)対話モデルには。</span><span class="sxs-lookup"><span data-stu-id="f1a02-106">This allows to extend the common [head-gaze and commit](gaze-and-commit.md) interaction model:</span></span> 
1. <span data-ttu-id="f1a02-107">単にターゲットを確認し、</span><span class="sxs-lookup"><span data-stu-id="f1a02-107">Simply look at a target and</span></span> 
2. <span data-ttu-id="f1a02-108">ターゲットを選択することを確認、セカンダリ明示的な a: などの入力を実行します</span><span class="sxs-lookup"><span data-stu-id="f1a02-108">To confirm your intention to select the target, perform a secondary explicit input such as a:</span></span>  
   - <span data-ttu-id="f1a02-109">手のジェスチャ (など、エア タップします)</span><span class="sxs-lookup"><span data-stu-id="f1a02-109">Hand gesture (e.g., an Air Tap)</span></span>
   - <span data-ttu-id="f1a02-110">(たとえば、Bluetooth キーボードまたは clicker) 上のボタンを押す</span><span class="sxs-lookup"><span data-stu-id="f1a02-110">Button press (e.g., on a Bluetooth keyboard or clicker)</span></span>
   - <span data-ttu-id="f1a02-111">音声指示コマンド (例:"Select")</span><span class="sxs-lookup"><span data-stu-id="f1a02-111">Voice command (e.g., "Select")</span></span>
   - <span data-ttu-id="f1a02-112">住所 (つまり、ユーザー保持を見ただけで、ターゲットを選択します)</span><span class="sxs-lookup"><span data-stu-id="f1a02-112">Dwelling (i.e., the user simply keeps looking at the target to select)</span></span>

<span data-ttu-id="f1a02-113">ただし、目視線の先では、特定の方法でヘッド視線の先をまったく違う方法で動作し、ためさまざまな固有の課題が付属します。</span><span class="sxs-lookup"><span data-stu-id="f1a02-113">However, eye gaze behaves very differently to head gaze in certain ways and hence comes with a number of unique challenges.</span></span> <span data-ttu-id="f1a02-114">[目視線のデザイン ガイドライン](eye-tracking.md)、一般的な利点のまとめし、を使用する場合を考慮する課題目 holographic アプリでの入力として追跡します。</span><span class="sxs-lookup"><span data-stu-id="f1a02-114">In the [Eye Gaze Design Guidelines](eye-tracking.md), we summarize general advantages and challenges to take into account when using eye tracking as an input in your holographic app.</span></span> <span data-ttu-id="f1a02-115">このセクションで目注視 & コミット 特定の設計に関する考慮事項について説明します。</span><span class="sxs-lookup"><span data-stu-id="f1a02-115">In this section, we focus on the specific design considerations for eye-gaze & commit.</span></span>
<span data-ttu-id="f1a02-116">最初に、人間の目では、非常に高速移動し、そのため、迅速に、ビュー全体を対象とする点で優れています。</span><span class="sxs-lookup"><span data-stu-id="f1a02-116">First, our eyes move incredibly fast and thus are great at quickly targeting across the view.</span></span> <span data-ttu-id="f1a02-117">これにより、視線の目のエア タップまたはクリックのキーを押してなどの高速コミットと組み合わせたときに特にクイックの視線の先コミット アクションに適しています。</span><span class="sxs-lookup"><span data-stu-id="f1a02-117">This makes eye gaze ideal for quick gaze-and-commit actions especially when combined with fast commits such as an air-tap or button press.</span></span>
   
<span data-ttu-id="f1a02-118">以下が答えのデザイン ガイドライン目を使用して、この種の相互作用の視線し、を考慮しておく必要がありますヘッド、目の視線入力間の違いについて説明します。</span><span class="sxs-lookup"><span data-stu-id="f1a02-118">In the following, we will address design guidelines when using eye gaze for this type of interaction and will discuss differences between head and eye gaze that you should keep in mind.</span></span>

## <a name="design-guidelines-for-eye-gaze-and-commit"></a><span data-ttu-id="f1a02-119">目注視し、コミットの設計ガイドライン</span><span class="sxs-lookup"><span data-stu-id="f1a02-119">Design guidelines for eye-gaze and commit</span></span>

<span data-ttu-id="f1a02-120">**カーソルを表示しない**:対話することはほぼ不可能ヘッドを使用する場合、カーソルなし視線、カーソルは煩雑素早く目視線の先を使用する場合に面倒になります。</span><span class="sxs-lookup"><span data-stu-id="f1a02-120">**Do not show a cursor**: While it is nearly impossible to interact without a cursor when using head gaze, the cursor becomes quickly distracting and annoying when using eye gaze.</span></span> <span data-ttu-id="f1a02-121">ユーザーに通知するためのカーソルではなく視線が動作してが正常かどうかが検出されました現在参照 target、微妙なビジュアルの使用には (詳細については以下) が強調表示します。</span><span class="sxs-lookup"><span data-stu-id="f1a02-121">Instead of relying on a cursor to inform the user whether eye tracking is working and has correctly detected the currently looked at target, use subtle visual highlights (more details below).</span></span>

<span data-ttu-id="f1a02-122">**微妙なブレンド ホバー フィードバックの**:ヘッド視線入力の優れた視覚的なフィードバックをものと、目視線の先を使用して恐ろしい、圧倒的なの経験があります。</span><span class="sxs-lookup"><span data-stu-id="f1a02-122">**Strive for subtle blended hover feedback**: What seems great visual feedback for head gaze can result in terrible, overwhelming experiences using eye gaze.</span></span> <span data-ttu-id="f1a02-123">目がきわめて高速で、フィールドからのビュー ポイント間ですばやく darting ことに注意してください。</span><span class="sxs-lookup"><span data-stu-id="f1a02-123">Remember that your eyes are enormously fast, quickly darting across points in your field-of-view.</span></span> <span data-ttu-id="f1a02-124">の検索時にちらつきのフィードバック (オン/オフ) クイック突然強調表示の変更があります。</span><span class="sxs-lookup"><span data-stu-id="f1a02-124">Quick sudden highlight changes (on/off) may result in flickery feedback when looking around.</span></span> <span data-ttu-id="f1a02-125">そのため、ホバー フィードバックを提供するときにスムーズにブレンドで強調表示の使用をお勧めします (およびブレンド アウトご覧にならない場合)。</span><span class="sxs-lookup"><span data-stu-id="f1a02-125">So, when providing hover feedback, we recommend using a smoothly blended-in highlight (and blended-out when looking away).</span></span> <span data-ttu-id="f1a02-126">最初に注意する必要がほとんどフィードバック ターゲットを見たときにこのことを意味します。</span><span class="sxs-lookup"><span data-stu-id="f1a02-126">This means that at first you would barely notice the feedback when looking at a target.</span></span> <span data-ttu-id="f1a02-127">500 ~ 1000 ミリ秒の過程で、強調表示は強さの点で向上します。</span><span class="sxs-lookup"><span data-stu-id="f1a02-127">Over the course of 500-1000 ms the highlight would increase in intensity.</span></span> <span data-ttu-id="f1a02-128">ターゲット システムのフォーカスがあるターゲットが正しく判断したことを確認するには、初心者のユーザーを検索し続ける可能性があります、中に上級ユーザーでしたすばやく視線 & フィードバックがその最大輝度になるまで待機することがなくコミットします。</span><span class="sxs-lookup"><span data-stu-id="f1a02-128">While novice users could keep looking at the target to ensure that the system has correctly determined the focused target, expert users could quickly gaze & commit without waiting until the feedback is at its full intensity.</span></span> <span data-ttu-id="f1a02-129">さらに、ホバー フィードバック フェードアウトときに blend アウトを使用することもお勧めします。</span><span class="sxs-lookup"><span data-stu-id="f1a02-129">In addition, we also recommend using a blend-out when fading out the hover feedback.</span></span> <span data-ttu-id="f1a02-130">調査は、モーション センサーとコントラストの簡単な変更が、周辺視野 (ため、場所を確認していない visual フィールドの領域) に非常に顕著なことが示されています。</span><span class="sxs-lookup"><span data-stu-id="f1a02-130">Research has shown that quick motion and contrast changes are very noticeable in your peripheral vision (so, the area of your visual field where you are not looking).</span></span> <span data-ttu-id="f1a02-131">Blend でとして、低速である、フェードアウトはありません。</span><span class="sxs-lookup"><span data-stu-id="f1a02-131">The fade-out doesn't have to be as slow as the blend-in.</span></span> <span data-ttu-id="f1a02-132">これは、強調表示のハイ コントラストまたは色の変更がある場合のみ重要です。</span><span class="sxs-lookup"><span data-stu-id="f1a02-132">This is only critical when you have high contrast or color changes for your highlight.</span></span> <span data-ttu-id="f1a02-133">ホバー フィードバックが非常に微妙な始めに場合は、言われなければ気付かない違いです。</span><span class="sxs-lookup"><span data-stu-id="f1a02-133">If the hover feedback was pretty subtle to begin with, you probably won't notice a difference.</span></span>

<span data-ttu-id="f1a02-134">**視線入力し、コミットの信号の同期をご確認ください**:入力信号の同期がない可能性がある単純な視線の先 (&)、コミットの課題のため、心配しないでください。</span><span class="sxs-lookup"><span data-stu-id="f1a02-134">**Look out for synchronizing gaze and commit signals**: The synchronization of input signals may be less of a challenge for simple gaze & commit, so, don't worry!</span></span> <span data-ttu-id="f1a02-135">ご確認ください長い音声コマンドまたは複雑な手のジェスチャを含む可能性がありますより複雑なコミット アクションを使用する場合にすべきことです。</span><span class="sxs-lookup"><span data-stu-id="f1a02-135">It is something to look out for in case you want to use more complicated commit actions though that may involve long voice commands or complicated hand gestures.</span></span> <span data-ttu-id="f1a02-136">ターゲットを確認し、長い音声コマンドを話したを想像してください。</span><span class="sxs-lookup"><span data-stu-id="f1a02-136">Imagine you look at target and utter a long voice command.</span></span> <span data-ttu-id="f1a02-137">検出すると、システムが必要な時間と話すに必要な時間を考慮アカウントに、目、視線の先が、通常、時間に移動したシーン内のいくつかの新しいターゲット。</span><span class="sxs-lookup"><span data-stu-id="f1a02-137">Taken into account the time that you needed to speak and the time that the system needed to detect what you said, your eye gaze has usually long moved on to some new target in the scene.</span></span> <span data-ttu-id="f1a02-138">そのため、いずれかことをユーザーに、ターゲットでコマンドが認識されている必要がありますまたはコマンドとどのようなユーザー求めていたに当時の始まった時点を決定する方法で入力を処理することがある注意してください。</span><span class="sxs-lookup"><span data-stu-id="f1a02-138">Hence, either make your users aware that they may need to keep looking at a target until the command has been recognized or handle the input in a way to determine the onset of the command and what the user had been looking at back then.</span></span>

## <a name="see-also"></a><span data-ttu-id="f1a02-139">関連項目</span><span class="sxs-lookup"><span data-stu-id="f1a02-139">See also</span></span>
* [<span data-ttu-id="f1a02-140">頭の視線入力とコミット</span><span class="sxs-lookup"><span data-stu-id="f1a02-140">Head-gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="f1a02-141">手のジェスチャ</span><span class="sxs-lookup"><span data-stu-id="f1a02-141">Hand gestures</span></span>](gestures.md)
* [<span data-ttu-id="f1a02-142">音声入力</span><span class="sxs-lookup"><span data-stu-id="f1a02-142">Voice input</span></span>](voice-design.md)
* [<span data-ttu-id="f1a02-143">モーション コントローラー</span><span class="sxs-lookup"><span data-stu-id="f1a02-143">Motion controllers</span></span>](motion-controllers.md)
