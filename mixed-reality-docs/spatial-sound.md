---
title: 立体音響
description: 混合 reality アプリケーションで空間サウンドを使用すると、3D 空間にサウンドを convincingly ことができます。
author: hak0n
ms.author: hakons
ms.date: 03/21/2018
ms.topic: article
keywords: 空間サウンド、サラウンドサウンド、3d オーディオ、3d サウンド、空間オーディオ
ms.openlocfilehash: a30a484c4e47593556fbd1786158262551e11d22
ms.sourcegitcommit: 17f86fed532d7a4e91bd95baca05930c4a5c68c5
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 06/11/2019
ms.locfileid: "66829918"
---
# <a name="spatial-sound"></a>立体音響

オブジェクトが目に見えなくなったときに、私たちが何をしているのかを確認する方法の1つは、サウンドを使用することです。 Windows Mixed Reality では、音声エンジンは、方向、距離、および環境シミュレーションを使用して3D サウンドをシミュレートすることによって、mixed reality の aural コンポーネントを提供します。 アプリケーションで空間サウンドを使用すると、開発者はユーザーに対して3次元空間 (球) でサウンドを convincingly ことができます。 これらのサウンドは、実際の物理オブジェクトまたはユーザーの周囲の混合現実ホログラムからのものであるように見えます。 [ホログラム](hologram.md)が光の付いたオブジェクトであり、音がかかることがあるので、サウンドコンポーネントは、believable を増やし、よりイマーシブなエクスペリエンスを作成するために、地面のホログラムに役立ちます。

ホログラムは、ユーザーの宝石が指している場所でのみ視覚的に表示できますが、アプリのサウンドはすべての方向から取得できます。上、下、背後、その他この機能を使用すると、現在ユーザーの表示に含まれていない可能性があるオブジェクトに注意を促すことができます。 ユーザーは、混合現実の世界でソースから emanating されるような音を感じることができます。 たとえば、ユーザーがオブジェクトに近づいたり、オブジェクトに近づいたりすると、ボリュームが増加します。 同様に、オブジェクトがユーザーの周りを移動する場合や、その逆の場合は、空間サウンドによって、サウンドがオブジェクトから直接送られるようになります。

<br>

>[!VIDEO https://www.youtube.com/embed/PTPvx7mDon4]

## <a name="device-support"></a>デバイスのサポート

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><strong>機能</strong></td>
        <td><a href="hololens-hardware-details.md"><strong>HoloLens (第 1 世代)</strong></a></td>
        <td><strong>HoloLens 2</strong></td>
        <td><a href="immersive-headset-hardware-details.md"><strong>イマーシブ ヘッドセット</strong></a></td>
    </tr>
     <tr>
        <td>立体音響</td>
        <td>✔️</td>
        <td>✔️</td>
        <td>✔️ (ヘッドフォンあり)</td>
    </tr>
</table>

## <a name="simulating-the-perceived-location-and-distance-of-sounds"></a>認識された場所とサウンドの距離をシミュレートする

サウンドが耳の両方に到達したかを分析することで、脳は、サウンドを生成するオブジェクトの距離と方向を決定します。 HRTF (または Head 関連の転送関数) は、ポイントの地点からの耳の反応を特徴付けるスペクトル応答をモデル化することで、この相互作用をシミュレートします。 空間オーディオエンジンでは、カスタマイズされた HRTFs を使用して、mixed reality エクスペリエンスを拡張し、さまざまな方向や距離からのサウンドをシミュレートします。

<br>

>[!VIDEO https://www.youtube.com/embed/aB3TDjYklmo]

左または右のオーディオ (azimuth) のキューは、各 ear でサウンドが到着したときの違いに起因します。 上下のキューは、外側の ear 図形 (pinnae) によって生成されたスペクトル変化から発生します。 オーディオの発信元を指定することにより、システムは、耳に異なる時刻に到着したサウンドのエクスペリエンスをシミュレートできます。 HoloLens では、azimuth spatialization はパーソナル化されていますが、昇格のシミュレーションは平均 anthropometrics のセットに基づいていることに注意してください。 したがって、昇格の精度は azimuth の精度よりも正確ではない可能性があります。

サウンドの特性は、それらが存在する環境によっても変わります。 たとえば、岩穴で叫んを使用すると、音声が壁、床、および雲に出、エコー効果が作成されます。 空間サウンドの部屋モデル設定は、特定のオーディオ環境でサウンドを配置するために、これらの反射を再現します。 この設定を使用すると、ユーザーの実際の場所を一致させて、よりイマーシブなオーディオエクスペリエンスを作成することができます。

## <a name="integrating-spatial-sound"></a>空間サウンドの統合

混合現実の一般的な原則は、ユーザーの物理的な世界または仮想環境での最先端の[ホログラム](hologram.md)であるため、ホログラムからのほとんどのサウンドは spatialized にする必要があります。 HoloLens では、自然に CPU とメモリの予算に関する考慮事項がありますが、CPU の使用率が 12% 未満 (4 つのコアのうちの 70%) を使用して、10-12 の空間サウンド音声を使用できます。 空間サウンドの音声の推奨される用途は次のとおりです。
* (特にビュー外の) オブジェクトを見つめています。 ホログラムにユーザーの注意が必要な場合は、そのホログラムでサウンドを再生します (例: 仮想 dog ほえ)。 これにより、ユーザーは、表示されていないホログラムを見つけることができます。
* Audio Haptics (touchless 相互作用のためのリアクティブオーディオ)。 たとえば、ユーザーの手や運動コントローラーがジェスチャフレームを入力して終了したときに音を鳴らします。 または、ユーザーがホログラムを選択したときに音を鳴らします。
* Immersion (ユーザーを囲むアンビエントサウンド)。

また、標準のステレオサウンドと空間サウンドをブレンドすると、現実的な環境を作成するのに効果的な場合があることに注意してください。ステレオサウンドは、反射 (距離の手掛かり) は、ノイズの多い環境では聞こえにくいことがあります。

Windows の空間サウンドエンジンでは、再生用に 48 k サンプルレートのみがサポートされています。 Unity などのほとんどのミドルウェアでは、サウンドファイルはサポートされている形式に自動的に変換されますが、Windows Audio Api を直接使用する場合は、コンテンツの形式を、その効果でサポートされている形式に一致させることができます。

## <a name="see-also"></a>関連項目
* [MR 空間220](holograms-220.md)
* [Unity の立体音響](spatial-sound-in-unity.md)
* [DirectX の立体音響](spatial-sound-in-directx.md)
* [立体音響の設計](spatial-sound-design.md)
