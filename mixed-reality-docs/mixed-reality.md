---
title: どのような複合現実をですか。
description: この記事では、複合現実を定義し、複合現実スペクトルに沿っての単純な AR、VR デバイス、だけではなく、Microsoft HoloLens と Windows Mixed Reality のイマーシブ ヘッドセットなどの Windows Mixed Reality デバイスの配置場所を示します。
author: BrandonBray
ms.author: branbray
ms.date: 03/21/2018
ms.topic: article
keywords: 複合現実、holographic、ar、vr、mr、xr、拡張現実、仮想現実、説明
ms.openlocfilehash: fbac8176b36cf28673dd9633cc059e5856a50296
ms.sourcegitcommit: 30246ab9b9be44a3c707061753e53d4bf401eb6b
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 06/22/2019
ms.locfileid: "67326310"
---
# <a name="what-is-mixed-reality"></a><span data-ttu-id="d7b63-104">どのような複合現実をですか。</span><span class="sxs-lookup"><span data-stu-id="d7b63-104">What is mixed reality?</span></span>

<span data-ttu-id="d7b63-105">複合現実では、デジタルの世界と現実の世界をブレンドの結果です。</span><span class="sxs-lookup"><span data-stu-id="d7b63-105">Mixed reality is the result of blending the physical world with the digital world.</span></span> <span data-ttu-id="d7b63-106">複合現実では、ユーザー、コンピューター、および環境の相互作用における次の進化は、し、可能性をこれまで、imaginations に制限されていましたのロックを解除します。</span><span class="sxs-lookup"><span data-stu-id="d7b63-106">Mixed reality is the next evolution in human, computer, and environment interaction and unlocks possibilities that before now were restricted to our imaginations.</span></span> <span data-ttu-id="d7b63-107">これは、コンピューター ビジョン、グラフィカルな処理能力、表示テクノロジ、および入力システムの進歩によって実現されます。</span><span class="sxs-lookup"><span data-stu-id="d7b63-107">It is made possible by advancements in computer vision, graphical processing power, display technology, and input systems.</span></span> <span data-ttu-id="d7b63-108">用語*複合現実*Paul Milgram して Fumio Kishino、1994年ホワイト ペーパーで導入された"[混合の分類を実際には視覚的な表示](http://etclab.mie.utoronto.ca/people/paul_dir/IEICE94/ieice.html)"。</span><span class="sxs-lookup"><span data-stu-id="d7b63-108">The term *mixed reality* was originally introduced in a 1994 paper by Paul Milgram and Fumio Kishino, "[A Taxonomy of Mixed Reality Visual Displays](http://etclab.mie.utoronto.ca/people/paul_dir/IEICE94/ieice.html)."</span></span> <span data-ttu-id="d7b63-109">そのホワイト ペーパーの概念が導入、*仮想 continuum*に適用される分類法の分類を表示する方法に重点を置いてとします。</span><span class="sxs-lookup"><span data-stu-id="d7b63-109">Their paper introduced the concept of the *virtuality continuum*, and focused on how the categorization of taxonomy applied to displays.</span></span> <span data-ttu-id="d7b63-110">その後、複合現実のアプリケーションが表示されますを超えます。</span><span class="sxs-lookup"><span data-stu-id="d7b63-110">Since then, the application of mixed reality goes beyond displays.</span></span> <span data-ttu-id="d7b63-111">環境の入力、サウンドの空間、および場所も含まれています。</span><span class="sxs-lookup"><span data-stu-id="d7b63-111">It also includes environmental input, spatial sound, and location.</span></span>

## <a name="environmental-input-and-perception"></a><span data-ttu-id="d7b63-112">環境の入力や認識</span><span class="sxs-lookup"><span data-stu-id="d7b63-112">Environmental input and perception</span></span>

![コンピューター、人間、環境間の相互作用を示す venn ダイアグラム](images/mixed-reality-venn-diagram-300px.png)<br> 

<span data-ttu-id="d7b63-114">過去何十年にも、経由では、人間とコンピューター入力間のリレーションシップをもについて説明されているしました。</span><span class="sxs-lookup"><span data-stu-id="d7b63-114">Over the past several decades, the relationship between human and computer input has been well explored.</span></span> <span data-ttu-id="d7b63-115">呼ばれる広く研究された規範に*人間のコンピューター間の対話*または HCI します。</span><span class="sxs-lookup"><span data-stu-id="d7b63-115">It even has a widely studied discipline known as *human computer interaction* or HCI.</span></span> <span data-ttu-id="d7b63-116">ユーザーによる入力は、さまざまなキーボード、マウス、タッチ、インク、音声、および Kinect スケルトンの追跡もなどの方法では発生します。</span><span class="sxs-lookup"><span data-stu-id="d7b63-116">Human input happens through a variety of means, including keyboards, mice, touch, ink, voice, and even Kinect skeletal tracking.</span></span>

<span data-ttu-id="d7b63-117">センサーと処理の進歩は環境から、コンピューターの入力の新しい領域に上昇に付与されます。</span><span class="sxs-lookup"><span data-stu-id="d7b63-117">Advancements in sensors and processing are giving rise to a new area of computer input from environments.</span></span> <span data-ttu-id="d7b63-118">コンピューターと環境間の相互作用が効果的に環境の理解や*perception*します。</span><span class="sxs-lookup"><span data-stu-id="d7b63-118">The interaction between computers and environments is effectively environmental understanding or *perception*.</span></span> <span data-ttu-id="d7b63-119">環境情報を表示するための Windows での API 名が呼び出されるため、 [perception Api](https://docs.microsoft.com/uwp/api/Windows.Perception)します。</span><span class="sxs-lookup"><span data-stu-id="d7b63-119">Hence the API names in Windows that reveal environmental information are called the [perception APIs](https://docs.microsoft.com/uwp/api/Windows.Perception).</span></span> <span data-ttu-id="d7b63-120">環境の入力などの世界で個人の位置をキャプチャする (例:[ヘッド追跡](coordinate-systems.md))、サーフェスと境界 (例:[空間マッピング](spatial-mapping.md)と[空間理解](case-study-expanding-the-spatial-mapping-capabilities-of-hololens.md))、環境光、環境音、オブジェクトの認識、および場所です。</span><span class="sxs-lookup"><span data-stu-id="d7b63-120">Environmental input captures things like a person's position in the world (e.g. [head tracking](coordinate-systems.md)), surfaces and boundaries (e.g. [spatial mapping](spatial-mapping.md) and [spatial understanding](case-study-expanding-the-spatial-mapping-capabilities-of-hololens.md)), ambient lighting, environmental sound, object recognition, and location.</span></span>

<span data-ttu-id="d7b63-121">ここで、3 - すべてのコンピューター処理の組み合わせ、人間の入力、および環境の入力 - 設定 true 複合現実エクスペリエンスを作成すること。</span><span class="sxs-lookup"><span data-stu-id="d7b63-121">Now, the combination of all three--computer processing, human input, and environmental input--sets the opportunity to create true mixed reality experiences.</span></span> <span data-ttu-id="d7b63-122">現実の世界での移動は、デジタルの世界での移動に変換できます。</span><span class="sxs-lookup"><span data-stu-id="d7b63-122">Movement through the physical world can translate to movement in the digital world.</span></span> <span data-ttu-id="d7b63-123">現実の世界で境界デジタルの世界でのゲーム プレイなどのアプリケーション エクスペリエンスに影響を与えることができます。</span><span class="sxs-lookup"><span data-stu-id="d7b63-123">Boundaries in the physical world can influence application experiences, such as game play, in the digital world.</span></span> <span data-ttu-id="d7b63-124">環境の入力を行わなくてもエクスペリエンスは、物理とデジタルの現実の間で blend ことはできません。</span><span class="sxs-lookup"><span data-stu-id="d7b63-124">Without environmental input, experiences cannot blend between physical and digital realities.</span></span>

## <a name="the-mixed-reality-spectrum"></a><span data-ttu-id="d7b63-125">複合現実スペクトル</span><span class="sxs-lookup"><span data-stu-id="d7b63-125">The mixed reality spectrum</span></span>

<span data-ttu-id="d7b63-126">複合現実では、物理とデジタルの両方の長所をブレンド、ために、これら 2 つの現実は仮想 continuum と呼ばれるスペクトルの極座標 end を定義します。</span><span class="sxs-lookup"><span data-stu-id="d7b63-126">Since mixed reality blends both physical and digital worlds, these two realities define the polar ends of a spectrum known as the virtuality continuum.</span></span> <span data-ttu-id="d7b63-127">わかりやすくするため、これに言及、*複合現実スペクトル*します。</span><span class="sxs-lookup"><span data-stu-id="d7b63-127">For simplicity, we refer to this as the *mixed reality spectrum*.</span></span> <span data-ttu-id="d7b63-128">左側にある私たち人間に存在する; 物理的現実があります。右側にある、対応するデジタル現実があります。</span><span class="sxs-lookup"><span data-stu-id="d7b63-128">On the left-hand side we have physical reality in which we, humans, exist; on the right-hand side we have the corresponding digital reality.</span></span>

<br>

>[!VIDEO https://www.youtube.com/embed/_xpI0JosYUk]

<span data-ttu-id="d7b63-129">市場でのほとんどの携帯電話には、今日 no にほとんどの環境についての機能がありません。</span><span class="sxs-lookup"><span data-stu-id="d7b63-129">Most mobile phones on the market today have little to no environmental understanding capabilities.</span></span> <span data-ttu-id="d7b63-130">したがって物理とデジタルの現実の間、エクスペリエンスを提供するを混ぜることはできません。</span><span class="sxs-lookup"><span data-stu-id="d7b63-130">Thus the experiences they offer cannot mix between physical and digital realities.</span></span> <span data-ttu-id="d7b63-131">現実の世界のビデオ ストリーム上の画像をオーバーレイするエクスペリエンスは*拡張現実*します。</span><span class="sxs-lookup"><span data-stu-id="d7b63-131">The experiences that overlay graphics on video streams of the physical world are *augmented reality*.</span></span> <span data-ttu-id="d7b63-132">ビュー、デジタル エクスペリエンスを提供するエクスペリエンスは*仮想現実*します。</span><span class="sxs-lookup"><span data-stu-id="d7b63-132">The experiences that occlude your view to present a digital experience are *virtual reality*.</span></span> <span data-ttu-id="d7b63-133">ご覧のように、これら 2 つの両極端の間で有効なの経験は*複合現実*:</span><span class="sxs-lookup"><span data-stu-id="d7b63-133">As you can see, the experiences enabled between these two extremes is *mixed reality*:</span></span>
* <span data-ttu-id="d7b63-134">現実の世界では、実際には、そこにあったかのように、ホログラムなどのデジタル オブジェクトを配置することで開始しています。</span><span class="sxs-lookup"><span data-stu-id="d7b63-134">Starting with the physical world, placing a digital object, such as a hologram, as if it was really there.</span></span>
* <span data-ttu-id="d7b63-135">現実の世界では、- 別のユーザーのデジタル形式で始まる--アバターがノートの終了時に、立っていた場所を示しています。</span><span class="sxs-lookup"><span data-stu-id="d7b63-135">Starting with the physical world, a digital representation of another person--an avatar--shows the location where they were standing when leaving notes.</span></span> <span data-ttu-id="d7b63-136">つまり、さまざまな時点での非同期のコラボレーションを表すエクスペリエンス。</span><span class="sxs-lookup"><span data-stu-id="d7b63-136">In other words, experiences that represent asynchronous collaboration at different points in time.</span></span>
* <span data-ttu-id="d7b63-137">ユーザーが物理オブジェクトを回避するためのエクスペリエンスで以降デジタルの世界では、壁や、家具など、現実の世界から物理的な境界をデジタル表示します。</span><span class="sxs-lookup"><span data-stu-id="d7b63-137">Starting with a digital world, physical boundaries from the physical world, such as walls and furniture, appear digitally within the experience to help users avoid physical objects.</span></span>

![複合現実スペクトル](images/mixed-reality-spectrum-550px.png)

<span data-ttu-id="d7b63-139">最も拡張現実と使用可能な仮想現実内容今日このスペクトルのごく一部を表します。</span><span class="sxs-lookup"><span data-stu-id="d7b63-139">Most augmented reality and virtual reality offerings available today represent a very small part of this spectrum.</span></span> <span data-ttu-id="d7b63-140">ただし、大きい複合現実スペクトルのサブセットです。</span><span class="sxs-lookup"><span data-stu-id="d7b63-140">They are, however, subsets of the larger mixed reality spectrum.</span></span> <span data-ttu-id="d7b63-141">Windows 10 では、全体の範囲を考慮して、使用して作成され、により、人物、場所、および現実の世界でのデジタルの表現を描画します。</span><span class="sxs-lookup"><span data-stu-id="d7b63-141">Windows 10 is built with the entire spectrum in mind, and allows blending digital representations of people, places, and things with the real world.</span></span>

![複合現実スペクトルにデバイスの種類](images/mixed-reality-spectrum-device-types-550px.png)

<span data-ttu-id="d7b63-143">Windows Mixed Reality エクスペリエンスを提供するデバイスの 2 つの主な種類あります。</span><span class="sxs-lookup"><span data-stu-id="d7b63-143">There are two main types of devices that deliver Windows Mixed Reality experiences:</span></span>
1. <span data-ttu-id="d7b63-144">**Holographic デバイス。**</span><span class="sxs-lookup"><span data-stu-id="d7b63-144">**Holographic devices.**</span></span> <span data-ttu-id="d7b63-145">これらは、実際に存在した場合と同じ、現実の世界にデジタル コンテンツを配置するデバイスの機能によって特徴付けられます。</span><span class="sxs-lookup"><span data-stu-id="d7b63-145">These are characterized by the device's ability to place digital content in the real world as if it were really there.</span></span>
2. <span data-ttu-id="d7b63-146">**没入型のデバイス。**</span><span class="sxs-lookup"><span data-stu-id="d7b63-146">**Immersive devices.**</span></span> <span data-ttu-id="d7b63-147">これらは、「プレゼンス」--現実の世界を非表示化とデジタル エクスペリエンスに置き換えることの意味を作成するデバイスの機能によって特徴付けられます。</span><span class="sxs-lookup"><span data-stu-id="d7b63-147">These are characterized by the device's ability to create a sense of "presence"--hiding the physical world, and replacing it with a digital experience.</span></span>

<table>
<tr>
<th width="20%"> <span data-ttu-id="d7b63-148">特性</span><span class="sxs-lookup"><span data-stu-id="d7b63-148">Characteristic</span></span></th><th width="40%"> <span data-ttu-id="d7b63-149">Holographic デバイス</span><span class="sxs-lookup"><span data-stu-id="d7b63-149">Holographic Devices</span></span></th><th width="40%"> <span data-ttu-id="d7b63-150">没入型のデバイス</span><span class="sxs-lookup"><span data-stu-id="d7b63-150">Immersive Devices</span></span></th>
</tr><tr>
<td> <span data-ttu-id="d7b63-151">デバイスの例</span><span class="sxs-lookup"><span data-stu-id="d7b63-151">Example Device</span></span></td><td> <span data-ttu-id="d7b63-152">Microsoft HoloLens</span><span class="sxs-lookup"><span data-stu-id="d7b63-152">Microsoft HoloLens</span></span><br /> <img alt="Microsoft HoloLens image" width="300" height="169" src="images/mshololens-hero1-whitbg-rgb-300px.png" /></td><td> <span data-ttu-id="d7b63-153">Acer の Windows Mixed Reality Development Edition</span><span class="sxs-lookup"><span data-stu-id="d7b63-153">Acer Windows Mixed Reality Development Edition</span></span><br /> <img alt="Acer Windows Mixed Reality Development Edition image" width="300" height="169" src="images/acer-windows-mixed-reality-development-edition-headset-300px.jpg" /></td>
</tr><tr>
<td> <span data-ttu-id="d7b63-154">ディスプレイ</span><span class="sxs-lookup"><span data-stu-id="d7b63-154">Display</span></span></td><td> <span data-ttu-id="d7b63-155"><i>透かしが表示されます。</i></span><span class="sxs-lookup"><span data-stu-id="d7b63-155"><i>See-through display.</i></span></span> <span data-ttu-id="d7b63-156">ヘッドセット ソックスを着けずにいるときに、物理環境を参照できます。</span><span class="sxs-lookup"><span data-stu-id="d7b63-156">Allows user to see the physical environment while wearing the headset.</span></span></td><td> <span data-ttu-id="d7b63-157"><i>非透過が表示されます。</i></span><span class="sxs-lookup"><span data-stu-id="d7b63-157"><i>Opaque display.</i></span></span> <span data-ttu-id="d7b63-158">ソックスを着けずにヘッドセット中には、物理環境をブロックします。</span><span class="sxs-lookup"><span data-stu-id="d7b63-158">Blocks out the physical environment while wearing the headset.</span></span></td>
</tr><tr>
<td> <span data-ttu-id="d7b63-159">移動</span><span class="sxs-lookup"><span data-stu-id="d7b63-159">Movement</span></span></td><td> <span data-ttu-id="d7b63-160">完全な 6 つ自由度の移動、回転と変換の両方。</span><span class="sxs-lookup"><span data-stu-id="d7b63-160">Full six-degrees-of-freedom movement, both rotation and translation.</span></span></td><td> <span data-ttu-id="d7b63-161">完全な 6 つ自由度の移動、回転と変換の両方。</span><span class="sxs-lookup"><span data-stu-id="d7b63-161">Full six-degrees-of-freedom movement, both rotation and translation.</span></span></td>
</tr>
</table>

<span data-ttu-id="d7b63-162">なお、デバイスに接続されているかどうかまたは (USB ケーブルまたは Wi-fi) 経由で別の PC または自己完結型の (無制限) はテザリングされたデバイスとは holographic または没入型かどうかは含まれません。</span><span class="sxs-lookup"><span data-stu-id="d7b63-162">Note, whether a device is connected to or tethered to a separate PC (via USB cable or Wi-Fi) or self-contained (untethered) does not reflect whether a device is holographic or immersive.</span></span> <span data-ttu-id="d7b63-163">確かに、モビリティを強化する機能より優れたエクスペリエンスにつながるおよび holographic と没入型の両方のデバイスがであるテザリングされたか無制限。</span><span class="sxs-lookup"><span data-stu-id="d7b63-163">Certainly, features that improve mobility lead to better experiences, and both holographic and immersive devices could be tethered or untethered.</span></span>

## <a name="devices-and-experiences"></a><span data-ttu-id="d7b63-164">デバイスとエクスペリエンス</span><span class="sxs-lookup"><span data-stu-id="d7b63-164">Devices and experiences</span></span>

<span data-ttu-id="d7b63-165">技術の進歩では、何が複合現実エクスペリエンスを有効にします。</span><span class="sxs-lookup"><span data-stu-id="d7b63-165">Technological advancement is what has enabled mixed reality experiences.</span></span> <span data-ttu-id="d7b63-166">全体の広範囲にわたる経験を実行できるデバイスを今すぐはありません。</span><span class="sxs-lookup"><span data-stu-id="d7b63-166">There are no devices today that can run experiences across the entire spectrum.</span></span> <span data-ttu-id="d7b63-167">ただし、Windows 10 では、デバイスの製造元と開発者の両方の共通の複合現実プラットフォームを提供します。</span><span class="sxs-lookup"><span data-stu-id="d7b63-167">However, Windows 10 provides a common mixed reality platform for both device manufacturers and developers.</span></span> <span data-ttu-id="d7b63-168">今すぐのデバイスは、複合現実の範囲内の特定の範囲をサポートできます。</span><span class="sxs-lookup"><span data-stu-id="d7b63-168">Devices today can support a specific range within the mixed reality spectrum.</span></span> <span data-ttu-id="d7b63-169">時間の経過と共に新しいデバイスはその範囲を展開します。</span><span class="sxs-lookup"><span data-stu-id="d7b63-169">Over time, new devices will expand that range.</span></span> <span data-ttu-id="d7b63-170">今後、holographic デバイスになり、没入感が向上、没入型のデバイスはより holographic になります。</span><span class="sxs-lookup"><span data-stu-id="d7b63-170">In the future, holographic devices will become more immersive, and immersive devices will become more holographic.</span></span>

![デバイスが複合現実スペクトルにレイアウトします。](images/mixed-reality-spectrum-device-placement-550px.png)

<span data-ttu-id="d7b63-172">多くの場合、またはゲーム開発者が作成するアプリケーション エクスペリエンスの種類を考慮することをお勧めします。</span><span class="sxs-lookup"><span data-stu-id="d7b63-172">Often, it is best to think what type of experience an application or game developer wants to create.</span></span> <span data-ttu-id="d7b63-173">特定の時点または、領域の一部、エクスペリエンスは通常対象に。</span><span class="sxs-lookup"><span data-stu-id="d7b63-173">The experiences will typically target a specific point or part on the spectrum.</span></span> <span data-ttu-id="d7b63-174">次に、開発者は、対象とデバイスの機能を検討する必要があります。</span><span class="sxs-lookup"><span data-stu-id="d7b63-174">Then, developers should consider the capabilities of devices they want to target.</span></span> <span data-ttu-id="d7b63-175">たとえば、現実の世界に依存するエクスペリエンスは、HoloLens で最適な実行されます。</span><span class="sxs-lookup"><span data-stu-id="d7b63-175">For example, experiences that rely on the physical world will run best on HoloLens.</span></span>
* <span data-ttu-id="d7b63-176">**に向かって (近くに物理的現実) 左。**</span><span class="sxs-lookup"><span data-stu-id="d7b63-176">**Towards the left (near physical reality).**</span></span> <span data-ttu-id="d7b63-177">ユーザーは残りますが、物理環境に存在して、残りの環境とお考えに加えられたことはありません。</span><span class="sxs-lookup"><span data-stu-id="d7b63-177">Users remain present in their physical environment and are never made to believe they have left that environment.</span></span>
* <span data-ttu-id="d7b63-178">**中間 (完全複合現実)。**</span><span class="sxs-lookup"><span data-stu-id="d7b63-178">**In the middle (fully mixed reality).**</span></span> <span data-ttu-id="d7b63-179">これらのエクスペリエンスは、現実の世界とデジタルの世界をブレンドします。</span><span class="sxs-lookup"><span data-stu-id="d7b63-179">These experiences blend the real world and the digital world.</span></span> <span data-ttu-id="d7b63-180">閲覧者向けビデオを見てきました[Jumanji](https://en.wikipedia.org/wiki/Jumanji)ジャングル環境とストーリーが行われた家の物理構造のブレンドされた方法を調整できます。</span><span class="sxs-lookup"><span data-stu-id="d7b63-180">Viewers who have seen the movie [Jumanji](https://en.wikipedia.org/wiki/Jumanji) can reconcile how the physical structure of the house where the story took place was blended with a jungle environment.</span></span>
* <span data-ttu-id="d7b63-181">**(近くに実際にはデジタル) 右方向。**</span><span class="sxs-lookup"><span data-stu-id="d7b63-181">**Towards the right (near digital reality).**</span></span> <span data-ttu-id="d7b63-182">ユーザーは、完全にデジタル環境が発生しての周囲に物理的な環境で発生するイベントに対応していません。</span><span class="sxs-lookup"><span data-stu-id="d7b63-182">Users experience a completely digital environment, and are unaware of what occurs in the physical environment around them.</span></span>


## <a name="see-also"></a><span data-ttu-id="d7b63-183">関連項目</span><span class="sxs-lookup"><span data-stu-id="d7b63-183">See also</span></span>
* [<span data-ttu-id="d7b63-184">API リファレンス:Windows.Perception</span><span class="sxs-lookup"><span data-stu-id="d7b63-184">API Reference: Windows.Perception</span></span>](https://docs.microsoft.com/uwp/api/Windows.Perception)
* [<span data-ttu-id="d7b63-185">API リファレンス:Windows.Perception.Spatial</span><span class="sxs-lookup"><span data-stu-id="d7b63-185">API Reference: Windows.Perception.Spatial</span></span>](https://docs.microsoft.com/uwp/api/Windows.Perception.Spatial)
* [<span data-ttu-id="d7b63-186">API リファレンス:Windows.Perception.Spatial.Surfaces</span><span class="sxs-lookup"><span data-stu-id="d7b63-186">API Reference: Windows.Perception.Spatial.Surfaces</span></span>](https://docs.microsoft.com/uwp/api/Windows.Perception.Spatial.Surfaces)
