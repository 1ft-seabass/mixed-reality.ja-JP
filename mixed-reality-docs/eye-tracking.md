---
title: 視線
description: HoloLens 2 を使用すると、開発者はユーザーが見ているものについての情報を使用できるので、ホログラフィック エクスペリエンスにおけるコンテキストと人間の理解が大きく進みます。
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
keywords: 視線追跡、Mixed Reality、インプット、視線
ms.openlocfilehash: 51779b7b210522aa4d19b5a32d7df6ccb2cb3a35
ms.sourcegitcommit: ff330a7e36e5ff7ae0e9a08c0e99eb7f3f81361f
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 08/28/2019
ms.locfileid: "70122065"
---
# <a name="eye-gaze-on-hololens-2"></a>HoloLens 2 での視線
HoloLens 2 を使用すると、開発者はユーザーが見ているものについての情報を使用できるので、ホログラフィック エクスペリエンスにおけるコンテキストと人間の理解が大きく進みます。 このページでは、さまざまなユースケースの目の追跡や、視線を使用したユーザーインターフェイスの設計時に見られることについて、どのように役立つかを開発者に通知します。 


## <a name="device-support"></a>デバイスのサポート

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><strong>機能</strong></td>
     <td><a href="hololens-hardware-details.md"><strong>HoloLens (第 1 世代)</strong></a></td>
     <td><strong>HoloLens 2</strong></td>
     <td><a href="immersive-headset-hardware-details.md"><strong>イマーシブ ヘッドセット</strong></a></td>
</tr>
<tr>
     <td>視線</td>
     <td>❌</td>
     <td>✔️</td>
     <td>❌</td>
</tr>
</table>

## <a name="use-cases"></a>使用事例
視線追跡を使用すれば、アプリケーションは、ユーザーが見ている場所をリアルタイムで追跡できます。 次のユースケースでは、mixed reality での視線追跡で可能な相互作用について説明します。
[混合現実のツールキット](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)は、目を通して見やすいように、目を追って見て見やすくするための便利で強力な例をいくつか提供していることに注意してください。ユーザーが見ている内容。 

### <a name="user-intent"></a>ユーザー意図    
ユーザーがどこで見ているかについての情報は、音声、ハンド、コントローラーなど**の他の入力に対し**て強力なコンテキストを提供します。
これは、さまざまなタスクに利用できます。
たとえば、ホログラムを見て「選択」と指示するだけで (「選択」を参照して[ください)、](gaze-and-commit.md)"select" を言い、 *"put the this..."* を言い、ユーザーがどこにいるかを調べることによって、シーン全体を**対象**とすることができます。ホログラムを配置したい*と言います。"* この例は、「[Mixed Reality Toolkit - Eye-supported Target Selection (Mixed Reality Toolkit - 目で支援するターゲット選択)](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html)」と「[Mixed Reality Toolkit - Eye-supported Target Positioning (Mixed Reality Toolkit - 目で支援するターゲット配置)](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html)」に記載されています。

さらに、ユーザーの目的の例として、ユーザーが参照する情報を使用して、埋め込み仮想エージェントや対話型ホログラムによるエンゲージメントを強化することができます。 たとえば、仮想エージェントは、現在表示されているコンテンツに基づいて、使用可能なオプションとその動作を適合させる場合があります。 

### <a name="implicit-actions"></a>暗黙的アクション
暗黙的アクションのカテゴリは、ユーザー意図に密接に関係しています。
これは、ホログラムまたはユーザーインターフェイスの要素が多少 instinctual な方法で対応することで、ユーザーがシステムと対話するのではなく、システムとユーザーが同期しているように感じる可能性があるということではないかもしれません。一例として、ユーザーがテキストを読み取ったときに自動的にスクロールが開始され、ユーザーがテキストボックスの一番下に移動したときに自動的にスクロールが開始されるような**自動スクロール**があります。  
この重要な点は、スクロール速度がユーザーの読み取り速度に適応することです。
もう1つの例として、視線がサポートされている**ズームとパン**があります。ユーザーは、フォーカスされている内容を正確に把握することができます。 ズームのトリガーとズーム速度の制御は、音声入力または手書き入力によって制御できます。これは、ユーザーがコントロールの感覚を持つことができるようにするために重要です。 これらの設計ガイドラインについては、以下で詳しく説明します。 拡大した後、ユーザーは、目を見つめて使用するだけで、自宅などの道をスムーズにたどることができます。
この種の相互作用に関するデモの例は、「[Mixed Reality Toolkit - Eye-supported Navigation (Mixed Reality Toolkit - 目で支援するナビゲーション)](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html)」のサンプルを参照してください。

_暗黙的なアクション_の追加のユースケースには、次のものが含まれます。
- **スマート通知:** 注目していた場所に通知がポップアップ表示されて不快に思ったことはありませんか? ユーザーがどのようなことに注目しているかを考慮して、ユーザーが現在使用している場所から通知をオフセットすることで、このエクスペリエンスを向上させることができます。 これにより、取られるが制限され、ユーザーの読み取りが完了すると自動的に破棄されます。 
- **気が利くホログラム:** Gazed 時に微妙に反応するホログラム。 これには、わずかに光る UI 要素から、ユーザーに見てみることができるように、または長時間の確認の後にユーザーの目を見つめないようにするために、わずかな咲きの花から仮想ペットまで、さまざまなものがあります。 この相互作用によって、アプリケーションでの接続性と満足度がわかりやすくなる場合があります。

### <a name="attention-tracking"></a>注意追跡   
どのようなユーザーが見ているかについての情報は、設計の使いやすさを評価し、効率的なワークフローの問題を特定するための非常強力なツールです。 さまざまなアプリケーション領域では、視線追跡の視覚化と分析が一般的な方法です。 HoloLens 2 では、このことを理解するために新しいディメンションを提供しています。これは、3D ホログラムを実際のコンテキストで配置し、それに従って評価することができるためです。 [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)には、視線追跡データをログに記録して読み込む方法と、それらを視覚化する方法の基本的な例が用意されています。

この領域の他のアプリケーションには、次のものが含まれます。 
-   **リモートの視線可視化:** リモートコラボレーターが見ていることを視覚化し、命令が正しく認識されているかどうかを確認します。
-   **ユーザー調査研究:** アテンション追跡を使用すると、初心者と専門家のユーザーが視覚的にコンテンツを分析する方法や、医療データを分析したり、運用している場合などの複雑なタスクに対する手作業の調整方法を調べることができます。
-   **トレーニング シミュレーションとパフォーマンス監視:** 実行フローにおけるボトルネックをより効率的に特定することにより、タスクの実行を練習して最適化します。
-   **デザイン評価、宣伝、市場調査:** 目の追跡は、web サイトと製品の設計を評価する際に市場調査を行うための一般的なツールです。

### <a name="additional-use-cases"></a>その他の使用事例
- **ゲーム:** スーパーパワーが欲しくなったことはありませんか? こつをお教えしましょう。 ホログラムを levitate することで、ホログラムを作成できます。 目からレーザー ビームを発射します。 敵を石にするか、固定します。 透視能力を使ってビルを探索します。 使い道は想像力次第です。  

- **表情豊かなアバター:** 視線追跡では、ライブ視線追跡データを使用して、ユーザーがどのようなものかを示すアバターの目をアニメーション化することで、より表現力の高い3D アバターを支援します。 

- **テキスト入力:** 視力の追跡は、特に音声や手の使用が不便な場合に、低労力のテキスト入力の代替手段として使用できます。 


## <a name="available-eye-tracking-data"></a>利用可能なアイトラッキングデータ
視線の相互作用に関する特定の設計ガイドラインについて詳しく説明する前に、HoloLens 2[目の追跡 API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose)によって提供される機能について簡単に説明します。 開発者は約_30 FPS (60 Hz)_ で、1つの目を見つめた射線 (宝石の出発点と向き) にアクセスできます。
視線追跡データへのアクセス方法の詳細については、「開発者ガイド」を参照してください。 [DirectX での視線](gaze-in-directx.md)と、 [Unity で](https://aka.ms/mrtk-eyes)の視線の使用に関するガイドを参照してください。

予測された視線は、実際のターゲットを中心に約1.5 °の範囲で表示されます (次の図を参照してください)。 わずかな不正確性が想定されているため、開発者はこの下限値の周りにいくらかの余白を計画する必要があります (たとえば、2.0-3.0 度では、より快適なエクスペリエンスが得られる可能性があります)。 以下では、小規模なターゲットの選択に対処する方法について説明します。 視線追跡が正しく機能するためには、各ユーザーが視線追跡ユーザー調整を行う必要があります。 

![2 m の距離での最適なターゲット サイズ](images/gazetargeting-size-1000px.jpg)<br>
*2メートル距離で最適なターゲットサイズ*

## <a name="calibration"></a>目盛り 
視線追跡を正確に機能させるには、各ユーザーが、一連の holographic ターゲットを確認する必要がある、[目の追跡ユーザーの調整](calibration.md)を行う必要があります。 これにより、デバイスはシステムを調整して、より快適で品質の高い閲覧エクスペリエンスをユーザーに提供し、同時に正確な視点を追跡することができます。 視線追跡はほとんどのユーザーに対して機能しますが、ユーザーが正常に調整できない場合もあります。
調整の詳細については、[調整](calibration.md)を確認してください。

## <a name="eye-gaze-input-design-guidelines"></a>視線入力のデザインガイドライン
高速移動の視点を利用する相互作用を構築するのは困難な場合があります。 このセクションでは、アプリケーションの設計時に考慮する必要がある主な利点と課題をまとめます。 

### <a name="benefits-of-eye-gaze-input"></a>視線入力の利点
- **高速ポインティング。** 視線筋肉は、人間の本文で最も速く反応する筋肉です。 

- **低労力。** 身体の動きがほとんど必要ありません。 

- **暗黙。** 多くの場合、ユーザーによって "覚えている" ことが示されます。ユーザーの目の動きに関する情報によって、ユーザーがどのターゲットに参加するかをシステムが把握できるようになります。 

- **代替入力チャネル。** 視線を使用すると、ユーザーからの手動による調整に基づく長年の経験に基づいて、手書き入力や音声入力に対する強力なサポート入力を提供できます。

- **視覚的注意。** もう1つの重要な利点は、ユーザーがどのようなことに注目しているかを推測できることです。 これは、さまざまなアプリケーション領域において、より効率的なユーザーインターフェイスとリモート通信のためのソーシャルキューの強化を効果的に評価できるようにするために役立ちます。

簡単に言うと、視線を入力として使用することで、高速で簡単なコンテキスト信号を実現できます。 これは、*音声*入力や*手動*入力などの他の入力と組み合わせてユーザーの意図を確認する場合に特に強力です。


### <a name="challenges-of-eye-gaze-as-an-input"></a>入力としての目を見つめた課題
多くの場合、には多くの責任があります。
視線を使用して、スーパーヒーローのようなユーザーエクスペリエンスを実現することができますが、適切に対応できないことを把握しておくことも重要です。 以下では、注意すべきいくつかの*課題*について説明します。また、視線入力を操作するときの対処方法についても説明します。 

- **視線が "常時オン" になってい**ます。目の蓋を開くと、環境内での作業が開始されます。 何かが長すぎると結果が得られない場合は、どのような外観にしても、アクションを誤って発行することになります。
そのため、ターゲットの選択をトリガーするには、*音声コマンド*、*ハンドジェスチャ*、*ボタンクリック*、または拡張熟考を使用して、視線を組み合わせることをお勧めします。
また、このソリューションでは、involuntarily によって何かをトリガーすることなく、ユーザーが自由に検索できるモードを使用することもできます。 また、この問題は、単にターゲットを見ているときにビジュアルと聴覚のフィードバックをデザインする場合にも考慮する必要があります。
一瞬のポップアウト効果やホバー音でユーザーを混乱させないようにしてください。 はらみはキーです。 後で、設計推奨事項について説明するときに、これに関するベスト プラクティスについても説明します。

- **監視と制御**たとえば、壁の写真を正確にためるとします。 写真の縁と周囲を見て、揃っているかどうかを確認します。 次に、画像を移動するための入力として目を見つめて使用する方法を考えてみましょう。 難しいのではないでしょうか。 これは、入力と制御の両方に必要な場合に、視線の2つの役割について説明します。 

- **クリックする前に離れる:** クイックターゲットを選択する場合は、ユーザーの目を見つめていて、手動でクリックする前 (たとえば、放映タップ) に移動できることが調査によって示されています。 そのため、より低速なコントロール入力 (音声、ハンド、コントローラーなど) を使用して、高速の視線信号を同期するには、特別な注意が必要です。

- **小さいターゲット:** 少し小さすぎて読むことができないテキストを読み込んだときに感じていることがわかりますか。 これによって目が疲れてしまうことがあります。目を絞って再調整しようとしているため、疲れてしまうことがあります。
これは、ユーザーが視点を使用してアプリケーションで小さすぎるターゲットを選択する必要がある場合に、ユーザーに対して呼び出す可能性があります。
設計に際しては、ユーザーにとって楽しく快適なエクスペリエンスを作るため、ターゲットを視角で 2 度以上にする (さらに大きい方が好ましい) ことをお勧めします。

- **不規則な視点の移動**この目では、固定から固定への迅速な移動を行います。 記録された目の動きのスキャン パスを見ると、視線が不規則に動いていることがわかります。 視線は、頭の中や*手の動き*と比較して、すばやく、自然*な*ジャンプに移動します。  

- **追跡の信頼性:** 視線追跡の精度は、目が新しい条件に合わせて調整したときのほんの少しの光の変化で低下する可能性があります。
これは必ずしもアプリケーションの設計に影響を与えるわけではありませんが、精度は2°の制限内にあるため、ユーザーが再調整する必要がある場合があります。 


## <a name="design-recommendations"></a>設計の推奨事項
次に示すのは、目を見つめた入力の利点と課題に基づいた、設計に関する特定の推奨事項の一覧です。

1. **視線は、ヘッド見つめと同じではありません。**
    - **高速だが不規則な目の動きが入力タスクに合っているかどうかを検討する:** ビューのフィールド全体でターゲットをすばやく選択すると、高速で不規則な目の動きが非常に優れていますが、smooth input 軌道 (描画や encircling の注釈など) を必要とするタスクには適用できません。 この場合は、手または頭によるポインティングをお勧めします。
  
    - **ユーザーの目を見つめた (スライダーやカーソルなど) に直接接続することは避けてください。**
カーソルの場合は、投影された視線の信号のオフセットがわずかであるため、"fleeing cursor" 効果が生じる可能性があります。 スライダーの場合は、スライダーを目で制御する2つの役割と競合し、オブジェクトが正しい位置にあるかどうかを確認することもできます。 簡単に言うと、ユーザーにとっては特に、ユーザーの信号が不正確になる可能性があります。 
  
2. **視線を他の入力と結合します。** ハンドジェスチャ、音声コマンド、ボタンの押下など、他の入力との視線追跡の統合には、いくつかの利点があります。
    - **自由観察を可能にする:** 私たちの主要な役割は、環境を観察することであるということです。重要なのは、ユーザーが何も (視覚、聴覚などの) フィードバックまたはアクションをトリガーすることなく検索できることです。 
    視線追跡と別の入力コントロールを組み合わせることにより、視線監視と入力制御モードの間でスムーズに遷移できます。
  
    - **強力なコンテキスト プロバイダー:** 音声コマンドを uttering したり、手の形でジェスチャを実行したりしているときに、ユーザーがどこで見ているかについての情報を使用することにより、ビューのフィールド間でシームレスに入力を channeling ことができます。 以下に例を示します。「Put that there (それをあそこに置いて)」と言うときに、単にターゲットと宛先を見るだけで、シーンの中でホログラムを選択して配置する作業を迅速かつ滑らかに行えます。 

    - **マルチモーダル入力を同期する必要性 (「クリック前に離れる」問題):** 長い音声コマンドやハンドジェスチャなど、より複雑な追加入力を使用して迅速な移動を組み合わせることにより、追加の入力コマンドを完了する前に、目を見つめていくリスクが高くなります。 したがって、独自の入力コントロール (カスタムハンドジェスチャなど) を作成する場合は、この入力の先頭またはおおよその期間を記録して、ユーザーが過去に見た内容と関連付けられるようにしてください。
    
3. **視線追跡入力の繊細なフィードバック:** システムが意図したとおりに動作していることを示すためにターゲットを検索するときにフィードバックを提供すると便利ですが、微妙に保つ必要があります。 これには、徐々にブレンドを行う、視覚的に強調表示する、またはターゲットのサイズを少し増やした場合など、他の微妙なターゲットの動作を実行することがありますユーザーの現在のワークフローを不必要に中断しています。 

4. **入力としての不自然な目の動きを強制しない:** アプリケーションのアクションをトリガーするために、ユーザーが特定の目の動き (宝石のジェスチャ) を実行しないようにします。

5. **不正確さを考慮に入れる:** ユーザーにとってわかりやすく、オフセットとジッターという2種類の不正確性を区別します。 オフセットに対処する最も簡単な方法は、操作に十分なサイズのターゲットを提供することです。 2°を超える視覚的な角度を参照として使用することをお勧めします。 たとえば、arm を拡張すると、サムネイルの表示角度が約2°になります。 これが次のガイダンスにつながります。
    - ユーザーが小さいターゲットを選択することを強制しないでください。 ここでは、ターゲットが十分に大きく、システムが適切に設計されている場合に、ユーザーの対話を簡単で魔法のない方法で記述しています。 ターゲットを小さくしすぎると、ユーザーはエクスペリエンスを疲れる、いらだたしいものと表現します。
  
## <a name="dev-guidance-what-if-eye-tracking-is-not-available"></a>開発ガイダンス:視線追跡を利用できない場合はどうすればよいですか。
次のようなさまざまな理由により、アプリが目の追跡データを受信しない場合があります。
* ユーザーが視線追跡の調整をスキップしました。
* ユーザーは調整されましたが、アプリに目の追跡データを使用するアクセス許可を付与しませんでした。
* このユーザーには、システムがまだサポートしていない、固有の眼鏡またはいくつかの目の状態があります。
* 外部要因は、損なわれるの前に髪があることから、HoloLens バイザーや眼鏡での汚れや occlusions の強い日光となど、信頼性の高い視線を追跡します。

アプリ開発者にとって、これは、視線追跡データが使用できないユーザーをサポートする方法を考慮する必要があることを意味します。 次に、視線追跡が利用可能かどうかを検出する方法と、さまざまなアプリケーションで使用できない場合の対処方法について説明します。

### <a name="1-how-to-detect-that-eye-tracking-is-available"></a>1. 視線追跡が使用可能であることを検出する方法
視線追跡データを使用できるかどうかを確認するためのチェックがいくつかあります。 確認...
* ...システムは、視線追跡をまったくサポートしています。 次の*メソッド*を呼び出します。[EyesPose () をサポートします。](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)

* ...ユーザーが調整されています。 次の*プロパティ*を呼び出します。[EyesPose. IsCalibrationValid (Windows)](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)

* ...ユーザーは、目の追跡データを使用するためのアクセス許可をアプリに付与しています。現在の _' GazeInputAccessStatus '_ を取得します。 これを行う方法の例については、「[宝石入力へのアクセスの要求](https://docs.microsoft.com/en-us/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input)」をご覧ください。

さらに、次に説明するように、受信した視線追跡データの更新の間にタイムアウトを追加して、またはそれ以外の方法でヘッドから宝石にフォールバックすることで、目の追跡データが古くなっていないことを確認することもできます。 

前述のように、視線追跡データが使用できない理由はいくつかあります。 一部のユーザーは、目の追跡データへのアクセスを取り消すことを決定した場合がありますが、ユーザーエクスペリエンスの低下によって、視線追跡データへのアクセスを提供しないというプライバシーに対しては、これが意図していない場合があります。 そのため、アプリが目の追跡を使用していて、これがエクスペリエンスの重要な部分である場合は、これをユーザーに明確に伝えることをお勧めします。 アプリケーションの可能性を最大限に活用するために、アプリケーションに対して目の追跡が不可欠である理由をユーザーに通知します (一部の拡張機能を一覧表示することもできます)。これにより、ユーザーがどのような機能を提供しているかを理解するのに役立ちます。 ユーザーが、上のチェックに基づいて目の追跡が機能していない理由を特定し、潜在的な問題の迅速なトラブルシューティングを行うための提案を提供します。 たとえば、システムが目の追跡をサポートしていることを検出できた場合は、ユーザーが調整され、アクセス許可が与えられているにもかかわらず、目の追跡データは表示されません。その場合は、汚れや目の occluded など、その他の問題を指している可能性があります。 注意が必要なのは、目の追跡が機能しないユーザーのまれなケースです。 そのため、では、アプリで目の追跡を有効にするためのアラームを消したり、無効にしたりできるようにすることで、このことを敬意してください。

### <a name="2-fallback-for-apps-using-eye-gaze-as-a-primary-input-pointer"></a>2. プライマリ入力ポインターとして視線を使用するアプリのフォールバック
アプリがポインター入力として視線を使用してシーン全体のホログラムをすばやく選択していても、目の追跡データが使用できない場合は、頭を見つめて、頭を見つめたカーソルを表示し始めることをお勧めします。 切り替えるかどうかを判断するには、タイムアウト (500 ~ 1500 ミリ秒など) を使用することをお勧めします。 これは、システムが短時間の動きやウインクによって追跡が一時的に失われるたびに、カーソルがポップアップされるのを防ぐためです。 Unity 開発者の場合、ヘッドの自動フォールバックは、Mixed Reality Toolkit で既に処理されています。 DirectX 開発者は、このスイッチを自分で処理する必要があります。

### <a name="3-fallback-for-other-eye-tracking-specific-applications"></a>3.その他の視点を特定するアプリケーションのフォールバック
アプリは、赤目を明確にするための特別な方法で、たとえば、アバターの目をアニメーション化したり、視覚的な注意に関する正確な情報に依存して目をヒートマップように調整したりすることができます。 この場合、明確なフォールバックはありません。 視線追跡が使用できない場合は、これらの機能を無効にする必要がある場合があります。 

<br>

このページでは、HoloLens 2 の視線追跡と視線入力の役割を理解するのに役立つ概要が提供されています。 開発を開始するには、 [Unity](https://aka.ms/mrtk-eyes)と、 [DirectX で](gaze-in-directx.md)の視線に関する情報を確認してください。


## <a name="see-also"></a>関連項目
* [DirectX での視線](gaze-in-directx.md)
* [Unity での視線 (Mixed Reality Toolkit)](https://aka.ms/mrtk-eyes)
* [調整](calibration.md)
* [頭の視線入力とコミット](gaze-and-commit.md)
* [手のジェスチャ](gestures.md)
* [音声入力](voice-design.md)
* [モーション コントローラー](motion-controllers.md)
* [快適性](comfort.md)
