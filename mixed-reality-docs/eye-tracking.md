---
title: 視線
description: 視線
author: sostel
ms.author: sostel
ms.date: 04/05/2019
ms.topic: article
keywords: 目の追跡、実際には、入力、目の視線の混在
ms.openlocfilehash: 75cbba9048b620e4b00492ad3f71315fabf86677
ms.sourcegitcommit: f5c1dedb3b9e29f27f627025b9e7613931a7ce18
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 04/27/2019
ms.locfileid: "64581052"
---
# <a name="eye-tracking-on-hololens-2"></a>HoloLens 2 の視線
HoloLens 2 では、まったく新しいレベルのコンテキストと人間にわかり、Holographic 内でのエクスペリエンスに検索内容ユーザーに関する情報を使用しての驚異的な機能を開発者に提供しています。 このページは、さまざまなユース ケースの追跡を目が開発者にできる利用し、目視線入力ベースのユーザー インターフェイスを設計するとき確認する項目の概要を示します。 

## <a name="use-cases"></a>使用事例
追跡の目では、リアルタイムでユーザーを検索する場所を追跡するためにアプリケーションを使用できます。 このセクションでは、いくつかの潜在的なユース ケースと複合現実での視線を可能になる斬新な相互作用について説明します。
始める前に、以下では伝え、 [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)数回興味深く強力な例をいくつかの迅速かつ簡単な目でサポートされているターゲットなどの目の追跡を使用して提供選択と基に、ユーザーを検索する場所にテキストを自動的にスクロールします。 

### <a name="user-intent"></a>ユーザーの意図    
ユーザーを検索する場所に関する情報を提供できる、強力かつ**他の入力のコンテキスト**音声、手、およびコント ローラーなど。
これは、さまざまなタスクを使用できます。
たとえば、これの範囲から迅速かつ容易に**を対象とする**ホログラム見て"select"というだけで、シーンの間で (も参照してください[ヘッド注視し、コミット](gaze-and-commit.md)) 言っておきたい"put この..."、または、ホログラムを配置し、"... とする場所を取り除いた方そういうこと"です。 この例が記載[Mixed Reality Toolkit - 目でサポートされているターゲットを選択](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html)と[混合現実 Toolkit - ターゲットの位置をその目でサポートされている](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html)します。

ユーザーの意図に関する他の例では、embodied 仮想エージェントと対話型ホログラム エンゲージメントを強化するためにユーザーを見て何についての情報を使用してを含めることができます。 たとえば、仮想エージェントが使用可能なオプションを変更でき、現在に基づいてその動作は、コンテンツを表示します。 

### <a name="implicit-actions"></a>暗黙的な操作
暗黙的なアクションのカテゴリは、ユーザーの意図に密接に関連します。
考え方としてはホログラムまたはユーザー インターフェイス要素がやや instinctual も感じられない、まったくなく、システムと対話するように、システムと、ユーザーが同期されているな形で対応します。たとえば、非常に成功した 1 つの例は**目視線入力ベースの自動スクロール**します。 考え方はだけです。ユーザーは、テキストを読み取って、できるだけでを読み続けてください。 テキストは、読み取りフローでユーザーを保持する段階的に移動します。 重要な側面は、対応、ユーザーの読み取り速度へのスクロール速度です。
別の例は**目でサポートされているズームとパン**のユーザーが何かに焦点を合わせてに正確に急降下のように感じることができますが。 ズームをトリガーして、ズームの速度を制御する音声を使用して制御できますまたはコントロールの感情を提供することの重要なは、入力を渡すし、(これは、これらについて以下で設計のガイドラインについて説明されます)、ユーザーの混乱を回避します。 したらズームインすると、ユーザーことができますし、スムーズにに従って、たとえば、面している通り、目視線の先を使用して単純に自分のコンピューターを探索するの。
この種の相互作用のデモの例が記載されて、 [Mixed Reality Toolkit - 目でサポートされているナビゲーション](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html)サンプル。

追加のケースを使用して、_暗黙的なアクション_含めることができます。
- **スマート通知:** これまで取得するが重点を置いて右をポップアップ通知によって嫌がるでしょうか。 ユーザーに注意してくださいの支払いを現在を考慮して、行うことができますより優れた! 表示通知、ユーザーが混乱を避けることを制限し、1 回自動的に消去する検索して現在位置からオフセットが読み取りを終了します。 
- **注意深いホログラム:** 微妙で参照されるときを react ホログラムします。 Blooming 緩やかに変化の花を仮想ペットの開始にさかのぼって確認するまたは長時間にわたるまなざし後に、目視線の先を回避しようとしています。 を少し発光の UI 要素から範囲この可能性があります。 これにより、接続と、アプリで満足度の興味深い意味が提供することがあります。

### <a name="attention-tracking"></a>注意の追跡   
ユーザーを検索する場所に関する情報は、設計の使いやすさを評価して効率的なワーク ストリームで問題を識別するために非常に強力なツールです。 ここまでで、視覚エフェクトと分析の視線はさまざまなアプリケーションの領域での一般的な方法で、既にいます。 HoloLens の 2 3D ホログラムを実際のコンテキスト内に配置し、評価と共にようにこのことを理解する新しいディメンションを提供します。 [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)なログ記録と監視追跡データを読み込み、それらを視覚化する方法の基本的な例を提供します。

この領域では、他のアプリケーションが含まれます。 
-   **リモート監視の視線の先の視覚化:** リモート コラボレーター検索内容にするなどの視覚化を手順が正しく認識され、後にかどうかを確認します。
-   **ユーザーの研究:** 注意追跡は、初心者のエキスパート ユーザーとは、コンテンツや、手の目-調整 (またはメカニズムの動作中の医療データを分析) などの複雑なタスクに視覚的に分析する方法の詳細を使用できます。
-   **トレーニングのシミュレーションとパフォーマンスの監視:** 実践しより効率的に実行フローのボトルネックを識別することによってタスクの実行を最適化します。
-   **評価版ソフトウェア、提供情報および市場調査を設計します。** 視線は、web サイトと製品の設計を評価する市場調査の一般的なツールです。

### <a name="additional-use-cases"></a>追加のユース ケース
- **ゲームの場合:** 優れたオプションがあるたいと思ったでしょうか。 機会になります。 それらでホログラムを levitate します。 レーザー ビーム目から撮影してください。 石に敵を有効にするか、固定します。 建物を探索するのにには、x 線画像構想を使用します。 想像力を上限であります。  

- **表現力豊かなアバターは:** 目を示す必要な情報、ユーザーが現在のアバターの目をアニメーション化する日付を追跡するライブの目を使用して、表現力豊かな 3D アバターで追跡します。 ウインクと点滅を追加することで、複数の表現力も追加されます。 

- **テキストを入力します。** 視線は音声認識または手が使用する便利な場合に特に低エフォート テキスト エントリの興味深い方法としては使用できます。 


## <a name="eye-tracking-api"></a>目追跡 API
目視線の相互作用に関する特定のデザインのガイドラインについて詳細に入る前に、HoloLens 2 の目の追跡ツールを提供する機能を簡単にポイントします。 [目追跡 API](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.eyespose)を通じてアクセス:`Windows.Perception.People.EyesPose`します。 1 つ目の視線の先レイ (視線の先の原点と方向) を開発者に提供します。
目の追跡ツールに関するデータを提供する_30 FPS_します。
予測目視線の先が ca 内に存在します。 1.0-1.5 度、実際の周囲のビジュアルの角度では、ターゲットで検索します。 少し不正確性は、想定どおり、この下限の境界値をいくつかの余白の幅を立てる必要があります。 これについてより下です。 視線を正確に機能、ユーザーの調整の視線を経由する各ユーザーが必要です。 

![2 つのメーター距離にある最適なターゲット サイズ](images/gazetargeting-size-1000px.jpg)<br>
*2 つのメーター距離にある最適なターゲット サイズ*


## <a name="eye-gaze-design-guidelines"></a>目視線の先のデザイン ガイドライン
高速移動の目を対象とするを利用する相互作用の構築は困難なことができます。 このセクションで、主な利点と、アプリを設計するときに考慮に入れての課題を要約します。 

### <a name="benefits-of-eye-gaze-input"></a>視線入力の目の利点
- **高速ポイントしています。** 目の威力は、当社の本文で最速 reacting 威力です。 

- **少ない。** ほとんどの物理的な動きは、必要があります。 

- **Implicitness します。** 多くの場合のようにユーザーが「に注意してください資料」として、ユーザーの目の動作についての情報には、ターゲットと連絡を取るユーザー プランをシステムことができます。 

- **代替の入力チャネル。** 目の視線入力は、手の形と音声入力からのビルド長年の経験、手の目の調整に基づくユーザーの強力なサポートの入力を指定できます。

- **Visual 注意します。** もう 1 つの重要なメリットは、どのようなユーザーが注意を推測することです。 これから詳細はよりスマートなユーザー インターフェイスに役立つようにさまざまなデザインを効果的に評価するまで、さまざまなアプリケーション領域で参照し、リモート通信にソーシャル的な手掛かりが強化されています。

簡単に言うと、目視線の先を使用して入力は、高速で簡単なコンテキスト信号の可能性がある提供していますこれは、他の入力と組み合わせて非常に強力ななど*音声*と*手動*への入力。ユーザーの意図を確認します。


### <a name="challenges-of-eye-gaze-as-an-input"></a>目の課題の視線入力として
電源の多くは、多くの責任には。目視線の先を使用して、superhero ように感じて魔法のようなユーザー エクスペリエンスを作成することが、内容は良くありませんでアカウントにこれを適切に把握しておくがもできます。 以下では、説明*課題*アカウントと目視線入力を使用する場合、その対処方法を考慮します。 

- **目、視線の先が「常時オン」** 目 lids を開く時点目は、環境内の固着の手順を開始します。 すべての対応を紹介しましたので、誤って可能性のあるアクションを発行および検索の時間が長すぎる悲惨な経験では結果は!
目視線の先を組み合わせることをお勧めします。 このため、*音声指示コマンド*、*ジェスチャを渡す*、*ボタンをクリック*またはターゲットの選択範囲をトリガーするドウェルを拡張します。
このソリューションを自由に確認できます膨大な感じのものを誤ってトリガーすることがなくモードもできます。 単にターゲットを見ると、視覚や聴覚的フィードバックを設計するときに、この問題もに考慮する必要があります。
即時のポップアウト効果を使用したユーザーの重荷となって、サウンドのマウス ポインターを移動したりしないでください。 注意が重要です。 設計に関する推奨事項について説明するときのベスト プラクティス下さらにこれを説明します。

- **コントロールと観測**壁に写真を正確に配置するとします。 境界線とも配置を確認するには、その環境を表示します。 ここではその方法を入力として、目視線の先を使用して、画像を移動すると同時にする場合を想像してください。 難しいでしょう。 これにより、両方の入力および制御するために必要な場合に、目の視線入力の double の役割を説明します。 

- **クリックする前に、このままにします。** クイック ターゲットの選択内容の調査によれば、手動のクリックを終える前に、ユーザーの目の視線入力可能性がありますに移動 (airtap など)。 そのため、低速のコントロールの入力 (音声、手、コント ローラーなど) と高速の目の視線入力信号を同期する特別な注意を支払う必要があります。

- **小規模のターゲット:** 少し読み快適に小さすぎるだけテキストを読み取るしようとするは、感情をわかりますか。 優れたフォーカスに目を再調整しようとするため、疲れているとして古いを感じる可能性がありますを目でのこの負担をかけず感じでしょうか。
これは、気を強制的に目を対象とするを使用して、アプリで小さすぎるターゲットを選択するときに、ユーザーに呼び出す可能性があります。
設計には、ユーザーに対しては、快適になり、快適なエクスペリエンスを作成するをお勧めするターゲットでは、可能であれば大きなビジュアルの角度で少なくとも 2 度必要があります。

- **目の視線の動きを不規則**人間の目は固定から固定化迅速な動きを実行します。 記録された目の移動のスキャンのパスを確認する場合、幅合わせしないので、見た目が確認できます。 迅速かつ自然なジャンプで比較する、目が移動*ヘッド注視*または*モーションを渡す*します。  

- **信頼性を追跡するには。** 新しい条件に目を調整するように光を変更するのに視線の精度が少しが低下する可能性があります。
アプリの設計は必ずしもは影響が、精度とする必要があります内に 2 度の上記の制限。 もう 1 つの調整を実行するユーザーが持っている可能性があります。 


### <a name="design-recommendations"></a>設計に関する推奨事項
次に、説明の利点に基づく特定のデザインの推奨事項を一覧表示し、目の課題の視線入力。

1. **目の視線入力! = ヘッド視線の先。**
    - **かどうかまだ高速不規則目の動きに合わせて、入力タスクを検討してください。** 目を高速と不規則な動きが優れたをすばやく、ビューのフィールドの間でのターゲットを選択する (たとえば、描画または注釈を encircling) 滑らかな入力の軌道を必要とするタスクの小さい適用することは。 この場合、手動または先頭を指すことをお勧めします。
  
    - **何かをユーザーの目注視 (スライダーやカーソルなど) に直接アタッチしないようにします。**
カーソルが発生した場合、射影された目視線入力信号にわずかなオフセットにより「勝てないカーソル」効果であります。 スライダーが発生した場合もオブジェクトが、正しい位置にあるかどうかを確認する必要があるときに、目のスライダーを制御するための二重ロールと競合します。 簡単に言うと、ユーザーことがあります迅速にないと思われる圧倒と気が散って、特にかどうか、シグナルそのユーザーの正確です。 
  
2. **目視線の先を他の入力に組み合わせます。** 目の追跡の手のジェスチャ、音声コマンドやボタンの押下などの他の入力との統合には、いくつかの利点があります。
    - **監視を無料で許可します。** いずれかをトリガーすることがなく、少し調べてみるようにする重要な人間の目のメインのロールでは、この環境を監視して、(視覚、音声、...) からのフィードバックやアクション。 
    別の入力コントロールと ET を組み合わせると ET 監視し、入力コントロール モード間でスムーズに移行できます。
  
    - **強力なコンテキスト プロバイダー:** 音声コマンドを uttering 中に、ユーザーが見るまたはビューのフィールドの間で、入力を簡単に道筋では、手のジェスチャを実行する場所に関する情報を使用します。 たとえば、次のものがあります。「追加することがあります」すばやくスムーズ選択し、シーン全体を見ただけで、ターゲットとなる目的でホログラムを配置します。 

    - **マルチ モーダルな入力値 ("leave をクリックする前に"の問題) を同期する必要があります。** 複雑な追加の入力 (長い音声コマンドや手のジェスチャなど) との迅速な目の動きを組み合わせると、入力の追加のコマンドを終了する前に、目視線の先で移動のリスクがあります。 そのため、独自の入力コントロール (カスタムの手のジェスチャなど) を作成する場合にどのようなユーザーいたことに執着して過去に関連付けるこの入力または概数の期間のログに記録することを確認すること。
    
3. **視線入力の微妙なフィードバック:** ターゲット (システムを意図したとおりに動作していることを示します) を考えましたが、微妙に保持する必要があります、フィードバックを提供すると便利です。 緩やかに変化ブレンド/ビジュアルの強調表示出力を含めることも低速のモーションなどの他のターゲットの微妙な動作を実行 (例: 少し増やすターゲット) を示す、システムは、ユーザーは、ターゲットを見ることを正しく検出されるなしで不必要にユーザーの現在のワークフローを中断します。 

4. **不自然な目の動きを適用する入力として使用しないでください。** アクションをトリガーするアプリで特定の目の動き (視線入力ジェスチャ) を実行するユーザーは求めません。

5. **不正確性のアカウント:** 2 種類のユーザーに顕著なである不正確性を識別します。オフセットやジッターします。 アドレス オフセットに最も簡単な方法は、対話する十分な大きさのターゲットを提供することです。 (> 2 度参照として – visual の角度に: arm (1) を拡張する場合は、サムネイル、ビジュアルの角度で約 2 度)。 これは、次のガイダンスにつながります。
    - 小さなターゲットを選択するユーザーは求めません。調査は、ターゲットは、十分な大きさ (および、システムが適切に設計されて) 場合として作業を簡単かつ魔法のような相互作用についてユーザーに説明することが示されています。 ターゲットが小さすぎるになると、ユーザーは辛いものとして、苛立つエクスペリエンスについて説明します。
    
# <a name="eye-gaze-design-guidelines-placeholder"></a>目視線の先のデザイン ガイドライン (プレース ホルダー)

HoloLens 2 では、ヘッド視線の先ではなく目視線の先を使用して高速かつ快適にコミット (&)、視線の先を作成する機会があります。 ただし、目視線の先では、特定の方法でヘッド視線の先をまったく違う方法で動作し、ためさまざまな固有の課題が付属します。 目の視線デザイン ガイドラインは、一般的な長所と holographic アプリでの入力のメディアとして目の追跡を使用するときに考慮する課題を要約します。 このセクションで目視線の先 (&) コミットの特定の設計の考慮事項について説明します。 最初に、人間の目では、非常に高速移動し、そのため、迅速に、ビュー全体を対象とする点で優れています。 これにより、目の視線クイック視線の先に最適です (&)、エア タップやボタンを押してなどの高速コミットと組み合わせたときに特に操作をコミットします。

カーソルを表示しません。対話することはほぼ不可能ヘッドを使用する場合、カーソルなし視線、カーソルは煩雑素早く目視線の先を使用する場合に面倒になります。 ユーザーに通知するためのカーソルではなく視線が動作してが正常かどうかが検出されました現在参照 target、微妙なビジュアルの使用には (詳細については以下) が強調表示します。

微妙なブレンド ホバー フィードバックを作業しています。ヘッド視線入力の優れた視覚的なフィードバックをものと、目視線の先を使用して恐ろしい、圧倒的なの経験があります。 目がきわめて高速で、フィールドからのビュー ポイント間ですばやく darting ことに注意してください。 の検索時にちらつきのフィードバック (オン/オフ) クイック突然強調表示の変更があります。 そのため、ホバー フィードバックを提供するときにスムーズにブレンドで強調表示の使用をお勧めします (およびブレンド アウトご覧にならない場合)。 最初に注意する必要がほとんどフィードバック ターゲットを見たときにこのことを意味します。 500 ~ 1000 ミリ秒の過程で、強調表示は強さの点で向上します。 ターゲット システムのフォーカスがあるターゲットが正しく判断したことを確認するには、初心者のユーザーを検索し続ける可能性があります、中に上級ユーザーでしたすばやく視線 & フィードバックがその最大輝度になるまで待機することがなくコミットします。 さらに、ホバー フィードバック フェードアウトときに blend アウトを使用することもお勧めします。 調査は、モーション センサーとコントラストの簡単な変更が、周辺視野 (ため、場所を確認していない visual フィールドの領域) に非常に顕著なことが示されています。 Blend でとして、低速である、フェードアウトはありません。 これは、強調表示のハイ コントラストまたは色の変更がある場合のみ重要です。 ホバー フィードバックが非常に微妙な始めに場合は、言われなければ気付かない違いです。

注視し、コミットの信号を同期するためになります。入力信号の同期がない可能性がある単純な視線の先 (&)、コミットの課題のため、心配しないでください。 ご確認ください長い音声コマンドまたは複雑な手のジェスチャを含む可能性がありますより複雑なコミット アクションを使用する場合にすべきことです。 ターゲットを確認し、長い音声コマンドを話したを想像してください。 検出すると、システムが必要な時間と話すに必要な時間を考慮アカウントに、目、視線の先が、通常、時間に移動したシーン内のいくつかの新しいターゲット。 そのため、いずれかことをユーザーに、ターゲットでコマンドが認識されている必要がありますまたはコマンドとどのようなユーザー求めていたに当時の始まった時点を決定する方法で入力を処理することがある注意してください。

## <a name="see-also"></a>関連項目
* [視線入力とコミット](gaze-and-commit.md)
* [Head 視線の先を対象とします。](gaze-targeting.md)
* [ジェスチャ](gestures.md)
* [音声設計](voice-design.md)
* [モーション コントローラー](motion-controllers.md)
* [快適性](comfort.md)
