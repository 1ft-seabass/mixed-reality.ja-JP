---
title: 視線追跡
description: HoloLens 2 を使用すると、開発者はユーザーが見ているものについての情報を使用できるので、ホログラフィック エクスペリエンスにおけるコンテキストと人間の理解が大きく進みます。
author: sostel
ms.author: sostel
ms.date: 10/29/2019
ms.topic: article
keywords: 視線追跡、mixed reality、インプット、視線、調整
ms.openlocfilehash: 60de5ceb9f55ca7e2f74856af9bd75567763e382
ms.sourcegitcommit: a5dc182da237f63f0487d40a2e11894027208b6c
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 11/02/2019
ms.locfileid: "73441113"
---
# <a name="eye-tracking-on-hololens-2"></a>HoloLens 2 上の視線追跡

![MRTK の視線追跡デモ](images/mrtk_et_scenemenu.jpg)

HoloLens 2 を使用すると、開発者はユーザーが見ているものについての情報を使用できるので、ホログラフィック エクスペリエンスにおけるコンテキストと人間の理解が大きく進みます。 このページでは、開発者とデザイナーに対するこの新機能の概要を説明します。さまざまなユースケースや基本的な開発者ガイドの視線追跡によってどのようにメリットが得られるかについて説明します。 


## <a name="calibration"></a>目盛り 
視線追跡を正確に機能させるには、各ユーザーが、一連の holographic ターゲットを確認する必要がある、[目の追跡ユーザーの調整](calibration.md)を行う必要があります。 これにより、デバイスはシステムを調整して、より快適で品質の高い閲覧エクスペリエンスをユーザーに提供し、同時に正確な視点を追跡することができます。 視線追跡はほとんどのユーザーに対して機能しますが、ユーザーが正常に調整できない場合もまれにあります。
調整の詳細と、スムーズなエクスペリエンスを保証する方法の詳細については、「[ユーザーの調整](calibration.md)の監視」ページをご覧ください。


## <a name="device-support"></a>デバイスのサポート
<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><strong>機能</strong></td>
     <td><a href="hololens-hardware-details.md"><strong>HoloLens (第 1 世代)</strong></a></td>
     <td><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></td>
     <td><a href="immersive-headset-hardware-details.md"><strong>イマーシブ ヘッドセット</strong></a></td>
</tr>
<tr>
     <td>視線</td>
     <td>❌</td>
     <td>✔️</td>
     <td>❌</td>
</tr>
</table>

## <a name="available-eye-tracking-data"></a>利用可能なアイトラッキングデータ
目を見つめた入力の特定のユースケースについて詳しく説明する前に、HoloLens 2[目の追跡 API](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose)によって提供される機能について簡単に説明します。 開発者は約_30 FPS (30 Hz)_ で、1つの目を見つめた射線 (宝石の出発点と向き) にアクセスできます。
視線追跡データへのアクセス方法の詳細については、「開発者ガイド」を参照してください。 [DirectX での視線](gaze-in-directx.md)と、 [Unity で](https://aka.ms/mrtk-eyes)の視線の使用に関するガイドを参照してください。

予測された視線は、実際のターゲットを中心に約1.5 °の範囲で表示されます (次の図を参照してください)。 わずかな不正確性が想定されているため、開発者はこの下限値の周りにいくらかの余白を計画する必要があります (たとえば、2.0-3.0 度では、より快適なエクスペリエンスが得られる可能性があります)。 以下では、小規模なターゲットの選択に対処する方法について説明します。 視線追跡が正しく機能するためには、各ユーザーが視線追跡ユーザー調整を行う必要があります。 

![2 m の距離での最適なターゲット サイズ](images/gazetargeting-size-1000px.jpg)<br>
*2メートル距離で最適なターゲットサイズ*

<br>

## <a name="use-cases"></a>使用事例
視線追跡を使用すれば、アプリケーションは、ユーザーが見ている場所をリアルタイムで追跡できます。 次のユースケースでは、2つの混合現実の HoloLens 2 での視線追跡によって可能な相互作用について説明します。
これらのユースケースはまだ Holographic シェルエクスペリエンスの一部ではないことに注意してください (つまり、HoloLens 2 を起動したときに表示されるインターフェイス)。
これらの[ツールキット](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)を使用すると、よく見られる簡単なターゲット選択や、テキストベースの自動スクロールなど、視線追跡を使用するためのいくつかの便利で強力な例を提供します。ユーザーが確認できます。 

### <a name="user-intent"></a>ユーザー意図    
ユーザーがどこで見ているかについての情報は、音声、ハンド、コントローラーなど**の他の入力に対し**て強力なコンテキストを提供します。
これは、さまざまなタスクに利用できます。
たとえば、ホログラムを見て *"選択"* ( "選択" とも呼ばれ[ます) を](gaze-and-commit.md)指示するだけで、または "select" を言い、次に *"put this..."* を言い、ホログラムを配置したい*と言います。"* この例は、「[Mixed Reality Toolkit - Eye-supported Target Selection (Mixed Reality Toolkit - 目で支援するターゲット選択)](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html)」と「[Mixed Reality Toolkit - Eye-supported Target Positioning (Mixed Reality Toolkit - 目で支援するターゲット配置)](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html)」に記載されています。

さらに、ユーザーの目的の例として、ユーザーが参照する情報を使用して、埋め込み仮想エージェントや対話型ホログラムによるエンゲージメントを強化することができます。 たとえば、仮想エージェントは、現在表示されているコンテンツに基づいて、使用可能なオプションとその動作を適合させる場合があります。 

### <a name="implicit-actions"></a>暗黙的アクション
暗黙的アクションのカテゴリは、ユーザー意図に密接に関係しています。
考えられるのは、ホログラムまたはユーザーインターフェイスの要素は、ユーザーがシステムと対話しているのではなく、システムとユーザーが同期しているのではなく、instinctual な方法で対応できるということです。一例として、ユーザーがテキストを読み取ったときに自動的にスクロールが開始され、ユーザーがテキストボックスの一番下に移動したときに自動的にスクロールが開始されるような**自動スクロール**があります。  
この重要な点は、スクロール速度がユーザーの読み取り速度に適応することです。
もう1つの例として、視線がサポートされている**ズームとパン**があります。ユーザーは、フォーカスされている内容を正確に把握することができます。 ズームのトリガーとズーム速度の制御は、音声入力または手書き入力によって制御できます。これは、ユーザーがコントロールの感覚を持つことができるようにするために重要です。 これらの設計の考慮事項については、以下で詳しく説明します。 拡大した後、ユーザーは、目を見つめて使用するだけで、自宅などの道をスムーズにたどることができます。
この種の相互作用に関するデモの例は、「[Mixed Reality Toolkit - Eye-supported Navigation (Mixed Reality Toolkit - 目で支援するナビゲーション)](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html)」のサンプルを参照してください。

その他の_暗黙的アクション_の使用事例を以下に示します。
- **スマート通知:** 通知によって annoyed が表示されます。 ユーザーがどのようなことに注目しているかを考慮して、ユーザーが現在使用している場所から通知をオフセットすることで、このエクスペリエンスを向上させることができます。 これにより、取られるが制限され、ユーザーの読み取りが完了すると自動的に破棄されます。 
- **Attentive ホログラム:** Gazed 時に微妙に反応するホログラム。 これは、少し発光した UI 要素、低速の咲きの花から仮想犬までの範囲であり、ユーザーが戻ってきて、その尾を wagging ます。 この相互作用によって、アプリケーションでの接続性と満足度がわかりやすくなる場合があります。

### <a name="attention-tracking"></a>注意追跡   
どのようなユーザーが見ているかについての情報は、設計の使いやすさを評価し、効率的なワークフローの問題を特定するための非常強力なツールです。 さまざまなアプリケーション領域では、視線追跡の視覚化と分析が一般的な方法です。 HoloLens 2 では、このことを理解するために新しいディメンションを提供しています。これは、3D ホログラムを実際のコンテキストで配置し、それに従って評価することができるためです。 [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)には、視線追跡データをログに記録して読み込む方法と、それらを視覚化する方法の基本的な例が用意されています。

この分野の他の適用方法を以下に示します。 
-   **リモートの視線可視化:** リモートコラボレーターが見ていることを視覚化して、共有の理解を深めます。
-   **ユーザー調査研究:** アテンション追跡は、私たちの環境をどのように認識し、どのように連携させるかを理解するのに役立ちます 
-   **トレーニング:** 専門家のビジュアル検索パターンと、医療データを分析したり、運用したりするなどの複雑なタスクについて、専門家のビジュアル検索パターンとそのハンド調整をよりよく理解することにより、初心者のトレーニングが向上しました。
-   **設計の評価と市場調査:** 目の追跡は、web サイトと製品の設計を評価する際に市場調査を行うための一般的なツールです。 HoloLens 2 では、デジタル製品設計のバリエーションを物理環境にマージすることで、これを3D 空間に拡張することができます。 

### <a name="additional-use-cases"></a>その他の使用事例
- **ゲーム:** スーパーパワーが必要でしたか。 こつをお教えしましょう。 ホログラムを levitate することで、ホログラムを作成できます。 お客様の目からレーザービームを撮影してください。 [RoboRaid For HoloLens 2](https://www.microsoft.com/p/roboraid/9nblggh5fv3j)で試してみてください。
敵を石にするか、固定します。 透視能力を使ってビルを探索します。 使い道は想像力次第です。
ユーザーが圧倒されないことに注意してください。詳細については、「[目を見つめた入力のデザインガイドライン](eye-gaze-interaction.md)」を参照してください。

- **表現力のあるアバター:** 視線追跡では、ライブ視線追跡データを使用して、ユーザーがどのようなものかを示すアバターの目をアニメーション化することで、より表現力の高い3D アバターを支援します。 

- **テキスト入力:** 視力の追跡は、特に音声や手の使用が不便な場合に、低労力のテキスト入力の代替手段として使用できます。 

<br>

## <a name="using-eye-gaze-for-interaction"></a>相互作用のための視線の使用
高速移動の視点を利用する相互作用を構築するのは困難な場合があります。
ワンハンドでは、視線入力の使用方法に注意する必要があるほど高速に移動します。そうしないと、ユーザーにとっては膨大な経験や邪魔が見られる可能性があるからです。 一方で、ユーザーに楽しみな気持ちする真のエクスペリエンスを作成することもできます。 詳細については、主な利点、課題、および[相互作用の](eye-gaze-interaction.md)ための視線の設計に関する推奨事項の概要に関する記事をご覧ください。 

<br>
 
## <a name="dev-guidance-what-if-eye-tracking-is-not-available"></a>開発ガイダンス: アイトラッキングを利用できない場合はどうすればよいですか。
次のようなさまざまな理由により、アプリが目の追跡データを受信しない場合があります。
* ユーザーが視線追跡の調整をスキップしました。
* ユーザーは調整されましたが、アプリに目の追跡データを使用するアクセス許可を付与しませんでした。
* このユーザーには、システムがまだサポートしていない、固有の眼鏡またはいくつかの目の状態があります。
* 外部要因は、損なわれるの前に髪があることから、HoloLens バイザーや眼鏡での汚れや occlusions の強い日光となど、信頼性の高い視線を追跡します。

アプリ開発者にとって、これは、視線追跡データが使用できないユーザーをサポートする方法を考慮する必要があることを意味します。 次に、視線追跡が利用可能かどうかを検出する方法と、さまざまなアプリケーションで使用できない場合の対処方法について説明します。

### <a name="1-how-to-detect-that-eye-tracking-is-available"></a>1. 視線追跡が使用可能であることを検出する方法
視線追跡データを使用できるかどうかを確認するためのチェックがいくつかあります。 確認...
* ...システムは、視線追跡をまったくサポートしています。 次の*メソッド*を呼び出します。 [EyesPose ()](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.issupported#Windows_Perception_People_EyesPose_IsSupported)です。

* ...ユーザーが調整されています。 次の*プロパティ*を呼び出します。 [EyesPose. IsCalibrationValid](https://docs.microsoft.com/uwp/api/windows.perception.people.eyespose.iscalibrationvalid#Windows_Perception_People_EyesPose_IsCalibrationValid)

* ...ユーザーは、視線追跡データを使用するためのアクセス許可をアプリに付与しました。現在の _' GazeInputAccessStatus '_ を取得します。 これを行う方法の例については、「[宝石入力へのアクセスの要求](https://docs.microsoft.com/windows/mixed-reality/gaze-in-directX#requesting-access-to-gaze-input)」をご覧ください。

さらに、次に説明するように、受信した視線追跡データの更新の間にタイムアウトを追加して、またはそれ以外の方法でヘッドから宝石にフォールバックすることで、目の追跡データが古くなっていないことを確認することもできます。 

前述のように、視線追跡データが使用できない理由はいくつかあります。 一部のユーザーは、目の追跡データへのアクセスを取り消すことを決定した場合がありますが、ユーザーエクスペリエンスの低下によって、視線追跡データへのアクセスを提供しないというプライバシーに対しては、これが意図していない場合があります。 そのため、アプリが目の追跡を使用していて、これがエクスペリエンスの重要な部分である場合は、これをユーザーに明確に伝えることをお勧めします。 アプリケーションの可能性を最大限に活用するために、アプリケーションに対して目の追跡が不可欠である理由をユーザーに通知します (一部の拡張機能を一覧表示することもできます)。これにより、ユーザーがどのような機能を提供しているかを理解するのに役立ちます。 ユーザーが、上のチェックに基づいて目の追跡が機能していない理由を特定し、潜在的な問題の迅速なトラブルシューティングを行うための提案を提供します。 たとえば、システムが目の追跡をサポートしていることを検出できた場合は、ユーザーが調整され、アクセス許可が与えられているにもかかわらず、目の追跡データは表示されません。その場合は、汚れや目の occluded など、その他の問題を指している可能性があります。 注意が必要なのは、目の追跡が機能しないユーザーのまれなケースです。 そのため、では、アプリで目の追跡を有効にするためのアラームを消したり、無効にしたりできるようにすることで、このことを敬意してください。

### <a name="2-fallback-for-apps-using-eye-gaze-as-a-primary-input-pointer"></a>2. プライマリ入力ポインターとして視線を使用するアプリのフォールバック
アプリがポインター入力として視線を使用してシーン全体のホログラムをすばやく選択していても、目の追跡データが使用できない場合は、頭を見つめて、頭を見つめたカーソルを表示し始めることをお勧めします。 切り替えるかどうかを判断するには、タイムアウト (500 ~ 1500 ミリ秒など) を使用することをお勧めします。 これは、システムが短時間の動きやウインクによって追跡が一時的に失われるたびに、カーソルがポップアップされるのを防ぐためです。 Unity 開発者の場合、ヘッドの自動フォールバックは、Mixed Reality Toolkit で既に処理されています。 DirectX 開発者は、このスイッチを自分で処理する必要があります。

### <a name="3-fallback-for-other-eye-tracking-specific-applications"></a>3. 他の監視に固有のアプリケーションのフォールバック
アプリは、赤目を明確にするための特別な方法で、たとえば、アバターの目をアニメーション化したり、視覚的な注意に関する正確な情報に依存して目をヒートマップように調整したりすることができます。 この場合、明確なフォールバックはありません。 視線追跡が使用できない場合は、これらの機能を無効にする必要がある場合があります。
ここでも、機能が動作していないことを認識していない可能性のあるユーザーに、このことを明確に伝えることをお勧めします。

<br>

このページでは、HoloLens 2 の視線追跡と視線入力の役割を理解するのに役立つ概要が提供されています。 開発を開始するには、ホログラムとの[相互作用のための視線](eye-gaze-interaction.md)の役割についての情報を確認します。また、 [Unity で](https://aka.ms/mrtk-eyes)は目を見つめ、 [DirectX で](gaze-in-directx.md)は目を見つめます。


## <a name="see-also"></a>関連項目
* [調整](calibration.md)
* [快適性](comfort.md)
* [視線に基づく相互作用](eye-gaze-interaction.md)
* [DirectX での視線](gaze-in-directx.md)
* [Unity での視線 (Mixed Reality Toolkit)](https://aka.ms/mrtk-eyes)
* [宝石とコミットメント](gaze-and-commit.md)
* [音声入力](voice-design.md)


