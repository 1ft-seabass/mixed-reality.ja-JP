---
title: 手および DirectX でモーション コント ローラー
description: ネイティブの DirectX アプリで手の形の追跡およびモーションのコント ローラーを使用するための開発者ガイド。
author: caseymeekhof
ms.author: cmeekhof
ms.date: 04/30/2019
ms.topic: article
keywords: ハンド、アニメーション コント ローラー、directx、入力、ホログラム
ms.openlocfilehash: 08666c8c26cd4851c0c003a96a9e96d7a90228ac
ms.sourcegitcommit: 45676da11ebe33a2aa3dccec0e8ad7d714420853
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 05/15/2019
ms.locfileid: "65629645"
---
# <a name="hands-and-motion-controllers-in-directx"></a><span data-ttu-id="365fa-104">手および DirectX でモーション コント ローラー</span><span class="sxs-lookup"><span data-stu-id="365fa-104">Hands and motion controllers in DirectX</span></span>

<span data-ttu-id="365fa-105">Windows Mixed Reality の両方を渡すと[モーションのコント ローラー](motion-controllers.md)で見つかった空間入力 Api を通じて入力を処理、 [Windows.UI.Input.Spatial](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial)名前空間。</span><span class="sxs-lookup"><span data-stu-id="365fa-105">In Windows Mixed Reality, both hand and [motion controller](motion-controllers.md) input is handled through the spatial input APIs, found in the [Windows.UI.Input.Spatial](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial) namespace.</span></span> <span data-ttu-id="365fa-106">などの一般的なアクションを簡単に処理できます**選択**ハンドとアニメーション コント ローラーの両方で同じ方法を押します。</span><span class="sxs-lookup"><span data-stu-id="365fa-106">This enables you to easily handle common actions like **Select** presses the same way across both hands and motion controllers.</span></span>

## <a name="getting-started"></a><span data-ttu-id="365fa-107">概要</span><span class="sxs-lookup"><span data-stu-id="365fa-107">Getting started</span></span>

<span data-ttu-id="365fa-108">Windows Mixed Reality で入力するアクセスの空間、するには、SpatialInteractionManager インターフェイスを起動します。</span><span class="sxs-lookup"><span data-stu-id="365fa-108">To access spatial input in Windows Mixed Reality, start with the SpatialInteractionManager interface.</span></span>  <span data-ttu-id="365fa-109">このインターフェイスを呼び出すことによってアクセスできる[SpatialInteractionManager::GetForCurrentView](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getforcurrentview)、通常は、アプリの起動中のある時点からです。</span><span class="sxs-lookup"><span data-stu-id="365fa-109">You can access this interface by calling  [SpatialInteractionManager::GetForCurrentView](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getforcurrentview), typically sometime during app startup.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

SpatialInteractionManager interactionManager = SpatialInteractionManager::GetForCurrentView();
```

<span data-ttu-id="365fa-110">SpatialInteractionManager のジョブはへのアクセスを提供する[SpatialInteractionSources](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource)入力のソースを表します。</span><span class="sxs-lookup"><span data-stu-id="365fa-110">The SpatialInteractionManager's job is to provide access to [SpatialInteractionSources](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource), which represent a source of input.</span></span>  <span data-ttu-id="365fa-111">SpatialInteractionSources の 3 つの種類は、システムで使用できます。</span><span class="sxs-lookup"><span data-stu-id="365fa-111">There are three kinds of SpatialInteractionSources available in the system.</span></span>
* <span data-ttu-id="365fa-112">**ハンド**検出されたユーザーの手の形を表します。</span><span class="sxs-lookup"><span data-stu-id="365fa-112">**Hand** represents a user's detected hand.</span></span> <span data-ttu-id="365fa-113">手動のソースは、HoloLens の基本的なジェスチャから追跡 HoloLens 2 をすべて連結したものの手に至るまで、デバイスに基づいてさまざまな機能を提供します。</span><span class="sxs-lookup"><span data-stu-id="365fa-113">Hand sources offer different features based on the device, ranging from basic gestures on HoloLens to fully articulated hand tracking on HoloLens 2.</span></span> 
* <span data-ttu-id="365fa-114">**コント ローラー**ペアになっているアニメーション コント ローラーを表します。</span><span class="sxs-lookup"><span data-stu-id="365fa-114">**Controller** represents a paired motion controller.</span></span> <span data-ttu-id="365fa-115">アニメーション コント ローラーには、さまざまな機能を提供できます。</span><span class="sxs-lookup"><span data-stu-id="365fa-115">Motion controllers can offer a variety of capabilities.</span></span>  <span data-ttu-id="365fa-116">例:トリガー、メニュー ボタン、ボタンの把握、タッチパッドおよびサムスティックを選択します。</span><span class="sxs-lookup"><span data-stu-id="365fa-116">For example: Select triggers, Menu buttons, Grasp buttons, touchpads and thumbsticks.</span></span>
* <span data-ttu-id="365fa-117">**音声**システム検出キーワードを言うと、ユーザーの音声を表します。</span><span class="sxs-lookup"><span data-stu-id="365fa-117">**Voice** represents the user's voice speaking system-detected keywords.</span></span> <span data-ttu-id="365fa-118">たとえば、このソースは選択キーを押して挿入し、"Select"、ユーザーの質問されるたびにリリースします。</span><span class="sxs-lookup"><span data-stu-id="365fa-118">For example, this source will inject a Select press and release whenever the user says "Select".</span></span>

<span data-ttu-id="365fa-119">フレームごとのデータ ソースがによって表されるため、 [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate)インターフェイス。</span><span class="sxs-lookup"><span data-stu-id="365fa-119">Per-frame data for a source is represented by the  [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) interface.</span></span> <span data-ttu-id="365fa-120">アプリケーションで、イベント ドリブンまたはポーリング ベースのモデルを使用するかどうかに応じて、このデータにアクセスする 2 つのさまざまな方法はあります。</span><span class="sxs-lookup"><span data-stu-id="365fa-120">There are two different ways to access this data, depending on whether you want to use an event-driven or polling-based model in your application.</span></span>

### <a name="event-driven-input"></a><span data-ttu-id="365fa-121">イベント ドリブンの入力</span><span class="sxs-lookup"><span data-stu-id="365fa-121">Event-driven input</span></span>
<span data-ttu-id="365fa-122">SpatialInteractionManager では、アプリがリッスンできるイベント数を提供します。</span><span class="sxs-lookup"><span data-stu-id="365fa-122">The SpatialInteractionManager provides a number of events that your app can listen for.</span></span>  <span data-ttu-id="365fa-123">例をいくつか含める[SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed)、 [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased)と[SourceUpdated](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated)します。</span><span class="sxs-lookup"><span data-stu-id="365fa-123">A few examples include   [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) and [SourceUpdated](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated).</span></span>

<span data-ttu-id="365fa-124">たとえば、次のコードは、MyApp::OnSourcePressed を呼び出して SourcePressed イベントをイベント ハンドラーをフックします。</span><span class="sxs-lookup"><span data-stu-id="365fa-124">For example, the following code hooks up an event handler called MyApp::OnSourcePressed to the SourcePressed event.</span></span>  <span data-ttu-id="365fa-125">これにより、相互作用のソースの任意の種類の押下を検出するために、アプリができます。</span><span class="sxs-lookup"><span data-stu-id="365fa-125">This allows your app to detect presses on any type of interaction source.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

auto interactionManager = SpatialInteractionManager::GetForCurrentView();
interactionManager.SourcePressed({ this, &MyApp::OnSourcePressed });

```

<span data-ttu-id="365fa-126">押されたこのイベントは、押下の発生時に対応する SpatialInteractionSourceState と共に、非同期的に、アプリに送信されます。</span><span class="sxs-lookup"><span data-stu-id="365fa-126">This pressed event is sent to your app asynchronously, along with the corresponding SpatialInteractionSourceState at the time the press happened.</span></span> <span data-ttu-id="365fa-127">アプリやゲーム エンジンはすぐに、いくつか処理を実行することがあります。 またはルーチンを処理する、入力イベント データをキューに登録することがあります。</span><span class="sxs-lookup"><span data-stu-id="365fa-127">Your app or game engine may want to perform some processing right away or you may want to queue up the event data in your input processing routine.</span></span> <span data-ttu-id="365fa-128">[選択] ボタンが押されたかどうかを確認する方法を示しています、SourcePressed イベントのイベント ハンドラー関数を次に示します。</span><span class="sxs-lookup"><span data-stu-id="365fa-128">Here is an event handler function for the SourcePressed event, which shows how to check whether the select button was pressed.</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

void MyApp::OnSourcePressed(SpatialInteractionManager const& sender, SpatialInteractionSourceEventArgs const& args)
{
    if (args.PressKind() == SpatialInteractionPressKind::Select)
    {
        // Select button was pressed, update app state
    }
}
```

<span data-ttu-id="365fa-129">デバイスのプライマリ アクションに対応する 'Select' を押してのみ、上記のコードをチェックします。</span><span class="sxs-lookup"><span data-stu-id="365fa-129">The above code only checks for the 'Select' press, which corresponds to the primary action on the device.</span></span> <span data-ttu-id="365fa-130">例には、HoloLens で、AirTap またはアニメーション コント ローラーに対してプルをトリガーが含まれます。</span><span class="sxs-lookup"><span data-stu-id="365fa-130">Examples include doing an AirTap on HoloLens or pulling the trigger on a motion controller.</span></span>  <span data-ttu-id="365fa-131">'Select' の押下では、対象とするホログラムをアクティブ化するユーザーの意図を表します。</span><span class="sxs-lookup"><span data-stu-id="365fa-131">'Select' presses represent the user's intention to activate the hologram they are targeting.</span></span>  <span data-ttu-id="365fa-132">SourcePressed イベントが多数のさまざまなボタンとジェスチャの発生し、そのような場合をテストする SpatialInteractionSource の他のプロパティを検査することができます。</span><span class="sxs-lookup"><span data-stu-id="365fa-132">The SourcePressed event will fire for a number of different buttons and gestures, and you can inspect other properties on the SpatialInteractionSource to test for those cases.</span></span>

### <a name="polling-based-input"></a><span data-ttu-id="365fa-133">ポーリング ベースの入力</span><span class="sxs-lookup"><span data-stu-id="365fa-133">Polling-based input</span></span>
<span data-ttu-id="365fa-134">すべてのフレームの入力の現在の状態をポーリングするのに SpatialInteractionManager を使用することもできます。</span><span class="sxs-lookup"><span data-stu-id="365fa-134">You can also use SpatialInteractionManager to poll for the current state of input every frame.</span></span>  <span data-ttu-id="365fa-135">これを行うには、単に呼び出す[GetDetectedSourcesAtTimestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp)すべてのフレーム。</span><span class="sxs-lookup"><span data-stu-id="365fa-135">To do this, simply call [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) every frame.</span></span>  <span data-ttu-id="365fa-136">この関数は、1 つを含む配列を返します[SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate)すべてアクティブ[SpatialInteractionSource](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource)します。</span><span class="sxs-lookup"><span data-stu-id="365fa-136">This function returns an array containing one [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) for every active [SpatialInteractionSource](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span></span> <span data-ttu-id="365fa-137">つまり各モーションのアクティブなコント ローラーの各追跡対象の手および音声の 'select' コマンドが最近に載せた場合です。</span><span class="sxs-lookup"><span data-stu-id="365fa-137">This means one for each active motion controller, one for each tracked hand, and one for speech if a 'select' command was recently uttered.</span></span> <span data-ttu-id="365fa-138">アプリケーションにドライブの入力には、各 SpatialInteractionSourceState のプロパティを検査できます。</span><span class="sxs-lookup"><span data-stu-id="365fa-138">You can then inspect the properties on each SpatialInteractionSourceState to drive input into your application.</span></span> 

<span data-ttu-id="365fa-139">ポーリング メソッドを使用して、'select' アクションを確認する方法の例を次に示します。</span><span class="sxs-lookup"><span data-stu-id="365fa-139">Here is an example of how to check for the 'select' action using the polling method.</span></span> <span data-ttu-id="365fa-140">なお、*予測*変数を表します、 [HolographicFramePrediction](https://docs.microsoft.com/en-us/uwp/api/Windows.Graphics.Holographic.HolographicFramePrediction)オブジェクトから取得できますが、 [HolographicFrame](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe)。</span><span class="sxs-lookup"><span data-stu-id="365fa-140">Note that the *prediction* variable represents a [HolographicFramePrediction](https://docs.microsoft.com/en-us/uwp/api/Windows.Graphics.Holographic.HolographicFramePrediction) object, which can be obtained from the [HolographicFrame](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe).</span></span>

```cpp
using namespace winrt::Windows::UI::Input::Spatial;

auto interactionManager = SpatialInteractionManager::GetForCurrentView();
auto sourceStates = m_spatialInteractionManager.GetDetectedSourcesAtTimestamp(prediction.Timestamp());

for (auto& sourceState : sourceStates)
{
    if (sourceState.IsSelectPressed())
    {
        // Select button is down, update app state
    }
}
```

<span data-ttu-id="365fa-141">各 SpatialInteractionSource が、ID は、新しいソースを特定し、既存のソースのフレーム間を関連付けるために使用することができます。</span><span class="sxs-lookup"><span data-stu-id="365fa-141">Each SpatialInteractionSource has an ID, which you can use to identify new sources and correlate existing sources from frame to frame.</span></span>  <span data-ttu-id="365fa-142">コント ローラーの Id をセッションの期間にわたって静的なままのままにし、FOV を入力するたびに手には、新しい ID が割り当てられます。</span><span class="sxs-lookup"><span data-stu-id="365fa-142">Hands are assigned a new ID every time they leave and enter the FOV, but controller IDs remain static for the duration of the session.</span></span>  <span data-ttu-id="365fa-143">SpatialInteractionManager 上など、イベントを使用できる[SourceDetected](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcedetected)と[SourceLost](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcelost)を手入力するか、デバイスのままにした場合、反応のビュー、またはアニメーション コント ローラーがオン/オフになっているかはペアになっていると対になっていません。</span><span class="sxs-lookup"><span data-stu-id="365fa-143">You can use the events on SpatialInteractionManager such as [SourceDetected](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcedetected) and [SourceLost](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcelost), to react when hands enter or leave the device's view, or when motion controllers are turned on/off or are paired/unpaired.</span></span>

### <a name="predicted-vs-historical-poses"></a><span data-ttu-id="365fa-144">履歴のポーズと予測</span><span class="sxs-lookup"><span data-stu-id="365fa-144">Predicted vs. historical poses</span></span>
<span data-ttu-id="365fa-145">GetDetectedSourcesAtTimestamp がタイムスタンプ パラメーターを持つことに注意してください。</span><span class="sxs-lookup"><span data-stu-id="365fa-145">Note that GetDetectedSourcesAtTimestamp has a timestamp parameter.</span></span> <span data-ttu-id="365fa-146">これにより、要求の状態を引き起こすのか、予測されたデータまたは入力の他のソースと空間的相互作用を関連付ける履歴、こと。</span><span class="sxs-lookup"><span data-stu-id="365fa-146">This enables you to request state and pose data that is either predicted or historical, letting you correlate spatial interactions with other sources of input.</span></span> <span data-ttu-id="365fa-147">たとえば、現在のフレームに手の形の位置を表示するときに渡すことができますによって提供される予測のタイムスタンプで、 [HolographicFrame](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe)します。</span><span class="sxs-lookup"><span data-stu-id="365fa-147">For example, when rendering the hand's position in the current frame, you can pass in the predicted timestamp provided by the [HolographicFrame](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe).</span></span> <span data-ttu-id="365fa-148">これにより、認識される待機時間を最小限に抑え、レンダリングされたフレームの出力に近づけるに手の形の位置を前方予測するシステムです。</span><span class="sxs-lookup"><span data-stu-id="365fa-148">This enables the system to forward-predict the hand position to closely align with the rendered frame output, minimizing perceived latency.</span></span>

<span data-ttu-id="365fa-149">ただし、このような予測の姿勢では、相互作用のソースと対象とするための理想的なポインティング射線は生成されません。</span><span class="sxs-lookup"><span data-stu-id="365fa-149">However, such a predicted pose does not produce an ideal pointing ray for targeting with an interaction source.</span></span> <span data-ttu-id="365fa-150">たとえば、アニメーション コント ローラーのボタンが押されたときに、オペレーティング システムに Bluetooth を通じてバブルアップするには、そのイベントの最大 20 ミリ秒かかることができます。</span><span class="sxs-lookup"><span data-stu-id="365fa-150">For example, when a motion controller button is pressed, it can take up to 20ms for that event to bubble up through Bluetooth to the operating system.</span></span> <span data-ttu-id="365fa-151">同様に、ユーザーが手のジェスチャを実行した後一定の時間はシステムに、ジェスチャと、アプリを検出し、それをポーリングする前に渡すことがあります。</span><span class="sxs-lookup"><span data-stu-id="365fa-151">Similarly, after a user performs a hand gesture, some amount of time may pass before the system detects the gesture and your app then polls for it.</span></span> <span data-ttu-id="365fa-152">状態変更のアプリのポーリング時間では、head と hand ポーズは相互作用が実際には、過去に発生したターゲットに使用されます。</span><span class="sxs-lookup"><span data-stu-id="365fa-152">By the time your app polls for a state change, the head and hand poses used to target that interaction actually happened in the past.</span></span> <span data-ttu-id="365fa-153">GetDetectedSourcesAtTimestamp に現在 HolographicFrame のタイムスタンプを渡すことによって、対象とする場合、姿勢代わりにフォワード予測対象となるターゲット光線にフレームを表示する時に 20 ミリ秒以上を今後なることがあります。</span><span class="sxs-lookup"><span data-stu-id="365fa-153">If you target by passing your current HolographicFrame's timestamp to GetDetectedSourcesAtTimestamp, the pose will instead be forward predicted to the targeting ray at the time the frame will be displayed, which could be more than 20ms in the future.</span></span> <span data-ttu-id="365fa-154">今後この姿勢が適しています。*レンダリング*、相互作用ソースでは、時間の問題がそれにより*を対象とする*、対話ユーザーの対象とすると、過去に発生します。</span><span class="sxs-lookup"><span data-stu-id="365fa-154">This future pose is good for *rendering* the interaction source, but compounds our time problem for *targeting* the interaction, as the user's targeting occurred in the past.</span></span>

<span data-ttu-id="365fa-155">さいわい、 [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed)、 [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased)と[SourceUpdated](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated)イベントは、履歴を提供[状態](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state)に関連付けられています。各入力イベント。</span><span class="sxs-lookup"><span data-stu-id="365fa-155">Fortunately, the [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed), [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) and [SourceUpdated](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourceupdated) events provide the historical [State](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) associated with each input event.</span></span>  <span data-ttu-id="365fa-156">履歴ヘッドと hand ポーズがを通じて使用可能な直接が含まれます[TryGetPointerPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose)、履歴と共に[タイムスタンプ](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.timestamp)このイベントと関連付けるために他の Api に渡すことができます。</span><span class="sxs-lookup"><span data-stu-id="365fa-156">This directly includes the historical head and hand poses available through [TryGetPointerPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose), along with a historical [Timestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.timestamp) that you can pass to other APIs to correlate with this event.</span></span>

<span data-ttu-id="365fa-157">レンダリングおよび手とコント ローラーと各フレームを対象とする場合は、次のベスト プラクティスにつながります。</span><span class="sxs-lookup"><span data-stu-id="365fa-157">That leads to the following best practices when rendering and targeting with hands and controllers each frame:</span></span>
* <span data-ttu-id="365fa-158">**/コント ローラーの手の形のレンダリング**フレームごとに、アプリが**ポーリング**の**前方予測**現在のフレームの photon 時に各操作のソースの問題します。</span><span class="sxs-lookup"><span data-stu-id="365fa-158">For **hand/controller rendering** each frame, your app should **poll** for the **forward-predicted** pose of each interaction source at the current frame’s photon time.</span></span>  <span data-ttu-id="365fa-159">呼び出すことによって相互作用のすべてのソースのポーリング[GetDetectedSourcesAtTimestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp)によって提供される予測のタイムスタンプを渡して、各フレーム[HolographicFrame::CurrentPrediction](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe.currentprediction)します。</span><span class="sxs-lookup"><span data-stu-id="365fa-159">You can poll for all interaction sources by calling [GetDetectedSourcesAtTimestamp](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.getdetectedsourcesattimestamp) each frame, passing in the predicted timestamp provided by [HolographicFrame::CurrentPrediction](https://docs.microsoft.com/en-us/uwp/api/windows.graphics.holographic.holographicframe.currentprediction).</span></span>
* <span data-ttu-id="365fa-160">**手/コント ローラーを対象とする**押されたリリース時にキーを押してまたはリリースでは、アプリが処理する必要があります**イベント**、レイキャストがに基づいて、**履歴**ヘッドまたは手ポーズそのイベント。</span><span class="sxs-lookup"><span data-stu-id="365fa-160">For **hand/controller targeting** upon a press or release, your app should handle pressed/released **events**, raycasting based on the **historical** head or hand pose for that event.</span></span> <span data-ttu-id="365fa-161">処理することによってこのターゲットの射線を取得、 [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed)または[SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased)イベント、取得、[状態](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state)イベントの引数、およびそのを呼び出してからプロパティ[TryGetPointerPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose)メソッド。</span><span class="sxs-lookup"><span data-stu-id="365fa-161">You get this targeting ray by handling the [SourcePressed](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcepressed) or [SourceReleased](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionmanager.sourcereleased) event, getting the [State](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceeventargs.state) property from the event arguments, and then calling its [TryGetPointerPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygetpointerpose) method.</span></span>

## <a name="cross-device-input-properties"></a><span data-ttu-id="365fa-162">デバイス間の入力プロパティ</span><span class="sxs-lookup"><span data-stu-id="365fa-162">Cross-device input properties</span></span>
<span data-ttu-id="365fa-163">SpatialInteractionSource API は、コント ローラーと追跡機能の広範なシステムの手をサポートします。</span><span class="sxs-lookup"><span data-stu-id="365fa-163">The SpatialInteractionSource API supports controllers and hand tracking systems with a wide range of capabilities.</span></span> <span data-ttu-id="365fa-164">これらの機能の数は、デバイスの種類の間で共通です。</span><span class="sxs-lookup"><span data-stu-id="365fa-164">A number of these capabilities are common between device types.</span></span> <span data-ttu-id="365fa-165">たとえば、手追跡とアニメーション コント ローラーの両方は、'select' アクションと 3D の位置を提供します。</span><span class="sxs-lookup"><span data-stu-id="365fa-165">For example, hand tracking and motion controllers both provide a 'select' action and a 3D position.</span></span> <span data-ttu-id="365fa-166">可能な限り、API は、これらの一般的な機能を SpatialInteractionSource で同じプロパティにマップします。</span><span class="sxs-lookup"><span data-stu-id="365fa-166">Wherever possible, the API maps these common capabilities to the same properties on the SpatialInteractionSource.</span></span>  <span data-ttu-id="365fa-167">これによりより簡単にさまざまな入力の種類をサポートするためにアプリケーションができます。</span><span class="sxs-lookup"><span data-stu-id="365fa-167">This enables applications to more easily support a wide range of input types.</span></span> <span data-ttu-id="365fa-168">次の表に、サポートされているプロパティおよび入力の型の間で比較します。</span><span class="sxs-lookup"><span data-stu-id="365fa-168">The following table describes the properties that are supported, and how they compare across input types.</span></span>

| <span data-ttu-id="365fa-169">プロパティ</span><span class="sxs-lookup"><span data-stu-id="365fa-169">Property</span></span> | <span data-ttu-id="365fa-170">説明</span><span class="sxs-lookup"><span data-stu-id="365fa-170">Description</span></span> | <span data-ttu-id="365fa-171">HoloLens Gestures</span><span class="sxs-lookup"><span data-stu-id="365fa-171">HoloLens Gestures</span></span> | <span data-ttu-id="365fa-172">アニメーション コント ローラー</span><span class="sxs-lookup"><span data-stu-id="365fa-172">Motion Controllers</span></span> | <span data-ttu-id="365fa-173">関節手</span><span class="sxs-lookup"><span data-stu-id="365fa-173">Articulated Hands</span></span>|
|--- |--- |--- |--- |--- |
| [<span data-ttu-id="365fa-174">SpatialInteractionSource::**処理**</span><span class="sxs-lookup"><span data-stu-id="365fa-174">SpatialInteractionSource::**Handedness**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.handedness) | <span data-ttu-id="365fa-175">右側または左側にある/コント ローラー。</span><span class="sxs-lookup"><span data-stu-id="365fa-175">Right or left hand / controller.</span></span> | <span data-ttu-id="365fa-176">サポートされない</span><span class="sxs-lookup"><span data-stu-id="365fa-176">Not Supported</span></span> | <span data-ttu-id="365fa-177">サポート対象</span><span class="sxs-lookup"><span data-stu-id="365fa-177">Supported</span></span> | <span data-ttu-id="365fa-178">サポート対象</span><span class="sxs-lookup"><span data-stu-id="365fa-178">Supported</span></span> |
| [<span data-ttu-id="365fa-179">SpatialInteractionSourceState::**IsSelectPressed**</span><span class="sxs-lookup"><span data-stu-id="365fa-179">SpatialInteractionSourceState::**IsSelectPressed**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.isselectpressed) | <span data-ttu-id="365fa-180">主ボタンの現在の状態。</span><span class="sxs-lookup"><span data-stu-id="365fa-180">Current state of the primary button.</span></span> | <span data-ttu-id="365fa-181">エア タップ</span><span class="sxs-lookup"><span data-stu-id="365fa-181">Air Tap</span></span> | <span data-ttu-id="365fa-182">トリガー</span><span class="sxs-lookup"><span data-stu-id="365fa-182">Trigger</span></span> | <span data-ttu-id="365fa-183">厳密でないエア タップ (垂直ピンチ)</span><span class="sxs-lookup"><span data-stu-id="365fa-183">Relaxed Air Tap (upright pinch)</span></span> |
| [<span data-ttu-id="365fa-184">SpatialInteractionSourceState::**IsGrasped**</span><span class="sxs-lookup"><span data-stu-id="365fa-184">SpatialInteractionSourceState::**IsGrasped**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.isgrasped) | <span data-ttu-id="365fa-185">グラブ ボタンの現在の状態。</span><span class="sxs-lookup"><span data-stu-id="365fa-185">Current state of the grab button.</span></span> | <span data-ttu-id="365fa-186">サポートされない</span><span class="sxs-lookup"><span data-stu-id="365fa-186">Not Supported</span></span> | <span data-ttu-id="365fa-187">ボタンを取得します。</span><span class="sxs-lookup"><span data-stu-id="365fa-187">Grab button</span></span> | <span data-ttu-id="365fa-188">ピンチまたは解決済みの手</span><span class="sxs-lookup"><span data-stu-id="365fa-188">Pinch or Closed Hand</span></span> |
| [<span data-ttu-id="365fa-189">SpatialInteractionSourceState::**IsMenuPressed**</span><span class="sxs-lookup"><span data-stu-id="365fa-189">SpatialInteractionSourceState::**IsMenuPressed**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.ismenupressed) | <span data-ttu-id="365fa-190">メニュー ボタンの現在の状態。</span><span class="sxs-lookup"><span data-stu-id="365fa-190">Current state of the menu button.</span></span>    | <span data-ttu-id="365fa-191">サポートされない</span><span class="sxs-lookup"><span data-stu-id="365fa-191">Not Supported</span></span> | <span data-ttu-id="365fa-192">メニュー ボタン</span><span class="sxs-lookup"><span data-stu-id="365fa-192">Menu Button</span></span> | <span data-ttu-id="365fa-193">サポートされない</span><span class="sxs-lookup"><span data-stu-id="365fa-193">Not Supported</span></span> |
| [<span data-ttu-id="365fa-194">SpatialInteractionSourceLocation::**位置**</span><span class="sxs-lookup"><span data-stu-id="365fa-194">SpatialInteractionSourceLocation::**Position**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation.position) | <span data-ttu-id="365fa-195">コント ローラーの手動またはグリップ位置の位置を XYZ します。</span><span class="sxs-lookup"><span data-stu-id="365fa-195">XYZ location of the hand or grip position on the controller.</span></span> | <span data-ttu-id="365fa-196">Palm 場所</span><span class="sxs-lookup"><span data-stu-id="365fa-196">Palm location</span></span> | <span data-ttu-id="365fa-197">グリップの姿勢位置</span><span class="sxs-lookup"><span data-stu-id="365fa-197">Grip pose position</span></span> | <span data-ttu-id="365fa-198">Palm 場所</span><span class="sxs-lookup"><span data-stu-id="365fa-198">Palm location</span></span> |
| [<span data-ttu-id="365fa-199">SpatialInteractionSourceLocation::**向き**</span><span class="sxs-lookup"><span data-stu-id="365fa-199">SpatialInteractionSourceLocation::**Orientation**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation.orientation) | <span data-ttu-id="365fa-200">コント ローラーの手動またはグリップ姿勢の方向を表す四元数。</span><span class="sxs-lookup"><span data-stu-id="365fa-200">Quaternion representing the orientation of the hand or grip pose on the controller.</span></span> | <span data-ttu-id="365fa-201">サポートされない</span><span class="sxs-lookup"><span data-stu-id="365fa-201">Not Supported</span></span> | <span data-ttu-id="365fa-202">グリップの姿勢向き</span><span class="sxs-lookup"><span data-stu-id="365fa-202">Grip pose orientation</span></span> | <span data-ttu-id="365fa-203">Palm 向き</span><span class="sxs-lookup"><span data-stu-id="365fa-203">Palm orientation</span></span> |
| [<span data-ttu-id="365fa-204">SpatialPointerInteractionSourcePose::**位置**</span><span class="sxs-lookup"><span data-stu-id="365fa-204">SpatialPointerInteractionSourcePose::**Position**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialpointerinteractionsourcepose.position#Windows_UI_Input_Spatial_SpatialPointerInteractionSourcePose_Position) | <span data-ttu-id="365fa-205">ポインティング射線の原点。</span><span class="sxs-lookup"><span data-stu-id="365fa-205">Origin of the pointing ray.</span></span> | <span data-ttu-id="365fa-206">サポートされない</span><span class="sxs-lookup"><span data-stu-id="365fa-206">Not Supported</span></span> | <span data-ttu-id="365fa-207">サポート対象</span><span class="sxs-lookup"><span data-stu-id="365fa-207">Supported</span></span> | <span data-ttu-id="365fa-208">サポート対象</span><span class="sxs-lookup"><span data-stu-id="365fa-208">Supported</span></span> |
| [<span data-ttu-id="365fa-209">SpatialPointerInteractionSourcePose::**ForwardDirection**</span><span class="sxs-lookup"><span data-stu-id="365fa-209">SpatialPointerInteractionSourcePose::**ForwardDirection**</span></span>](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialpointerinteractionsourcepose.forwarddirection#Windows_UI_Input_Spatial_SpatialPointerInteractionSourcePose_ForwardDirection) | <span data-ttu-id="365fa-210">ポインティング射線の方向です。</span><span class="sxs-lookup"><span data-stu-id="365fa-210">Direction of the pointing ray.</span></span> | <span data-ttu-id="365fa-211">サポートされない</span><span class="sxs-lookup"><span data-stu-id="365fa-211">Not Supported</span></span> | <span data-ttu-id="365fa-212">サポート対象</span><span class="sxs-lookup"><span data-stu-id="365fa-212">Supported</span></span> | <span data-ttu-id="365fa-213">サポート対象</span><span class="sxs-lookup"><span data-stu-id="365fa-213">Supported</span></span> |

<span data-ttu-id="365fa-214">上記のプロパティの一部は、すべてのデバイスで使用できませんし、API がこれをテストするための手段を提供します。</span><span class="sxs-lookup"><span data-stu-id="365fa-214">Some of the above properties are not available on all devices, and the API provides a means to test for this.</span></span> <span data-ttu-id="365fa-215">たとえば、検査することができます、 [SpatialInteractionSource::IsGraspSupported](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.isgraspsupported)プロパティ ソースが理解アクションを提供するかどうかを判断します。</span><span class="sxs-lookup"><span data-stu-id="365fa-215">For example, you can inspect the [SpatialInteractionSource::IsGraspSupported](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.isgraspsupported) property to determine whether the source provides a grasp action.</span></span>

### <a name="grip-pose-vs-pointing-pose"></a><span data-ttu-id="365fa-216">グリップの姿勢ポインティング ポーズとの比較</span><span class="sxs-lookup"><span data-stu-id="365fa-216">Grip pose vs. pointing pose</span></span>

<span data-ttu-id="365fa-217">Windows Mixed Reality は、さまざまなフォーム ファクターでモーションのコント ローラーをサポートします。</span><span class="sxs-lookup"><span data-stu-id="365fa-217">Windows Mixed Reality supports motion controllers in a variety of form factors.</span></span>  <span data-ttu-id="365fa-218">追跡システム関節手の形もサポートしています。</span><span class="sxs-lookup"><span data-stu-id="365fa-218">It also supports articulated hand tracking systems.</span></span>  <span data-ttu-id="365fa-219">これらすべてのシステムは、手の形の位置とアプリがユーザーの手でポイントまたは rendreing オブジェクトを使用する自然な「前」方向の別のリレーションシップを持ちます。</span><span class="sxs-lookup"><span data-stu-id="365fa-219">All of these systems have different relationships between the hand position and the natural "forward" direction that apps should use for pointing or rendreing objects in the user's hand.</span></span>  <span data-ttu-id="365fa-220">このすべてをサポートするには、両方手の形の追跡、およびモーションのコント ローラーに指定された 3D ポーズの 2 つの種類があります。</span><span class="sxs-lookup"><span data-stu-id="365fa-220">To support all of this, there are two types of 3D poses provided for both hand tracking and motion controllers.</span></span>  <span data-ttu-id="365fa-221">最初は、ユーザーの手の形の位置を表すグリップ ポーズです。</span><span class="sxs-lookup"><span data-stu-id="365fa-221">The first is grip pose, which represents the user's hand position.</span></span>  <span data-ttu-id="365fa-222">2 つ目の姿勢で、ユーザーの手の形またはコント ローラーから送信されたポインティング光線を表しますが指しています。</span><span class="sxs-lookup"><span data-stu-id="365fa-222">The second is pointing pose, which represents a pointing ray originating from the user's hand or controller.</span></span> <span data-ttu-id="365fa-223">したがって、表示する場合**ユーザーの手**または**オブジェクトは、ユーザーの手の形で保持されている**剣またはガン、グリップ姿勢を使用するなど、します。</span><span class="sxs-lookup"><span data-stu-id="365fa-223">So, if you want to render **the user's hand** or **an object held in the user's hand**, such as a sword or gun, use the grip pose.</span></span> <span data-ttu-id="365fa-224">コント ローラーまたは例では、ユーザーが手の形から raycast したい場合**UI でポイント**、ポインティングの姿勢を使用します。</span><span class="sxs-lookup"><span data-stu-id="365fa-224">If you want to raycast from the controller or hand, for example when the user is **pointing at UI** , use the pointing pose.</span></span>

<span data-ttu-id="365fa-225">アクセスできる、**グリップ姿勢**を通じて[SpatialInteractionSourceState::Properties::TryGetLocation(...)](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceproperties.trygetlocation#Windows_UI_Input_Spatial_SpatialInteractionSourceProperties_TryGetLocation_Windows_Perception_Spatial_SpatialCoordinateSystem_).次のように定義されます。</span><span class="sxs-lookup"><span data-stu-id="365fa-225">You can access the **grip pose** through [SpatialInteractionSourceState::Properties::TryGetLocation(...)](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourceproperties.trygetlocation#Windows_UI_Input_Spatial_SpatialInteractionSourceProperties_TryGetLocation_Windows_Perception_Spatial_SpatialCoordinateSystem_).  It is defined as follows:</span></span>
* <span data-ttu-id="365fa-226">**位置を握って**:Palm 重心当然ながら、コント ローラーを保持しているときに、左または右中央にグリップ内の位置を調整します。</span><span class="sxs-lookup"><span data-stu-id="365fa-226">The **grip position**: The palm centroid when holding the controller naturally, adjusted left or right to center the position within the grip.</span></span>
* <span data-ttu-id="365fa-227">**向きの適切な軸を握って**:5 本の指フラットな姿勢を形成する完全に開くと、射線は、palm に通常 (順方向から左 palm、適切な palm から旧バージョンとの)</span><span class="sxs-lookup"><span data-stu-id="365fa-227">The **grip orientation's Right axis**: When you completely open your hand to form a flat 5-finger pose, the ray that is normal to your palm (forward from left palm, backward from right palm)</span></span>
* <span data-ttu-id="365fa-228">**向きの順方向軸を握って**:部分的に (場合と同様、コント ローラーを保持している) の手の閉じるときに、"forward"チューブを通じて非 thumb 指によって形成されるポイントの半径。</span><span class="sxs-lookup"><span data-stu-id="365fa-228">The **grip orientation's Forward axis**: When you close your hand partially (as if holding the controller), the ray that points "forward" through the tube formed by your non-thumb fingers.</span></span>
* <span data-ttu-id="365fa-229">**軸の向きを握って**:右と前方参照の定義が含まれるアップ軸。</span><span class="sxs-lookup"><span data-stu-id="365fa-229">The **grip orientation's Up axis**: The Up axis implied by the Right and Forward definitions.</span></span>

<span data-ttu-id="365fa-230">アクセスできる、**ポインター姿勢**を通じて[SpatialInteractionSourceState::Properties::TryGetLocation (...):: SourcePointerPose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation#Windows_UI_Input_Spatial_SpatialInteractionSourceLocation_SourcePointerPose)または[SpatialInteractionSourceState:。TryGetPointerPose (...):: TryGetInteractionSourcePose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialpointerpose#Windows_UI_Input_Spatial_SpatialPointerPose_TryGetInteractionSourcePose_Windows_UI_Input_Spatial_SpatialInteractionSource_)します。</span><span class="sxs-lookup"><span data-stu-id="365fa-230">You can access the **pointer pose** through [SpatialInteractionSourceState::Properties::TryGetLocation(...)::SourcePointerPose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractionsourcelocation#Windows_UI_Input_Spatial_SpatialInteractionSourceLocation_SourcePointerPose) or [SpatialInteractionSourceState::TryGetPointerPose(...)::TryGetInteractionSourcePose](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialpointerpose#Windows_UI_Input_Spatial_SpatialPointerPose_TryGetInteractionSourcePose_Windows_UI_Input_Spatial_SpatialInteractionSource_).</span></span>

## <a name="controller-specific-input-properties"></a><span data-ttu-id="365fa-231">コント ローラーに固有の入力プロパティ</span><span class="sxs-lookup"><span data-stu-id="365fa-231">Controller-specific input properties</span></span>
<span data-ttu-id="365fa-232">SpatialInteractionSource では、コント ローラーの追加機能を備えたコント ローラー プロパティがあります。</span><span class="sxs-lookup"><span data-stu-id="365fa-232">For controllers, the SpatialInteractionSource has a Controller property with additional capabilities.</span></span>
* <span data-ttu-id="365fa-233">**HasThumbstick:** True の場合、コント ローラーは、スティックが。</span><span class="sxs-lookup"><span data-stu-id="365fa-233">**HasThumbstick:** If true, the controller has a thumbstick.</span></span> <span data-ttu-id="365fa-234">検査、 [ControllerProperties](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractioncontrollerproperties)スティックを取得する SpatialInteractionSourceState のプロパティ x と y 値 (ThumbstickX および ThumbstickY)、ほかの押された状態 (IsThumbstickPressed)。</span><span class="sxs-lookup"><span data-stu-id="365fa-234">Inspect the [ControllerProperties](https://docs.microsoft.com/uwp/api/windows.ui.input.spatial.spatialinteractioncontrollerproperties) property of the SpatialInteractionSourceState to acquire the thumbstick x and y values (ThumbstickX and ThumbstickY), as well as its pressed state (IsThumbstickPressed).</span></span>
* <span data-ttu-id="365fa-235">**HasTouchpad:** True の場合、コント ローラーがタッチパッドにします。</span><span class="sxs-lookup"><span data-stu-id="365fa-235">**HasTouchpad:** If true, the controller has a touchpad.</span></span> <span data-ttu-id="365fa-236">タッチパッドの取得を SpatialInteractionSourceState の ControllerProperties プロパティを検査する x および y 値 (TouchpadX および TouchpadY) と、ユーザーが (IsTouchpadTouched) パッドをタッチし、(ダウン タッチパッドを押して、場合を把握するにはIsTouchpadPressed)。</span><span class="sxs-lookup"><span data-stu-id="365fa-236">Inspect the ControllerProperties property of the SpatialInteractionSourceState to acquire the touchpad x and y values (TouchpadX and TouchpadY), and to know if the user is touching the pad (IsTouchpadTouched) and if they are pressing the touchpad down (IsTouchpadPressed).</span></span>
* <span data-ttu-id="365fa-237">**SimpleHapticsController:** コント ローラーの SimpleHapticsController API では、コント ローラーの haptics 機能を検査でき、ハプティクス フィードバックを制御することもできます。</span><span class="sxs-lookup"><span data-stu-id="365fa-237">**SimpleHapticsController:** The SimpleHapticsController API for the controller allows you to inspect the haptics capabilities of the controller, and it also allows you to control haptic feedback.</span></span>

<span data-ttu-id="365fa-238">タッチパッドとスティックの範囲が (下から上、および左から右へ) を両方の軸の 1 に-1 であることに注意してください。</span><span class="sxs-lookup"><span data-stu-id="365fa-238">Note that the range for touchpad and thumbstick is -1 to 1 for both axes (from bottom to top, and from left to right).</span></span> <span data-ttu-id="365fa-239">SpatialInteractionSourceState::SelectPressedValue プロパティを使用してアクセスは、アナログのトリガーの範囲には、0 ~ 1 の範囲が含まれています。</span><span class="sxs-lookup"><span data-stu-id="365fa-239">The range for the analog trigger, which is accessed using the SpatialInteractionSourceState::SelectPressedValue property, has a range of 0 to 1.</span></span> <span data-ttu-id="365fa-240">値を true に等しくなる IsSelectPressed と 1 つ関連付けますその他の値を false に等しくなる IsSelectPressed で相互に関連付けます。</span><span class="sxs-lookup"><span data-stu-id="365fa-240">A value of 1 correlates with IsSelectPressed being equal to true; any other value correlates with IsSelectPressed being equal to false.</span></span>

## <a name="articulated-hand-tracking"></a><span data-ttu-id="365fa-241">追跡関節手</span><span class="sxs-lookup"><span data-stu-id="365fa-241">Articulated hand tracking</span></span>
<span data-ttu-id="365fa-242">Windows Mixed Reality API では、追跡、たとえば HoloLens 2 で連結したものを完全にサポートを提供します。</span><span class="sxs-lookup"><span data-stu-id="365fa-242">The Windows Mixed Reality API provides full support for articulated hand tracking, for example on HoloLens 2.</span></span> <span data-ttu-id="365fa-243">追跡関節手の形は、アプリケーションで直接操作し、入力モデルをポイントし、コミットを実装するために使用できます。</span><span class="sxs-lookup"><span data-stu-id="365fa-243">Articulated hand tracking can be used to implement direct manipulation and point-and-commit input models in your applications.</span></span> <span data-ttu-id="365fa-244">完全カスタムのインタラクティビティの作成に使用できます。</span><span class="sxs-lookup"><span data-stu-id="365fa-244">It can also be used to author fully custom interactions.</span></span>

### <a name="hand-skeleton"></a><span data-ttu-id="365fa-245">手の形のスケルトン</span><span class="sxs-lookup"><span data-stu-id="365fa-245">Hand skeleton</span></span>
<span data-ttu-id="365fa-246">追跡関節手の形では、により、さまざまな種類の相互作用の 25 の共通スケルトンを提供します。</span><span class="sxs-lookup"><span data-stu-id="365fa-246">Articulated hand tracking provides a 25 joint skeleton that enables many different types of interactions.</span></span>  <span data-ttu-id="365fa-247">スケルトンでは、インデックス/中間/リング/ほとんど本の指の 5 つの結合、つまみについては 4 つの結合および共同 1 手首を提供します。</span><span class="sxs-lookup"><span data-stu-id="365fa-247">The skeleton provides 5 joints for the index/middle/ring/little fingers, 4 joints for the thumb, and 1 wrist joint.</span></span>  <span data-ttu-id="365fa-248">手首ジョイントは、階層の基本として機能します。</span><span class="sxs-lookup"><span data-stu-id="365fa-248">The wrist joint serves as the base of the hierarchy.</span></span> <span data-ttu-id="365fa-249">次の図は、スケルトンのレイアウトを示しています。</span><span class="sxs-lookup"><span data-stu-id="365fa-249">The following picture illustrates the layout of the skeleton.</span></span>

![手の形のスケルトン](images/hand-skeleton.png)

<span data-ttu-id="365fa-251">ほとんどの場合、それが表すボーンに基づいて各ジョイントがという名前です。</span><span class="sxs-lookup"><span data-stu-id="365fa-251">In most cases, each joint is named based on the bone that it represents.</span></span>  <span data-ttu-id="365fa-252">すべての共同で 2 つのボーンがあるので、その位置に子ボーンに基づいて各ジョイント名前付け規則を使用します。</span><span class="sxs-lookup"><span data-stu-id="365fa-252">Since there are two bones at every joint, we use a convention of naming each joint based on the child bone at that location.</span></span>  <span data-ttu-id="365fa-253">子ボーンは、ボーン手首からかけ離れたものとして定義されます。</span><span class="sxs-lookup"><span data-stu-id="365fa-253">The child bone is defined as the bone further from the wrist.</span></span>  <span data-ttu-id="365fa-254">たとえば、「インデックス位」共同が含まれています、インデックスの位ボーンの開始位置とそのボーンの方向。</span><span class="sxs-lookup"><span data-stu-id="365fa-254">For example, the "Index Proximal" joint contains the beginning position of the index proximal bone, and the orientation of that bone.</span></span>  <span data-ttu-id="365fa-255">ボーンの終了位置は含まれません。</span><span class="sxs-lookup"><span data-stu-id="365fa-255">It does not contain the ending position of the bone.</span></span>  <span data-ttu-id="365fa-256">必要がある場合はから取得して、[次へ]、階層、「インデックス中間」共同で結合。</span><span class="sxs-lookup"><span data-stu-id="365fa-256">If you need that, you'd get it from the next joint in the hierarchy, the "Index Intermediate" joint.</span></span>

<span data-ttu-id="365fa-257">25 の階層的な結合だけでなく、システムは、palm ジョイントを提供します。</span><span class="sxs-lookup"><span data-stu-id="365fa-257">In addition to the 25 hierarchical joints, the system provides a palm joint.</span></span>  <span data-ttu-id="365fa-258">片手で行うことはない通常の一部と見なさ骨組みです。</span><span class="sxs-lookup"><span data-stu-id="365fa-258">The palm is not typically considered part of the skeletal structure.</span></span>  <span data-ttu-id="365fa-259">手の全体的な位置と向きを取得する便利な手段としてのみ提供されます。</span><span class="sxs-lookup"><span data-stu-id="365fa-259">It is provided only as a convenient way to get the hand's overall position and orientation.</span></span>

<span data-ttu-id="365fa-260">次の情報は、共同の各提供されます。</span><span class="sxs-lookup"><span data-stu-id="365fa-260">The following information is provided for each joint:</span></span>

| <span data-ttu-id="365fa-261">名前</span><span class="sxs-lookup"><span data-stu-id="365fa-261">Name</span></span> | <span data-ttu-id="365fa-262">説明</span><span class="sxs-lookup"><span data-stu-id="365fa-262">Description</span></span> |
|--- |--- |
|<span data-ttu-id="365fa-263">位置</span><span class="sxs-lookup"><span data-stu-id="365fa-263">Position</span></span> | <span data-ttu-id="365fa-264">ジョイントは、要求されたすべての座標システムで使用できるの 3D の位置。</span><span class="sxs-lookup"><span data-stu-id="365fa-264">3D position of the joint, available in any requested coordinate system.</span></span> |
|<span data-ttu-id="365fa-265">方向</span><span class="sxs-lookup"><span data-stu-id="365fa-265">Orientation</span></span> | <span data-ttu-id="365fa-266">すべてで利用可能、ボーンの 3D の方向は、座標系を要求します。</span><span class="sxs-lookup"><span data-stu-id="365fa-266">3D orientation of the bone, available in any requested coordinate system.</span></span> |
|<span data-ttu-id="365fa-267">半径</span><span class="sxs-lookup"><span data-stu-id="365fa-267">Radius</span></span> | <span data-ttu-id="365fa-268">共同の位置にあるスキンの画面までの距離。</span><span class="sxs-lookup"><span data-stu-id="365fa-268">Distance to surface of the skin at the joint position.</span></span> <span data-ttu-id="365fa-269">直接の対話、または本の指の幅に依存する視覚エフェクトをチューニングするために便利です。</span><span class="sxs-lookup"><span data-stu-id="365fa-269">Useful for tuning direct interactions or visualizations that rely on finger width.</span></span> |
|<span data-ttu-id="365fa-270">正確性</span><span class="sxs-lookup"><span data-stu-id="365fa-270">Accuracy</span></span> | <span data-ttu-id="365fa-271">この共同の情報について、システムの感覚を取ってにヒントを提供します。</span><span class="sxs-lookup"><span data-stu-id="365fa-271">Provides a hint on how confident the system feels about this joint's information.</span></span> |

<span data-ttu-id="365fa-272">関数を使用手の形のスケルトン データにアクセスすることができます、 [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate)します。</span><span class="sxs-lookup"><span data-stu-id="365fa-272">You can access the hand skeleton data through a function on the [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>  <span data-ttu-id="365fa-273">関数を呼び出す[TryGetHandPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygethandpose#Windows_UI_Input_Spatial_SpatialInteractionSourceState_TryGetHandPose)と呼ばれるオブジェクトを返すと[HandPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose)します。</span><span class="sxs-lookup"><span data-stu-id="365fa-273">The function is called [TryGetHandPose](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate.trygethandpose#Windows_UI_Input_Spatial_SpatialInteractionSourceState_TryGetHandPose), and it returns an object called [HandPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose).</span></span>  <span data-ttu-id="365fa-274">ソースが思い起こさせます手をサポートしていない場合、この関数は null を返します。</span><span class="sxs-lookup"><span data-stu-id="365fa-274">If the source does not support articulated hands, then this function will return null.</span></span>  <span data-ttu-id="365fa-275">呼び出して共同の現在のデータを取得するには、HandPose したら、 [TryGetJoint](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose.trygetjoint#Windows_Perception_People_HandPose_TryGetJoint_Windows_Perception_Spatial_SpatialCoordinateSystem_Windows_Perception_People_HandJointKind_Windows_Perception_People_JointPose__)、関心がジョイントの名前に置き換えます。</span><span class="sxs-lookup"><span data-stu-id="365fa-275">Once you have a HandPose, you can get current joint data by calling [TryGetJoint](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose.trygetjoint#Windows_Perception_People_HandPose_TryGetJoint_Windows_Perception_Spatial_SpatialCoordinateSystem_Windows_Perception_People_HandJointKind_Windows_Perception_People_JointPose__), with the name of the joint you are interested in.</span></span>  <span data-ttu-id="365fa-276">として、データが返されます、 [JointPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.jointpose)構造体。</span><span class="sxs-lookup"><span data-stu-id="365fa-276">The data is returned as a [JointPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.jointpose) structure.</span></span>  <span data-ttu-id="365fa-277">次のコードでは、人差し指先端の位置を取得します。</span><span class="sxs-lookup"><span data-stu-id="365fa-277">The following code gets the position of the index finger tip.</span></span> <span data-ttu-id="365fa-278">変数*currentState*のインスタンスを表します[SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate)します。</span><span class="sxs-lookup"><span data-stu-id="365fa-278">The variable *currentState* represents an instance of [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>

```cpp
using namespace winrt::Windows::Perception::People;
using namespace winrt::Windows::Foundation::Numerics;

auto handPose = currentState.TryGetHandPose();
if (handPose)
{
    JointPose joint;
    if (handPose.TryGetJoint(desiredCoordinateSystem, HandJointKind::IndexTip, joint))
    {
        float3 indexTipPosition = joint.Position;

        // Do something with the index tip position
    }
}
```

### <a name="hand-mesh"></a><span data-ttu-id="365fa-279">手の形メッシュ</span><span class="sxs-lookup"><span data-stu-id="365fa-279">Hand mesh</span></span>

<span data-ttu-id="365fa-280">API の追跡、連結したものを手動で完全に変形可能な三角形の手の形メッシュはできます。</span><span class="sxs-lookup"><span data-stu-id="365fa-280">The articulated hand tracking API allows for a fully deformable triangle hand mesh.</span></span>  <span data-ttu-id="365fa-281">このメッシュでは、手の形のスケルトンとリアルタイムで変形できるし、は高度な物理学の手法と同様に視覚エフェクトに便利です。</span><span class="sxs-lookup"><span data-stu-id="365fa-281">This mesh can deform in real time along with the hand skeleton, and is useful for visualization as well as advanced physics techniques.</span></span>  <span data-ttu-id="365fa-282">手の形メッシュにアクセスするには、最初に作成する必要があります、 [HandMeshObserver](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver)オブジェクトを呼び出すことによって[TryCreateHandMeshObserverAsync](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.trycreatehandmeshobserverasync)上、 [SpatialInteractionSource](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource)します。</span><span class="sxs-lookup"><span data-stu-id="365fa-282">To access the hand mesh, you need to first create a [HandMeshObserver](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver) object by calling [TryCreateHandMeshObserverAsync](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource.trycreatehandmeshobserverasync) on the [SpatialInteractionSource](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsource).</span></span>  <span data-ttu-id="365fa-283">これは、1 回実行する、ソースあたり通常最初に表示するだけ済みます。</span><span class="sxs-lookup"><span data-stu-id="365fa-283">This only needs to be done once per source, typically the first time you see it.</span></span>  <span data-ttu-id="365fa-284">手の形に視界が入力したときに、HandMeshObserver オブジェクトを作成するには、この関数を呼び出しを意味します。</span><span class="sxs-lookup"><span data-stu-id="365fa-284">That means you'll call this function to create a HandMeshObserver object whenever a hand enters the FOV.</span></span>  <span data-ttu-id="365fa-285">これは非同期関数では、ここでの同時実行の少し対処する必要がありますので注意してください。</span><span class="sxs-lookup"><span data-stu-id="365fa-285">Note that this is an async function, so you'll have to deal with a bit of concurrency here.</span></span>  <span data-ttu-id="365fa-286">利用可能になった HandMeshObserver オブジェクトを求める、三角形インデックス バッファーを呼び出して[GetTriangleIndices](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver.gettriangleindices#Windows_Perception_People_HandMeshObserver_GetTriangleIndices_System_UInt16___)します。</span><span class="sxs-lookup"><span data-stu-id="365fa-286">Once available, you can ask the HandMeshObserver object for the triangle index buffer by calling [GetTriangleIndices](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver.gettriangleindices#Windows_Perception_People_HandMeshObserver_GetTriangleIndices_System_UInt16___).</span></span>  <span data-ttu-id="365fa-287">インデックスは、ソースの有効期間だけキャッシュし、1 回取得することができます、フレーム、経由でフレームを変更しないでください。</span><span class="sxs-lookup"><span data-stu-id="365fa-287">Indices don't change frame over frame, so you can get those once and cache them for the lifetime of the source.</span></span>  <span data-ttu-id="365fa-288">インデックスは、時計回りにワインディングの順序で提供されます。</span><span class="sxs-lookup"><span data-stu-id="365fa-288">Indices are provided in clockwise winding order.</span></span>

<span data-ttu-id="365fa-289">次のコードでは、メッシュのオブザーバーを作成するデタッチ std::thread スピンアップし、メッシュ オブザーバーが使用可能、インデックス バッファーを抽出します。</span><span class="sxs-lookup"><span data-stu-id="365fa-289">The following code spins up a detached std::thread to create the mesh observer and extracts the index buffer once the mesh observer is available.</span></span>  <span data-ttu-id="365fa-290">という名前の変数から開始し*currentState*のインスタンスである[SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate)履歴手の形を表します。</span><span class="sxs-lookup"><span data-stu-id="365fa-290">It starts from a variable called *currentState*, which is an instance of [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate) representing a tracked hand.</span></span>

```cpp
using namespace Windows::Perception::People;

std::thread createObserverThread([this, currentState]()
{
    HandMeshObserver newHandMeshObserver = currentState.Source().TryCreateHandMeshObserverAsync().get();
    if (newHandMeshObserver)
    {
        unsigned indexCount = newHandMeshObserver.TriangleIndexCount();
        vector<unsigned short> indices(indexCount);
        newHandMeshObserver.GetTriangleIndices(indices);

        // Save the indices and handMeshObserver for later use - and use a mutex to synchronize access if needed!
     }
});
createObserverThread.detach();
```
<span data-ttu-id="365fa-291">非同期呼び出しを処理するための 1 つのオプションは、デタッチ スレッドを開始します。</span><span class="sxs-lookup"><span data-stu-id="365fa-291">Starting a detached thread is just one option for handling async calls.</span></span>  <span data-ttu-id="365fa-292">またはを使って新しい[co_await](https://docs.microsoft.com/en-us/windows/uwp/cpp-and-winrt-apis/concurrency)でサポートされる機能C++/WinRT です。</span><span class="sxs-lookup"><span data-stu-id="365fa-292">Alternatively, you could use the new [co_await](https://docs.microsoft.com/en-us/windows/uwp/cpp-and-winrt-apis/concurrency) functionality supported by C++/WinRT.</span></span>

<span data-ttu-id="365fa-293">HandMeshObserver オブジェクトを作成したら、その対応する SpatialInteractionSource がアクティブになっている期間を保持する必要があります。</span><span class="sxs-lookup"><span data-stu-id="365fa-293">Once you have a HandMeshObserver object, you should hold onto it for the duration that its corresponding SpatialInteractionSource is active.</span></span>  <span data-ttu-id="365fa-294">フレームごと、それを求める最新頂点バッファーを呼び出すことによって、手の形を表す[GetVertexStateForPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver.getvertexstateforpose)を渡して、 [HandPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose)頂点姿勢を表すインスタンス。</span><span class="sxs-lookup"><span data-stu-id="365fa-294">Then each frame, you can ask it for the latest vertex buffer that represents the hand by calling [GetVertexStateForPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshobserver.getvertexstateforpose) and passing in a [HandPose](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handpose) instance that represents the pose that you want vertices for.</span></span>  <span data-ttu-id="365fa-295">バッファー内の各頂点は、位置と標準があります。</span><span class="sxs-lookup"><span data-stu-id="365fa-295">Each vertex in the buffer has a position and a normal.</span></span>  <span data-ttu-id="365fa-296">手の形のメッシュの頂点の現在のセットを取得する方法の例を示します。</span><span class="sxs-lookup"><span data-stu-id="365fa-296">Here's an example of how to get the current set of vertices for a hand mesh.</span></span>  <span data-ttu-id="365fa-297">以前と同様、 *currentState*変数のインスタンスを表します[SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate)します。</span><span class="sxs-lookup"><span data-stu-id="365fa-297">Just as before, the *currentState* variable represents an instance of [SpatialInteractionSourceState](https://docs.microsoft.com/en-us/uwp/api/windows.ui.input.spatial.spatialinteractionsourcestate).</span></span>

```cpp
using namespace winrt::Windows::Perception::People;

auto handPose = currentState.TryGetHandPose();
if (handPose)
{
    std::vector<HandMeshVertex> vertices(handMeshObserver.VertexCount());
    auto vertexState = handMeshObserver.GetVertexStateForPose(handPose);
    vertexState.GetVertices(vertices);

    auto meshTransform = vertexState.CoordinateSystem().TryGetTransformTo(desiredCoordinateSystem);
    if (meshTransform != nullptr)
    {
        // Do something with the vertices and mesh transform, along with the indices that you saved earlier
    }
}
```

<span data-ttu-id="365fa-298">スケルトンの結合とは異なり、手の形のメッシュ API はできません、頂点の座標システムを指定すること。</span><span class="sxs-lookup"><span data-stu-id="365fa-298">In contrast to skeleton joints, the hand mesh API does not allow you to specify a coordinate system for the vertices.</span></span>  <span data-ttu-id="365fa-299">代わりに、 [HandMeshVertexState](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshvertexstate)座標システムで提供されている頂点を指定します。</span><span class="sxs-lookup"><span data-stu-id="365fa-299">Instead, the [HandMeshVertexState](https://docs.microsoft.com/en-us/uwp/api/windows.perception.people.handmeshvertexstate) specifies the coordinate system that the vertices are provided in.</span></span>  <span data-ttu-id="365fa-300">呼び出してメッシュ変換を取得することができますし、 [TryGetTransformTo](https://docs.microsoft.com/en-us/uwp/api/windows.perception.spatial.spatialcoordinatesystem.trygettransformto#Windows_Perception_Spatial_SpatialCoordinateSystem_TryGetTransformTo_Windows_Perception_Spatial_SpatialCoordinateSystem_)し、目的の座標系を指定します。</span><span class="sxs-lookup"><span data-stu-id="365fa-300">You can then get a mesh transform by calling [TryGetTransformTo](https://docs.microsoft.com/en-us/uwp/api/windows.perception.spatial.spatialcoordinatesystem.trygettransformto#Windows_Perception_Spatial_SpatialCoordinateSystem_TryGetTransformTo_Windows_Perception_Spatial_SpatialCoordinateSystem_) and specifying your desired coordinate system.</span></span>  <span data-ttu-id="365fa-301">頂点を操作するたびに、このメッシュ変換を使用する必要があります。</span><span class="sxs-lookup"><span data-stu-id="365fa-301">You'll need to use this mesh transform whenever you work with the vertices.</span></span>  <span data-ttu-id="365fa-302">このアプローチでは、レンダリングのために、メッシュを使用してのみ場合に特に、CPU オーバーヘッドが削減されます。</span><span class="sxs-lookup"><span data-stu-id="365fa-302">This approach reduces CPU overhead, especially if you are only using the mesh for rendering purposes.</span></span>

## <a name="gaze-and-commit-composite-gestures"></a><span data-ttu-id="365fa-303">視線し、複合ジェスチャのコミット</span><span class="sxs-lookup"><span data-stu-id="365fa-303">Gaze and Commit composite gestures</span></span>
<span data-ttu-id="365fa-304">HoloLens で特に注視し、コミットの入力モデルを使用するアプリケーションの (最初 gen) 空間の入力 API を提供、省略可能な[SpatialGestureRecognizer](https://msdn.microsoft.com/library/windows/apps/windows.ui.input.spatial.spatialgesturerecognizer.aspx)上に構築された複合のジェスチャを有効にするには使用できる、' select' イベント。</span><span class="sxs-lookup"><span data-stu-id="365fa-304">For applications using the gaze-and-commit input model, particularly on HoloLens (first gen), the Spatial Input API provides an optional [SpatialGestureRecognizer](https://msdn.microsoft.com/library/windows/apps/windows.ui.input.spatial.spatialgesturerecognizer.aspx) that can be used to to enable composite gestures built on top of the 'select' event.</span></span>  <span data-ttu-id="365fa-305">ルーティングの相互作用によって、SpatialInteractionManager からホログラムの SpatialGestureRecognizer に、アプリ イベントを検出できますタップ、保持、操作、およびナビゲーション一様に手、音声、および空間の入力デバイス間での押下を処理する必要はありません。手動で解放します。</span><span class="sxs-lookup"><span data-stu-id="365fa-305">By routing interactions from the SpatialInteractionManager to a hologram's SpatialGestureRecognizer, apps can detect Tap, Hold, Manipulation, and Navigation events uniformly across hands, voice, and spatial input devices, without having to handle presses and releases manually.</span></span>

<span data-ttu-id="365fa-306">SpatialGestureRecognizer を要求するジェスチャ セットの間の最小限の曖昧のみを実行します。</span><span class="sxs-lookup"><span data-stu-id="365fa-306">SpatialGestureRecognizer performs only the minimal disambiguation between the set of gestures that you request.</span></span> <span data-ttu-id="365fa-307">たとえば、タップするだけを要求する場合ようおり、タップが引き続き発生を指がユーザーに押し可能性があります。</span><span class="sxs-lookup"><span data-stu-id="365fa-307">For example, if you request just Tap, the user may hold their finger down as long as they like and a Tap will still occur.</span></span> <span data-ttu-id="365fa-308">要求した場合は、タップ押しすると、約 1 秒が指を保持しているのでは、ジェスチャは保留リストに昇格し、タップは行われなくとの両方。</span><span class="sxs-lookup"><span data-stu-id="365fa-308">If you request both Tap and Hold, after about a second of holding down their finger, the gesture will promote to a Hold and a Tap will no longer occur.</span></span>

<span data-ttu-id="365fa-309">SpatialGestureRecognizer を使用する処理 SpatialInteractionManager の[InteractionDetected](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialInteractionManager.InteractionDetected)イベントと公開されている、SpatialPointerPose グラブします。</span><span class="sxs-lookup"><span data-stu-id="365fa-309">To use SpatialGestureRecognizer, handle the SpatialInteractionManager's [InteractionDetected](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialInteractionManager.InteractionDetected) event and grab the SpatialPointerPose exposed there.</span></span> <span data-ttu-id="365fa-310">積集合を持つ、ホログラムこの姿勢からユーザーのヘッド注視光線を使用し、画面がユーザーの環境では、ユーザーのプログラムと対話するかを判断するためにメッシュします。</span><span class="sxs-lookup"><span data-stu-id="365fa-310">Use the user's head gaze ray from this pose to intersect with the holograms and surface meshes in the user's surroundings, in order to determine what the user is intending to interact with.</span></span> <span data-ttu-id="365fa-311">その後、ターゲット ホログラムの SpatialGestureRecognizer、イベント引数の中で、SpatialInteraction をルーティングを使用してその[CaptureInteraction](http://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.CaptureInteraction)メソッド。</span><span class="sxs-lookup"><span data-stu-id="365fa-311">Then, route the SpatialInteraction in the event arguments to the target hologram's SpatialGestureRecognizer, using its [CaptureInteraction](http://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.CaptureInteraction) method.</span></span> <span data-ttu-id="365fa-312">に従ってその相互作用の解釈が起動、 [SpatialGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureSettings) - の作成時に、その認識エンジンで設定[TrySetGestureSettings](http://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.TrySetGestureSettings)します。</span><span class="sxs-lookup"><span data-stu-id="365fa-312">This starts interpreting that interaction according to the [SpatialGestureSettings](https://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureSettings) set on that recognizer at creation time - or by [TrySetGestureSettings](http://msdn.microsoft.com/library/windows/apps/xaml/Windows.UI.Input.Spatial.SpatialGestureRecognizer.TrySetGestureSettings).</span></span>

<span data-ttu-id="365fa-313">HoloLens で (gen 最初) の相互作用とジェスチャのユーザーの視線入力ヘッドからターゲットではなくしようとしてレンダリングまたはして手のアイコンの場所に直接対話を派生する必要があります一般にします。</span><span class="sxs-lookup"><span data-stu-id="365fa-313">On HoloLens (first gen), interactions and gestures should generally derive their targeting from the user's head gaze, rather than trying to render or interact at the hand's location directly.</span></span> <span data-ttu-id="365fa-314">相互作用が開始されたら、操作やナビゲーションのジェスチャと同様、手の相対的な動きをジェスチャを制御を使用できます。</span><span class="sxs-lookup"><span data-stu-id="365fa-314">Once an interaction has started, relative motions of the hand may be used to control the gesture, as with the Manipulation or Navigation gesture.</span></span>

## <a name="see-also"></a><span data-ttu-id="365fa-315">関連項目</span><span class="sxs-lookup"><span data-stu-id="365fa-315">See also</span></span>
* [<span data-ttu-id="365fa-316">DirectX で Head、目の視線入力</span><span class="sxs-lookup"><span data-stu-id="365fa-316">Head and eye gaze in DirectX</span></span>](gaze-in-directx.md)
* [<span data-ttu-id="365fa-317">入力モデルを直接操作</span><span class="sxs-lookup"><span data-stu-id="365fa-317">Direct manipulation input model</span></span>](direct-manipulation.md)
* [<span data-ttu-id="365fa-318">入力モデルをポイントし、コミット</span><span class="sxs-lookup"><span data-stu-id="365fa-318">Point-and-commit input model</span></span>](point-and-commit.md)
* [<span data-ttu-id="365fa-319">入力モデルを注視とコミット</span><span class="sxs-lookup"><span data-stu-id="365fa-319">Gaze and commit input model</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="365fa-320">モーション コントローラー</span><span class="sxs-lookup"><span data-stu-id="365fa-320">Motion controllers</span></span>](motion-controllers.md)
