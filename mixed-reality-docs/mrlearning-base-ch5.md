---
title: 入門チュートリアル-6. 詳細な入力オプションの調査
description: このコースを完了すると、Mixed Reality アプリケーション内で Azure 顔認識を実装する方法を学習することができます。
author: jessemcculloch
ms.author: jemccull
ms.date: 02/26/2019
ms.topic: article
keywords: Mixed Reality、Unity、チュートリアル、Hololens
ms.openlocfilehash: 0f01b789cfc358500ec94a10f82315bca55dd622
ms.sourcegitcommit: af1602710c1ccb7ed870a491923350d387706129
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 08/01/2019
ms.locfileid: "68702009"
---
# <a name="6-exploring-advanced-input-options"></a>6。詳細な入力オプションの調査

このチュートリアルでは、HoloLens 2 の高度な入力オプションをいくつか紹介します。これには、音声コマンド、パンジェスチャ、および視線追跡の使用が含まれます。 

## <a name="objectives"></a>目的

- 音声コマンドとキーワードを使用してイベントをトリガーする
- 追跡したハンドを使用して、追跡したハンドでテクスチャと3D オブジェクトをパンする
- HoloLens 2 の監視機能を活用してオブジェクトを選択する

## <a name="instructions"></a>手順

### <a name="enabling-voice-commands"></a>音声コマンドの有効化

このセクションでは、2つの音声コマンドを実装します。 まず、"診断の切り替え" という指示によって、フレームレート診断パネルを切り替える機能を紹介します。 次に、音声コマンドでサウンドを再生する機能について説明します。 まず、音声コマンドの構成を担当する MRTK プロファイルと設定について説明します。 

1. 基本のシーン階層で、[MixedRealityToolkit] を選択します。 [インスペクター] パネルで、[システム設定の入力] まで下にスクロールします。 ダブルクリックして、[Input System Profile] (入力システム プロファイル) を開きます。 [レッスン 1](mrlearning-base-ch1.md)で学んだように、入力システムプロファイルを複製して編集可能にします。 

入力システムプロファイルには、さまざまな設定があります。 音声コマンドの場合は、[音声コマンドの設定] を選択します。 

![Lesson5 Chapter1 Step2im](images/Lesson5_Chapter1_step2im.PNG)

2. 「[レッスン 1](mrlearning-base-ch1.md)」で学習したように、speech コマンドプロファイルを複製して編集可能にします。 音声コマンドプロファイルをダブルクリックすると、さまざまな設定が表示されます。 これらの設定の詳細については、 [Mrtk speech のドキュメント](<https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/Input/Speech.html>)を参照してください。 

>注:既定では、一般の動作は [Auto Start] (自動で開始) です。 これは、必要に応じて、手動で開始するように変更できます。 ただし、この例では、自動開始のままにします。 MRTK には、メニュー、診断の切り替え、プロファイラーの切り替えなど、いくつかの既定の音声コマンドが付属しています。 診断フレームカウントカウンターをオンまたはオフにするために、キーワード "診断の切り替え" を使用します。 また、以下のステップで新しい音声コマンドを追加します。
>
> ![Lesson5 Chapter1 Noteim](images/Lesson5_chapter1_noteim.PNG)

3. 新しい音声コマンドを追加します。 新しい音声コマンドを追加するには、[+ 新しい音声の追加] コマンドボタンをクリックします。 既存の音声コマンドの一覧の下に新しい行が表示されます。 使用したい音声コマンドを入力します。 この例では、"音楽の再生" コマンドを使用します。

>ヒント:また、音声認識コマンドのキーコードを設定することもできます。 これにより、音声コマンドを使用して、キーボードキーを押したときにイベントをトリガーできます。    

4. 音声コマンドに応答する機能を追加します。 他の入力スクリプトがアタッチされていないベースシーン階層内のオブジェクトを選択します (操作ハンドラーがないなど)。 [インスペクター] パネルで、[コンポーネントの追加] をクリックします。 「音声入力ハンドラー」と入力し、それを選択します。

   ![Lesson5 Chapter1.txt Step4im](images/Lesson5_chapter1_step4im.PNG)

   

既定では、2つのチェックボックスが表示されます。 1つは [フォーカスが必要] チェックボックスです。 これは、オブジェクトを見つめていて、視線、頭を見つめ、コントローラーを見つめた、またはハンドを見つめている場合に限り、音声コマンドがトリガーされることを意味します。 ユーザーが音声コマンドを使用するためにオブジェクトを確認する必要がないように、このチェックボックスをオフにします。

5. 音声コマンドに応答する機能を追加します。 これを行うには、音声入力ハンドラーにある [+] ボタンをクリックし、応答するキーワードを選択します。

   > 注:これらのキーワードは、以前のステップで編集したプロファイルに基づいて事前設定されています。

![Lesson5 Chapter1 Step5im](images/Lesson5_chapter1_step5im.PNG)

6. [キーワード] の横に、ドロップダウンメニューが表示されます。 [診断の切り替え] を選択すると、"診断の切り替え" という語句がユーザーに表示されるたびに、アクションがトリガーされます。 要素0を展開するには、その横にある矢印を押す必要があることに注意してください。

![Lesson5 Chapter1 Step6im](images/Lesson5_chapter1_step6im.PNG)

7. 診断デモコントロールスクリプトを追加して、フレームレートカウンターの診断のオンとオフを切り替えます。 これを行うには、[コンポーネントの追加] をクリックし、[Diagnostics Demo Controls script] を検索して、メニューから追加します。 このスクリプトは任意のオブジェクトに追加できます。 しかし、わかりやすくするために、音声入力ハンドラーと同じオブジェクトに追加します。 

   > 注:このスクリプトは、これらのモジュールにのみ含まれており、元の MRTK には含まれていません。

![Lesson5 Chapter1 Step7im](images/Lesson5_chapter1_step7im.PNG)

8. 音声入力ハンドラーに新しい応答を追加します。 これを行うには、の下の [+] ボタンをクリックします (上の図の緑色の矢印でマークされている)。

![Lesson5 Chapter1 Step7im](images/Lesson5_chapter1_step8.PNG)

9. 診断デモコントロールスクリプトを含むオブジェクトを、手順 8. で作成した新しい応答にドラッグします。
    ![Lesson5 Chapter1 Step9im](images/Lesson5_chapter1_step9im.PNG)

10. 次に、[関数なし] ドロップダウンリストを選択し、[診断デモコントロール] を選択します。 次に、診断をオンまたはオフに切り替える "On トグル診断 ()" 関数を選択します。  ![Lesson5 Chapter1 Step10im](images/Lesson5_chapter1_step10im.PNG)
    
> デバイス向けにビルドする前に、マイクの設定を有効にする必要があります。 これを行うには、[ファイル] をクリックし、[ビルドの設定]、[プレーヤーの設定] の順にクリックして、マイクの機能が設定されていることを確認します。

次に、Octa オブジェクトを使用して音声コマンドからオーディオファイルを再生する機能を追加します。 [レッスン 4](mrlearning-base-ch4.md)から、オーディオクリップを再生して、octa オブジェクトに触れる機能を追加したことを思い出してください。 この同じオーディオ ソースを、ミュージック音声コマンドでも活用します。

11. 基本のシーン階層で、Octa オブジェクトを選択します。

12. 別の音声入力ハンドラーを追加します (手順4と5を繰り返します)。ただし、octa オブジェクトを使用します。 

13. 手順6の [診断の切り替え] コマンドを追加するのではなく、次の図に示すように、[音楽音声の再生] コマンドを追加します。
    
     ![Lesson5 Chapter1 Step13im](images/Lesson5_chapter1_step13im.PNG)
    
    
    
14. 手順 8. と手順 9. と同様に、新しい応答を追加し、Octa オブジェクトを空の応答スロットにドラッグします。

15. [関数なし] というドロップダウンメニューを選択します。 次に、[オーディオソース] を選択し、[PlayOneShot (AudioClip)] を選択します。

![Lesson5 Chapter1 Step15im](images/Lesson5_chapter1_step15im.PNG)

16. この例では、[レッスン 4](mrlearning-base-ch4.md)と同じオーディオクリップを使用します。 プロジェクトパネルに移動し、"MRTK_Gem" オーディオクリップを検索して、次の図に示すようにオーディオソーススロットにドラッグします。 これで、アプリケーションは音声コマンド "トグル診断" に応答して、フレームレートカウンターパネルを切り替え、音楽を再生して MRTK_Gem 楽曲を再生します。
     ![Lesson5 Chapter1 Step16im](images/Lesson5_chapter1_step16im.PNG)


### <a name="the-pan-gesture"></a>パン ジェスチャ 

このセクションでは、パンジェスチャの使用方法について説明します。 これは、指またはハンドを使用してコンテンツをスクロールすることでスクロールする場合に便利です。 また、パンジェスチャを使用してオブジェクトを回転したり、3D オブジェクトのコレクションを順番に移動したり、2D UI をスクロールすることもできます。 また、パンジェスチャを使用してテクスチャをワープする方法と、3D オブジェクトのコレクションを移動する方法についても説明します。

1. quad を作成します。 基本のシーン階層で、右クリックし、[3D オブジェクト] を選択して、[クワッド] を選択します。

![Lesson5 Chapter2 Step2im](images/Lesson5_chapter2_step2im.PNG)

2. quad を適切な位置に配置します。 この例では、HoloLens 2 から快適に使用できるように、x = 0、y = 0、z = 1.5 をカメラから離れた位置に設定します。

   > 注:4つのブロックまたは前のレッスンの内容の前にある場合は、他のオブジェクトをブロックしないように注意してください。

3. 素材を quad に適用します。 この素材が、パン ジェスチャでスクロールする素材になります。 

![Lesson5 Chapter2 Step3im](images/Lesson5_chapter2_step3im.PNG)

4. [プロジェクト] パネルで、検索ボックスに「コンテンツのパン」と入力します。 この素材を、シーンの quad にドラッグします。 

> 注:Pan コンテンツマテリアルは MRTK には含まれていませんが、前のレッスンでインポートしたように、このモジュールの資産パッケージのアセットに含まれています。 

> 注:パン コンテンツを追加すると、引き伸ばされたように見えることがあります。 これを修正するには、quad のサイズの x、y、z 値を希望する大きさになるまで調整します。

パン ジェスチャを使用するには、オブジェクト上のコライダーが必要です。 場合によっては、quad には既にメッシュ コライダーがあります。 ただし、メッシュ コライダーは極めて薄く、選択するのが容易ではないため理想的ではありません。 メッシュ コライダーをボックス コライダーに置き換えることをお勧めします。

5. [インスペクター] パネルから、クワッド上のメッシュ collider を右クリックします。 次に、[コンポーネントの削除] をクリックして削除します。
    ![Lesson5 Chapter2 Step5im](images/Lesson5_chapter2_step5im.PNG)
6. 次に、[コンポーネントの追加] をクリックして box collider を追加し、"box collider" を検索します。既定で追加される box collider はまだ薄くなっているので、[Collider の編集] ボタンをクリックして編集します。 ボタンを押すと、x、y、z の値を使用して、またはシーン エディターの要素を使用してサイズを調整できます。 この例では、ボックス コライダーを quad の少し後ろまで拡張します。 シーン エディターで、ボックス コライダーを後ろから外側にドラッグします (下の図を参照してください)。 これにより、ユーザーは指を使用するだけでなく、スクロールすることもできます。 
    ![Lesson5 Chapter2 Step6im](images/Lesson5_chapter2_step6im.PNG)
7. 操作ができるようにします。 このモジュールを直接操作する必要があるので、ここではレッスン4で、Octa オブジェクトから音楽を再生するために使用した Near インタラクション Touchable コンポーネントを使用します。 [コンポーネントの追加] をクリックし、次の図に示すように "near インタラクション touchable" を検索して選択します。 

8. パン ジェスチャを認識する機能を追加します。 [コンポーネントの追加] をクリックし、「手書き入力のパン」と入力すると、ハンドレイ (距離からのパンを可能にする) とインデックスの指のどちらかを選択できるようになります。 この例では、[Index Finger] (人差し指) のままにします。 
    ![Lesson5 Chapter2 Step7 8Im](images/Lesson5_chapter2_step7-8im.PNG)

![Lesson5 Chapter2 Step8im](images/Lesson5_chapter2_step8im.PNG)

9. 手書きのパンスクリプトでは、[水平方向のロック] と [垂直方向に固定] チェックボックスはそれぞれロックを解除します。 [テクスチャのラップ] 設定により、テクスチャ (テクスチャマッピング) がユーザーのパンの動きに従います。 この例では、チェックボックスをオンにします。 また、ベロシティがアクティブになっています。オフにすると、パンジェスチャは機能しません。 このボックスにもチェックを入れます。 これで、パン対応のクワッドが作成されます。

   

   次に、3D オブジェクトをパンする方法を学びます。 

10. クワッドオブジェクトを右クリックし、[3D オブジェクト] を選択して、[キューブ] をクリックします。 cube を、おおよそ x = 0.1、y = 0.1、z = 0.1 になるように大きさを調整します。 キューブを右クリックし、[複製] を押すか、ctrl + command D キーを押して、キューブを3回コピーします。 シーンは次の図のようになります。

![Lesson5 Chapter2 Step10im](images/Lesson5_chapter2_step10im.PNG)







11. もう一度 quad を選択し、[ハンド対話] パンスクリプトで、各キューブにパンアクションを設定します。 [イベントレシーバーのパン] で、イベントを受け取るオブジェクトの数を指定します。 4つのキューブがあるため、「4」と入力し、enter キーを押します。 4つの空のフィールドが表示されます。


![Lesson5 Chapter2 Step11im](images/Lesson5_chapter2_step11im.PNG)



12. 各キューブをそれぞれ空の要素スロットにドラッグします。
     ![Lesson5 Chapter2 Step12im](images/Lesson5_chapter2_step12im.PNG)
    
13. Ctrl キーを押しながら command キーを押しながらすべてのキューブに移動するための Move スクリプトを追加し、各オブジェクトを選択します。 [インスペクター] パネルで [コンポーネントの追加] をクリックし、[move with pan] を検索します。 スクリプトをクリックすると、各キューブに追加されます。 これで、3D オブジェクトがパンジェスチャで移動します。 quad 上のメッシュの表示を削除した場合、非表示の quad があるはずで、3D オブジェクトのリストからそこにパンできます。

### <a name="eye-tracking"></a>視線追跡

このセクションでは、デモで目の追跡を有効にする方法について説明します。 3D メニュー項目が目の gazed になったときに、その項目をゆっくりと回転させます。 また、見つめられた項目が選択されると、楽しい効果がトリガーされるようにします。

1. MRTK プロファイルが正しく構成されていることを確認します。 執筆時点で、Mixed Reality ツールキット プロファイルの構成には、視線追跡機能は既定では含まれていません。 視線追跡機能を追加するには、 [Mixed Reality Toolkit のドキュメント](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_BasicSetup.html#setting-up-the-mrtk-profiles-required-for-eye-tracking  )で説明されているように、「視線追跡に必要な MRTK プロファイルを設定する」セクションの手順に従います。 上のドキュメントリンクの残りの手順に従って、視線追跡が適切に構成されていることを確認します。これには、GazeProvider (カメラに接続されているコンポーネント) での目の追跡の有効化と、Unity エディターでの目の追跡のシミュレーションの有効化が含まれます。 MRTK の将来のバージョンには、既定で目の追跡が含まれる場合があることに注意してください。

    上記のリンクでは、以下の点についての簡潔な指示があります。

    - MRTK プロファイルで使用するための視線 Data Provider の作成
    - Gaze Provider で視線追跡を有効にする
    - エディターでの目の追跡シミュレーションの設定
    - Visual Studio ソリューションの機能を編集して、ビルド済みアプリケーションで視線追跡できるようにする

2. [Eye Tracking Target] (視線追跡ターゲット) コンポーネントをターゲット オブジェクトに追加します。 オブジェクトが視線イベントに応答できるようにするには、視線を使用して操作する各オブジェクトに EyeTrackingTarget コンポーネントを追加する必要があります。 このコンポーネントを、グリッド コレクションの一部である 9 つの 3D オブジェクトそれぞれに追加します。 ヒント:EyeTrackingTarget コンポーネントを一括で追加するには、階層内の複数の項目を選択します。
    ![Lesson5 Chapter3 Step2](images/Lesson5Chapter3Step2.JPG)

3. 次に、EyeTrackingTutorialDemo スクリプトを追加して、興味深い操作ができるようにします。 EyeTrackingTutorialDemo スクリプトは、このチュートリアルシリーズリポジトリの一部として含まれています。 混合 Reality ツールキットには、既定では含まれていません。 Grid コレクション内の3D オブジェクトごとに、[コンポーネントの追加] メニューでコンポーネントを検索して、EyeTrackingTutorialDemo スクリプトを追加します。
   ![Lesson5 Chapter3 Step3](images/Lesson5Chapter3Step3.JPG)

4. ターゲットを見つめている間、オブジェクトを回転させます。 3D オブジェクトを見ている間にスピンするように構成したいと考えています。 これを行うには、次の図に示すように、EyeTrackingTarget コンポーネントの Target () セクションを参照しながら、に新しいフィールドを挿入します。 

![Lesson5 Chapter3 Step4a](images/Lesson5Chapter3Step4a.JPG)
![Lesson5 Chapter3 Step4b](images/Lesson5Chapter3Step4b.JPG)



新しく作成されたフィールドで、次の図に示すように、現在の Game オブジェクトを空のフィールドに追加し、EyeTrackingTutorialDemo > RotateTarget () を選択します。 これで、視線追跡により、3D オブジェクトを見つめると回転するように構成できました。 

5. エアタップによって、または "select" と言ったときに、選択時に gazed される "ブリップが発生 target" の機能を追加します。 手順4に似ていますが、次の図に示すように、EyeTrackingTarget コンポーネントの game オブジェクトの Select () フィールドに割り当てることによって、EyeTrackingTutorialDemo > ブリ Ptarget () をトリガーします。 これで構成が完了すると、エアタップや音声コマンドの "select" などの選択アクションをトリガーするたびに、game オブジェクトにわずかなブリップが発生が見られます。 
    ![Lesson5 Chapter3 Step5](images/Lesson5Chapter3Step5.JPG)
6. HoloLens 2 向けにビルドする前に、視線追跡機能が適切に構成されていることを確かめます。 このドキュメントの執筆時点では、Unity には、視線追跡機能に対して、宝石入力を設定する機能がまだありません。 この機能の設定は、監視が HoloLens 2 で動作するために必要です。 次の Mixed Reality ツールキット ドキュメントにある指示に従って、視線入力機能を有効にしてください。 https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_BasicSetup.html#testing-your-unity-app-on-a-hololens-2 


## <a name="congratulations"></a>結論

アプリケーションに基本的な監視機能が正常に追加されました。 これらの操作は、視線追跡が持つ可能性のほんの一部にすぎません。 また、レッスン5では、音声コマンド、パンジェスチャ、視線追跡などの高度な入力機能について学習しました。 

[次のレッスン:7.月着陸船サンプル アプリケーションの作成](mrlearning-base-ch6.md)

