---
title: 入力を高度な MR Learning ベース モジュール
description: このコースでは、複合現実のアプリケーション内で Azure の顔認識機能を実装する方法について説明します。
author: jessemcculloch
ms.author: jemccull
ms.date: 02/26/2019
ms.topic: article
ms.localizationpriority: high
keywords: 複合現実、unity、チュートリアル、hololens
ms.openlocfilehash: 32141aafd43c5d729919673509c93bb2014edd37
ms.sourcegitcommit: 1c0fbee8fa887525af6ed92174edc42c05b25f90
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 05/16/2019
ms.locfileid: "65730929"
---
# <a name="mr-learning-base-module---advanced-input"></a>入力を高度な MR Learning ベース モジュール

このレッスンでは、HoloLens 2 は、音声コマンド、パン ジェスチャ、および視線の使用などのいくつかの高度な入力オプションについて説明します。 

## <a name="objectives"></a>目標

- 音声コマンドやキーワードを使用してイベントをトリガーする方法について説明します
- 追跡対象の手を使用してテクスチャと 3D オブジェクトに移動
- HoloLens 2 の視線のオブジェクトを選択する機能を活用します。

## <a name="instructions"></a>手順

### <a name="enabling-voice-commands"></a>音声コマンドを有効にします。

このセクションでを実装する 2 つの音声コマンド。 最初に、「トグルの診断」を言うことにより、フレーム レート診断パネルを切り替える機能 2 つ目は、音声コマンドを使用してサウンドを再生する機能。 まず学びます MRTK プロファイルと設定の音声コマンドを構成する責任を負います。 

1. 基本のシーンの階層構造では、"MixedRealityToolkit。"を選択します。 Inspector パネルで、入力システム設定までスクロールします。 ダブルクリックして、入力システム プロファイルを開きます。 学んだことで、編集可能なことに、入力システム プロファイルを複製[レッスン 1](mrlearning-base-ch1.md) 

入力システム プロファイルでは、さまざまな設定が表示されます。 音声コマンドには書かれている場所、「音声コマンドの設定」にダウンします。 

![Lesson5 第 1 章 Step2im](images/Lesson5_Chapter1_step2im.PNG)

2. 複製を学んだことで、編集するに音声コマンド プロファイル[レッスン 1](mrlearning-base-ch1.md)します。 さまざまな設定が表示されます、音声コマンド プロファイルをダブルクリックします。 これらの設定の詳細については、参照、 [MRTK speech のドキュメント](<https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/Input/Speech.html>)します。 

>注:既定では、全般的な動作は自動開始です。 手動で起動が必要な場合に変更できますが、この例ではここでは自動的に開始します。 MRTK、いくつかの既定の音声コマンド (メニューの切り替えの診断、および切り替えプロファイラー) などが付属します。 使用するキーワード「トグル診断」オン/オフ、診断のフレーム レート カウンターを有効にするためにします。 次の手順で新しい音声コマンドも追加します。
>
> ![Lesson5 第 1 章 Noteim](images/Lesson5_chapter1_noteim.PNG)

3. 新しい音声コマンドを追加します。 新しい音声コマンドを追加するには、[+ 新しい音声コマンドの追加] ボタンをクリックしてし、を既存の音声コマンドの一覧の下に表示される新しい行が表示されます。 使用する音声コマンドを入力します。 この musicample ex「音楽を再生します」コマンドを使用するつもりは

>ヒント:音声認識コマンドについての keycode を設定することもできます。 これにより、キーボードのキーの押下時にトリガーする音声コマンド。   

4. 音声コマンドに応答する機能を追加します。 (例: も操作ハンドラー。) に接続されているその他の入力スクリプトがない基本シーンの階層構造で任意のオブジェクトを選択します。Inspector パネルで、「コンポーネントを追加します」をクリックします。 入力"音声入力の handler" これを選択します。
   ![Lesson5 第 1 章 Step4im](images/Lesson5_chapter1_step4im.PNG)

   

既定では、2 つのチェック ボックスが表示されます、1 つは、「が必要なフォーカス」チェック ボックスをオンします。 つまり注視レイ、(目視線入力、head 視線入力、コント ローラー-視線入力、または手視線の先) オブジェクトを指している限り、音声コマンドがトリガーされます。 ユーザーが音声コマンドを使用するオブジェクトを確認する必要があるないようにするには、このチェック ボックスをオフにします。

5. 音声コマンドに応答する機能を追加します。 これを行うには、音声入力の handler 内にある「+」ボタンをクリックしに応答するには、キーワードを選択します。

   > 注:これらのキーワードでは、前の手順で編集したプロファイルに基づいて設定されます。

![Lesson5 第 1 章 Step5im](images/Lesson5_chapter1_step5im.PNG)

6. 「キーワード」の横にあるドロップダウン メニューが表示されます。 「診断の切り替え」を選択します。 これにより、アクションをトリガーする、ユーザーが「切り替え診断」という語句が話すたびにできるようにします。 その横にある方向キーを押して「要素 0」を展開する必要がありますに注意してください。

![Lesson5 第 1 章 Step6im](images/Lesson5_chapter1_step6im.PNG)

7. "診断デモ コントロールするスクリプトを追加"フレーム レート カウンターの診断をオンとオフを切り替えます。 これを行うには、"コンポーネントの追加 ボタンを押して、「診断デモ コントロール スクリプト」を検索し、メニューから追加します。 このスクリプトは、任意のオブジェクトに追加することができますが、わかりやすくするため、ここに追加して音声入力の handler と同じオブジェクト。 

   > 注: このスクリプトはのみこれらのモジュールに含まれているし、は、元の MRTK 含まれていません。

![Lesson5 第 1 章 Step7im](images/Lesson5_chapter1_step7im.PNG)

8. 音声入力のハンドラーでは、新しい応答を追加します。 行うには、「応答 ()」(上の図の緑色の矢印でマークされている) が書かれている場所の下に「+」ボタンをクリックします。

![Lesson5 第 1 章 Step7im](images/Lesson5_chapter1_step8.PNG)

9. 手順 8. で作成した新しい応答を診断デモ コントロールのスクリプトを持つオブジェクトをドラッグします。
    ![Lesson5 第 1 章 Step9im](images/Lesson5_chapter1_step9im.PNG)

10. ようになりました「機能はありません」のドロップダウン リストを選択して、診断デモのコントロールを選択し、「診断 () の切り替えを」。 この関数は、オンとオフの診断を切り替えます。  ![Lesson5 第 1 章 Step10im](images/Lesson5_chapter1_step10im.PNG)
    
> デバイスにビルドする前にする必要がある mic の設定を有効にするに注意してください。 ファイルでボタンをクリックするには、ビルド、player の設定からの設定に移動し、マイク機能が設定されていることを確認します。

次に、"octa"オブジェクトを使用して音声コマンドからのオーディオ ファイルを再生する機能が追加されます。 メッセージの取り消し[レッスン 4](mrlearning-base-ch4.md)、octa オブジェクトからオーディオ クリップを再生する機能を追加しました。 ここでは、この同じのオーディオ ソースを音楽音声コマンドを活用します。

11. 基本のシーンの階層構造で octa オブジェクトを選択します。

12. もう 1 つの音声入力の handler (手順 4 と 5)、追加しますが、octa オブジェクトを使用します。 

13. 手順 6 から「トグル診断」の音声コマンドを追加する代わりに次の図に示すように「再生」の音声コマンドを追加します。
    
     ![Lesson5 第 1 章 Step13im](images/Lesson5_chapter1_step13im.PNG)
    
    
    
14. 手順 8. と 9. と同様、新しい応答を追加し、応答で、octa を空のスロットにドラッグします。

15. 「機能はありません、」「オーディオ ソースの選択、」し、"PlayOneShot (AudioClip)。"ことを示すドロップダウン メニューを選択します。

![Lesson5 第 1 章 Step15im](images/Lesson5_chapter1_step15im.PNG)

16. オーディオのクリップでこの例ではここから同じのオーディオ クリップを使用して、[レッスン 4](mrlearning-base-ch4.md)します。 [プロジェクト] パネルに移動し、"MRTK_Gem"オーディオ クリップを検索および次の図に示すように、オーディオ ソース スロットにドラッグします。 アプリケーションは、音声コマンド"切り替え診断"に応答できる必要がありますので、フレーム レート カウンター パネルの切り替えを「音楽の再生」MRTK_Gem 曲を再生します。
     ![Lesson5 第 1 章 Step16im](images/Lesson5_chapter1_step16im.PNG)


### <a name="the-pan-gesture"></a>パン ジェスチャ 

この章では、パン ジェスチャを使用する方法を学びます。 スクロール (コンテンツをスクロールする本の指、手のひらを使用)。 便利です。3 D オブジェクトまたはでもスクロール 2D UI のコレクションを順番に、オブジェクトを回転するのにパン ジェスチャを使用することもできます。 私たちは、テクスチャをワープ パン ジェスチャを使用する方法学習は。 3D オブジェクトのコレクションを移動する方法についても学びます。

1. クワッドを作成します。 基本のシーン階層内を右クリックして、"3 D Object"を選択し、「クアッド」を選択します

![Lesson5 第 2 章 Step2im](images/Lesson5_chapter2_step2im.PNG)

2. 適切な 4 つの位置を変更します。 この例で、x を設定します = 0、y = 0 と z はカメラの位置から、HoloLens 2 から離れる 1.5 を = です。

   > 注:場合、クアッド要素 (はの前面ではありません) から前のレッスンでは、任意のコンテンツが他のオブジェクトのいずれかをブロックしないように移動することを確認します。

3. クワッドに素材を適用されます。 この資料はパン ジェスチャでスクロール私たちは材料になります。 

![Lesson5 第 2 章 Step3im](images/Lesson5_chapter2_step3im.PNG)

4. [プロジェクト] パネルで「コンテンツをパンします。」の検索ボックスに入力します。 シーンにクアッドにマテリアルをドラッグします。 

> 注:「コンテンツをパン」資料は、MRTK に含まれませんが、インポート前のレッスンでは、このモジュールの資産のパッケージの資産。 

> 注:パンのコンテンツを追加する場合は、ストレッチが見えます。 これは、外観に満足するまでは、x、y、z の値、四角形のサイズの値を調整することによって修正できます。

パン ジェスチャを使用するには、オブジェクトにコライダーを必要があります。 クワッドが既に mesh collider コライダーを表示があります。 ただし、非常に薄いおよび選択が困難であるため mesh collider コライダーは、適していません。 Mesh collider コライダーを置き換えて、box collider をお勧めします。

5. パネルの inspector) クアッド上にある mesh collider コライダーを右クリックし、コンポーネントを削除する をクリックして、削除 
   ![Lesson5 第 2 章 Step5im](images/Lesson5_chapter2_step5im.PNG)

6. "コンポーネントの追加] をクリックして [box collider"を検索、足場に box collider を追加するようになりました 既定値は、シンすぎますが足場に box collider を追加、ため編集"コライダーを編集 ボタンをクリックします。 押したときに、シーンのエディターで、x、y、z 値または要素を使用してサイズを調整できます。 たとえば、クアッドの背後にある、足場に box collider を少し拡張します。 シーンのエディターでは、外側の (下図を参照してください)、背面から、足場に box collider をドラッグします。 これでは、指が知り尽くして全体をスクロールするだけでなく使用するユーザーを許可します。 
    ![Lesson5 第 2 章 Step6im](images/Lesson5_chapter2_step6im.PNG)
7. 対話型こと。 クワッドと直接対話するので、相互作用押せる"近く"コンポーネント (も使いましたこれでレッスン 4、octa から音楽を再生する) を使用する必要です。 "コンポーネントの追加 をクリックします。「近くの相互作用押せる」検索し、選択し、次の図のようにします。 

8. パン ジェスチャを認識する機能を追加します。 "コンポーネントの追加 をクリックし、「相互作用のパンを渡します」を入力 (距離から方向へパンすることができます) 手射線と人差し指を切り替える必要があります。 この例では、人差し指をそのままにします。 
    ![Lesson5 第 2 章 Step7 8Im](images/Lesson5_chapter2_step7-8im.PNG)

![Lesson5 第 2 章 Step8im](images/Lesson5_chapter2_step8im.PNG)

9. 手の形の相互作用パン スクリプト"lock 水平"および"lock 垂直"のチェック ボックスにロックされます移動、それぞれします。 折り返しのテクスチャの設定とテクスチャ (テクスチャ マッピング)、ユーザーのパンの動きに従います。 この例では、チェック ボックスをオンにいきます。 「速度 active」、パン ジェスチャは機能しません、オフにした場合もあります。 同様に、このボックスを確認します。 これでパンが有効な quad が必要です。

   

   次に、3 D オブジェクトをパンする方法について説明します。 

10. クアッド オブジェクトを右クリックし、3 D オブジェクトを選択し、「キューブです」をクリックしてください X はほぼキューブを拡大縮小 = 0.1、y = 0.1、z = 0.1 です。 (キューブを右クリックして、重複するキーを押しますまたはコントロール/コマンド D キーを押してによって) 3 回そのキューブをコピーします。 それらを均等スペースします。 シーンは、次の図のようになります。

![Lesson5 第 2 章 Step10im](images/Lesson5_chapter2_step10im.PNG)







11. 再度、クアッドを選択し、手の形の相互作用パン スクリプトで各キューブのパン操作を設定する必要です。 「パン イベント レシーバー」で、イベントを受信しているオブジェクトの数を指定します。 4 つのキューブがあるので「4」の種類とキーを押してを入力します。 4 つの空のフィールドが表示されます。


![Lesson5 第 2 章 Step11im](images/Lesson5_chapter2_step11im.PNG)



12. 各要素が空のスロットには、内のキューブの各をドラッグします。
     ![Lesson5 第 2 章 Step12im](images/Lesson5_chapter2_step12im.PNG)
    
13. すべてのキューブに「移動 pan の」スクリプトを追加します。 これを行うには、キーを押しますコントロール/コマンドの保持し、各オブジェクトを選択します。 Inspector パネルで、"コンポーネントの追加 をクリックし、「パンと共に移動します」を検索します。 スクリプトをクリックし、各キューブに追加されます。 ここで 3D オブジェクトは、パン ジェスチャと共に移動! 削除すると、メッシュをレンダリングしてクワドが四角形が非表示であることを 3D オブジェクトのリストをパンすることができます。

### <a name="eye-tracking"></a>視線

この章では、このデモで目の追跡を有効にする方法について説明します。 目視線の先にすると gazed されているが、3 D のメニュー項目が回転私たちが緩やかに変化します。 楽しいもトリガー gazed 時に項目が選択されている場合に影響します。

1. Mixed Reality Toolkit プロファイルが正しく構成されていることを確認します。 この執筆時点で、複合現実 toolkit プロファイルの構成に目が既定で追跡機能は含まれません。 目の追跡機能を追加するには、「目の追跡に必要な MRTK プロファイルの設定」セクションの手順に従って」の説明に従って、 [Mixed Reality Toolkit のドキュメント](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_BasicSetup.html#setting-up-the-mrtk-profiles-required-for-eye-tracking  )します。 GazeProvider (カメラに接続されているコンポーネント) で追跡を目と Unity エディターの視線のシミュレーションを有効化を有効にするなど、上記リンクのドキュメントの残りの手順に従ってその視線を適切に構成を確認します。 注、MRTK の将来のバージョンは、既定では目の追跡を含めることができます。

    上記のリンクの簡単な指示を提供します。

    - MRTK プロファイルで使用するための目視線データ プロバイダーを作成します。
    - 視線のプロバイダーの目の追跡を有効にします。
    - エディターでの視線をシミュレートするための設定します。
    - 編集、ビルド済みアプリケーションの監視追跡できるように、Visual Studio ソリューションの機能

2. ターゲット オブジェクトに目を追跡対象のコンポーネントを追加します。 目の視線入力イベントに応答するオブジェクトを許可するのには、目視線の先を使用して対話する各オブジェクトに対して EyeTrackingTarget コンポーネントを追加する必要があります。 各グリッド コレクションの一部である 9 つの 3D オブジェクトには、このコンポーネントを追加します。 ヒント: EyeTrackingTarget コンポーネントの一括追加する階層の複数の項目を選択します。
    ![Lesson5 第 3 章の手順 2](images/Lesson5Chapter3Step2.JPG)

3. 次にいくつかの魅力的な対話の EyeTrackingTutorialDemo スクリプトを追加します。 EyeTrackingTutorialDemo スクリプトでは、このチュートリアル シリーズのリポジトリの一部として含まれてし、Mixed Reality Toolkit では既定では含まれません。 グリッドのコレクション内の各 3D オブジェクトを"コンポーネントの追加 メニューで、コンポーネントを検索して EyeTrackingTutorialDemo スクリプトを追加します。
   ![Lesson5 第 3 章の手順 3](images/Lesson5Chapter3Step3.JPG)

   4. オブジェクトをターゲットしている間にスピンします。 今回はで対象にしているときに迅速に作成する、3 D オブジェクトを構成します。 これを行うには、次の図に示すように、EyeTrackingTarget コンポーネントの「中に検索でターゲット」セクションでは、新しいフィールドを挿入します。 

![Lesson5 第 3 章 Step4a](images/Lesson5Chapter3Step4a.JPG)
![Lesson5 第 3 章 Step4b](images/Lesson5Chapter3Step4b.JPG)



新しく作成されたフィールドに、空のフィールドを現在のゲーム オブジェクトを追加し、EyeTrackingTutorialDemo を選択 > RotateTarget() 次の図に示すようにします。 今すぐ、3 D オブジェクトは、目の追跡時に gazed 中は、回転に構成されます。 

5. (エア タップ、または"select"という) を選択するで gazed 中は、"ブリップ target"を機能に追加します。 EyeTrackingTutorialDemo をトリガーする手順 4 と同様に、> 次の図に示すように、EyeTrackingTarget コンポーネントのゲーム オブジェクトの"Select()"フィールドに割り当てる BlipTarget() します。 ここで構成されているこのわかりますエア タップや音声コマンドなどの選択アクションをトリガーするたびに、ゲーム オブジェクトにわずかなブリップ「を選択します。」 
    ![Lesson5 第 3 章の手順 5](images/Lesson5Chapter3Step5.JPG)
6. HoloLens 2 にビルドする前に目の追跡機能が適切に構成を確認します。 本稿執筆、Unity はまだありません視線の先 (監視追跡) の入力機能を設定する機能。 この機能の設定は、目の追跡、HoloLens 2 で動作する必要があります。 視線入力機能を有効にする複合現実 toolkit のドキュメントでこれらの手順に従います。 https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_BasicSetup.html#testing-your-unity-app-on-a-hololens-2 


### <a name="congratulations"></a>これで終了です。 
追跡機能をアプリケーションに基本的な監視が追加されました。 これらのアクションは、視線で可能性の世界の先頭のみです。 この章では、レッスン 5、場所の学習、音声コマンドなどの高度な入力機能パン ジェスチャ、および監視の追跡も終了します。 

[次のレッスン:旧暦モジュール アセンブリ サンプル エクスペリエンス](mrlearning-base-ch6.md)

