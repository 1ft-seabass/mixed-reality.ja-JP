---
title: 入門チュートリアル-6. 詳細な入力オプションの調査
description: このコースを完了すると、Mixed Reality アプリケーション内で Azure 顔認識を実装する方法を学習することができます。
author: jessemcculloch
ms.author: jemccull
ms.date: 02/26/2019
ms.topic: article
keywords: Mixed Reality、Unity、チュートリアル、Hololens
ms.openlocfilehash: bb6aa620cebfda74b0b6b5f6ca04e1eeb68d9c7b
ms.sourcegitcommit: 6bc6757b9b273a63f260f1716c944603dfa51151
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 11/01/2019
ms.locfileid: "73438456"
---
# <a name="6-exploring-advanced-input-options"></a>6. 詳細な入力オプションを調査する

このチュートリアルでは、音声コマンド、パンジェスチャ、および視線追跡の使用を含む、HoloLens 2 の高度な入力オプションをいくつか紹介します。 

## <a name="objectives"></a>目標

- 音声コマンドとキーワードを使用してイベントをトリガーする
- 追跡したハンドを使用して、追跡したハンドでテクスチャと3D オブジェクトをパンする
- HoloLens 2 の監視機能を活用してオブジェクトを選択する

## <a name="instructions"></a>手順

### <a name="enabling-voice-commands"></a>音声コマンドの有効化

このセクションでは、2つの音声コマンドが実装されています。 まず、[診断の切り替え] を表示することによって、フレームレート診断パネルを切り替える機能が導入されました。 次に、音声コマンドでサウンドを再生する機能について説明します。 まず、音声コマンドの構成を担当する MRTK プロファイルと設定を確認します。 

1. 基本のシーン階層で、[MixedRealityToolkit] を選択します。 [インスペクター] パネルで、[システム設定の入力] まで下にスクロールします。 ダブルクリックして、入力システムプロファイルを開きます。 [レッスン 1](mrlearning-base-ch1.md)で学んだように、入力システムプロファイルを複製して編集可能にします。 

入力システムプロファイルには、さまざまな設定があります。 音声コマンドの場合は、[音声コマンドの設定] を選択します。 

![Lesson5 Chapter1 Step2im](images/Lesson5_Chapter1_step2im.PNG)

2. 「[レッスン 1](mrlearning-base-ch1.md)」で学習したように、speech コマンドプロファイルを複製して編集可能にします。 音声コマンドプロファイルをダブルクリックすると、さまざまな設定が表示されます。 これらの設定の詳細については、 [Mrtk speech のドキュメント](<https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/Input/Speech.html>)を参照してください。 

>注: 既定では、一般的な動作は [自動開始] です。 必要に応じて、これを手動で開始するように変更できます。 ただし、この例では、[自動開始] のままにしておきます。 MRTK には、メニュー、診断の切り替え、プロファイラーの切り替えなど、いくつかの既定の音声コマンドが付属しています。 診断フレームカウントカウンターをオンまたはオフにするために、キーワード "診断の切り替え" を使用します。 また、以下のステップで新しい音声コマンドを追加します。
>
> ![Lesson5 Chapter1 Noteim](images/Lesson5_chapter1_noteim.PNG)

3. 新しい音声コマンドを追加します。 これを行うには、[+ 新しい音声の追加] コマンドボタンをクリックします。 既存の音声コマンドの一覧の下に新しい行が表示されます。 使用する音声コマンドを入力します。 この例では、"play music" コマンドを使用します。

>ヒント: 音声コマンドのキーコードを設定することもできます。 これにより、音声コマンドを使用して、キーボードキーを押したときにイベントをトリガーできます。    

4. 音声コマンドに応答する機能を追加します。 他の入力スクリプトがアタッチされていないベースシーン階層内のオブジェクトを選択します (操作ハンドラーがないなど)。 [インスペクター] パネルで、[コンポーネントの追加] をクリックします。 「音声入力ハンドラ」と入力して選択します。

   ![Lesson5 Chapter1.txt Step4im](images/Lesson5_chapter1_step4im.PNG)

   

既定では、2つのチェックボックスが表示されます。 1つは [フォーカスが必要] チェックボックスです。 そのため、光を見つめ、ヘッドを見つめ、コントローラーを見つめ、または手動でオブジェクトをポイントしている限り、音声コマンドがトリガーされます。 ユーザーが音声コマンドを使用するためにオブジェクトを確認する必要がないように、このチェックボックスをオフにします。

5. 音声コマンドに応答する機能を追加します。 これを行うには、音声入力ハンドラーにある [+] ボタンをクリックし、応答するキーワードを選択します。

   > 注: これらのキーワードは、前の手順で編集したプロファイルに基づいて設定されます。

![Lesson5 Chapter1 Step5im](images/Lesson5_chapter1_step5im.PNG)

6. [キーワード] の横に、ドロップダウンメニューが表示されます。 [診断の切り替え] を選択すると、ユーザーが "診断の切り替え" という語句が表示されるたびに、アクションがトリガーされます。 要素0を展開するには、その横にある矢印を押す必要があることに注意してください。

![Lesson5 Chapter1 Step6im](images/Lesson5_chapter1_step6im.PNG)

7. 診断デモコントロールスクリプトを追加して、フレームレートカウンターの診断のオンとオフを切り替えます。 これを行うには、[コンポーネントの追加] をクリックし、[診断のデモコントロールスクリプト] を検索して、メニューから追加します。 このスクリプトは任意のオブジェクトに追加できます。 しかし、わかりやすくするために、音声入力ハンドラーと同じオブジェクトに追加します。 

   > 注: このスクリプトは、これらのモジュールにのみ含まれていますが、元の MRTK には含まれていません。

![Lesson5 Chapter1 Step7im](images/Lesson5_chapter1_step7im.PNG)

8. 音声入力ハンドラーに新しい応答を追加します。 これを行うには、の下の [+] ボタンをクリックします (上の図では、緑色の矢印でマークされています)。

![Lesson5 Chapter1 Step7im](images/Lesson5_chapter1_step8.PNG)

9. 診断デモコントロールスクリプトを含むオブジェクトを、手順 8. で作成した新しい応答にドラッグします。
    ![Lesson5 Chapter1 Step9im](images/Lesson5_chapter1_step9im.PNG)

10. [関数なし] ドロップダウンリストを選択し、次に診断デモコントロールを選択します。 次に、診断をオンまたはオフに切り替える "On トグル診断 ()" 関数を選択します。  ![Lesson5 Chapter1 Step10im](images/Lesson5_chapter1_step10im.PNG)
    
> デバイスにビルドする前に、mic 設定を有効にする必要があることに注意してください。 これを行うには、[ファイル] をクリックし、[ビルドの設定]、[プレーヤーの設定] の順にクリックし、マイクの機能が設定されていることを確認します

次に、Octa オブジェクトを使用して音声コマンドからオーディオファイルを再生する機能を追加します。 [レッスン 4](mrlearning-base-ch4.md)から、オーディオクリップを再生して、octa オブジェクトにタッチする機能が追加されたことを思い出してください。 この同じオーディオ ソースを、ミュージック音声コマンドでも活用します。

11. 基本のシーン階層で、Octa オブジェクトを選択します。

12. 別の音声入力ハンドラーを追加します (手順4と5を繰り返します)。ただし、octa オブジェクトを使用します。 

13. 手順6の [診断の切り替え] コマンドを追加するのではなく、次の図に示すように、[音楽音声の再生] コマンドを追加します。
    
     ![Lesson5 Chapter1 Step13im](images/Lesson5_chapter1_step13im.PNG)
    
    
    
14. 手順 8. と手順 9. と同様に、新しい応答を追加し、Octa オブジェクトを空の応答スロットにドラッグします。

15. [関数なし] というドロップダウンメニューを選択します。 次に、[オーディオソース]、[PlayOneShot (AudioClip)] の順に選択します。

![Lesson5 Chapter1 Step15im](images/Lesson5_chapter1_step15im.PNG)

16. この例では、[レッスン 4](mrlearning-base-ch4.md)と同じオーディオクリップを使用します。 プロジェクトパネルに移動し、"MRTK_Gem" オーディオクリップを検索して、次の図に示すようにオーディオソーススロットにドラッグします。 これで、アプリケーションは音声コマンド "トグル診断" に応答して、フレームレートカウンターパネルを切り替え、音楽を再生して MRTK_Gem 楽曲を再生します。
     ![Lesson5 Chapter1 Step16im](images/Lesson5_chapter1_step16im.PNG)


### <a name="the-pan-gesture"></a>パン ジェスチャ 

このセクションでは、パンジェスチャの使用方法について説明します。 これは、指またはハンドを使用してコンテンツをスクロールすることでスクロールする場合に便利です。 また、パンジェスチャを使用して、オブジェクトの回転、3D オブジェクトのコレクションの反復処理、または 2D UI のスクロールを行うこともできます。 また、パンジェスチャを使用してテクスチャをワープする方法と、3D オブジェクトのコレクションを移動する方法についても説明します。

1. quad を作成します。 基本のシーン階層で、右クリックし、[3D オブジェクト] を選択し、次にクワッドを選択します。

![Lesson5 Chapter2 Step2im](images/Lesson5_chapter2_step2im.PNG)

2. 必要に応じて、クワッドの位置を変更します。 この例では、HoloLens 2 から快適に使用できるように、x = 0、y = 0、z = 1.5 をカメラから離れた位置に設定します。

   > 注: 4 つのブロックまたはが前のレッスンの内容の前にある場合は、他のオブジェクトをブロックしないように注意してください。

3. 素材を quad に適用します。 この資料では、パンジェスチャを使用してスクロールします。 

![Lesson5 Chapter2 Step3im](images/Lesson5_chapter2_step3im.PNG)

4. [プロジェクト] パネルで、検索ボックスに「コンテンツのパン」と入力します。 その素材をシーンのクワッドにドラッグします。 

> 注: パンコンテンツマテリアルは MRTK には含まれていませんが、前のレッスンでインポートしたように、このモジュールの資産パッケージにアセットが含まれています。 

> 注: パンコンテンツを追加すると、拡大表示される場合があります。 これを修正するには、quad のサイズの x、y、z 値を希望する大きさになるまで調整します。

パン ジェスチャを使用するには、オブジェクト上のコライダーが必要です。 場合によっては、quad には既にメッシュ コライダーがあります。 ただし、メッシュ コライダーは極めて薄く、選択するのが容易ではないため理想的ではありません。 メッシュ コライダーをボックス コライダーに置き換えることをお勧めします。

5. [インスペクター] パネルから、クワッド上のメッシュ collider を右クリックします。 次に、[コンポーネントの削除] をクリックして削除します。
    ![Lesson5 Chapter2 Step5im](images/Lesson5_chapter2_step5im.PNG)
6. 次に、[コンポーネントの追加] をクリックして box collider を追加し、"box collider" を検索します。 既定で追加された box collider はまだ薄くなっているため、[Collider の編集] ボタンをクリックして編集します。 ボタンを押すと、x、y、z の値を使用して、またはシーン エディターの要素を使用してサイズを調整できます。 この例では、ボックス コライダーを quad の少し後ろまで拡張します。 シーン エディターで、ボックス コライダーを後ろから外側にドラッグします (下の図を参照してください)。 これにより、ユーザーは指を使用するだけでなく、スクロールすることもできます。 
    ![Lesson5 Chapter2 Step6im](images/Lesson5_chapter2_step6im.PNG)
7. 操作ができるようにします。 このモジュールを直接操作する必要があるので、ここではレッスン4で、Octa オブジェクトから音楽を再生するために使用した Near インタラクション Touchable コンポーネントを使用します。 [コンポーネントの追加] をクリックし、次の図に示すように "near インタラクション touchable" を検索して選択します。 

8. パン ジェスチャを認識する機能を追加します。 [コンポーネントの追加] をクリックし、「ハンドインタラクションのパン」と入力します。 [Hand Ray] (手の光線) (離れたところからパンできるようになる) と [Index Finger] (人差し指) の選択肢があります。 この例では、[Index Finger] (人差し指) のままにします。 
    ![Lesson5 Chapter2 Step7 8Im](images/Lesson5_chapter2_step7-8im.PNG)

![Lesson5 Chapter2 Step8im](images/Lesson5_chapter2_step8im.PNG)

9. 手書きのパンスクリプトでは、[水平方向のロック] と [垂直方向に固定] チェックボックスはそれぞれロックを解除します。 [テクスチャのラップ] 設定により、テクスチャ (テクスチャマッピング) がユーザーのパンの動きに従います。 この例では、チェックボックスをオンにします。 また、ベロシティがアクティブになっています。オフにすると、パンジェスチャは機能しません。 このボックスにもチェックを入れます。 これで、パン対応のクワッドが作成されます。

   

   次に、3D オブジェクトをパンする方法を学びます。 

10. クワッドオブジェクトを右クリックし、[3D オブジェクト] を選択して、[キューブ] をクリックします。 cube を、おおよそ x = 0.1、y = 0.1、z = 0.1 になるように大きさを調整します。 キューブを右クリックし、[複製] を押すか、ctrl + command D キーを押して、キューブを3回コピーします。 シーンは次の図のようになります。

![Lesson5 Chapter2 Step10im](images/Lesson5_chapter2_step10im.PNG)







11. もう一度クワッドを選択し、[ハンド対話] パンスクリプトで、各キューブにパンアクションを設定します。 [イベントレシーバーのパン] で、イベントを受け取るオブジェクトの数を指定します。 4つのキューブがあるため、「4」と入力し、enter キーを押します。 4つの空のフィールドが表示されます。


![Lesson5 Chapter2 Step11im](images/Lesson5_chapter2_step11im.PNG)



12. 各キューブをそれぞれ空の要素スロットにドラッグします。
     ![Lesson5 Chapter2 Step12im](images/Lesson5_chapter2_step12im.PNG)
    
13. Ctrl キーを押しながら command キーを押しながら各オブジェクトを選択することによって、すべてのキューブに移動するための Move スクリプトを追加します。 [インスペクター] パネルの [コンポーネントの追加] をクリックし、[move with pan] を検索します。 スクリプトをクリックすると、各キューブに追加されます。 これで、3D オブジェクトがパンジェスチャで移動します。 quad 上のメッシュの表示を削除した場合、非表示の quad があるはずで、3D オブジェクトのリストからそこにパンできます。

### <a name="eye-tracking"></a>視線追跡

このセクションでは、デモで目の追跡を有効にする方法について説明します。 3D メニュー項目が目の gazed になったときに、その項目をゆっくりと回転させます。 また、見つめられた項目が選択されると、楽しい効果がトリガーされるようにします。

1. MRTK プロファイルが正しく構成されていることを確認します。 執筆時点で、Mixed Reality ツールキット プロファイルの構成には、視線追跡機能は既定では含まれていません。 視線追跡機能を追加するには、 [Mixed Reality Toolkit のドキュメント](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_BasicSetup.html#setting-up-the-mrtk-profiles-required-for-eye-tracking  )で説明されているように、「視線追跡に必要な MRTK プロファイルを設定する」セクションの手順に従います。 上のドキュメントリンクの残りの手順に従って、視線追跡が適切に構成されていることを確認します。これには、GazeProvider (カメラに接続されているコンポーネント) での視線追跡の有効化や、Unity エディターでの視線追跡のシミュレーションの有効化などが含まれます。 MRTK の将来のバージョンには、既定で目の追跡が含まれる場合があることに注意してください。

    上記のリンクでは、以下の点についての簡潔な指示があります。

    - MRTK プロファイルで使用するための視線 Data Provider の作成
    - Gaze Provider で視線追跡を有効にする
    - エディターでの目の追跡シミュレーションの設定
    - Visual Studio ソリューションの機能を編集して、ビルド済みアプリケーションで視線追跡できるようにする

2. [Eye Tracking Target] (視線追跡ターゲット) コンポーネントをターゲット オブジェクトに追加します。 オブジェクトが視線イベントに応答できるようにするには、視線を使用して操作する各オブジェクトに EyeTrackingTarget コンポーネントを追加する必要があります。 このコンポーネントを、グリッド コレクションの一部である 9 つの 3D オブジェクトそれぞれに追加します。 ヒント: EyeTrackingTarget コンポーネントを一括で追加するには、階層内の複数の項目を選択します。
    ![Lesson5 Chapter3 Step2](images/Lesson5Chapter3Step2.JPG)

3. 次に、いくつかの魅力的な対話用に EyeTrackingTutorialDemo スクリプトを追加します。 EyeTrackingTutorialDemo スクリプトは、このチュートリアルシリーズリポジトリの一部として含まれています。 混合 Reality ツールキットには、既定では含まれていません。 Grid コレクション内の3D オブジェクトごとに、[コンポーネントの追加] メニューでコンポーネントを検索して、EyeTrackingTutorialDemo スクリプトを追加します。
   ![Lesson5 Chapter3 Step3](images/Lesson5Chapter3Step3.JPG)

4. ターゲットを見つめている間、オブジェクトを回転させます。 3D オブジェクトを見ている間にスピンするように構成したいと考えています。 これを行うには、次の図に示すように、EyeTrackingTarget コンポーネントの Target () セクションを参照しながら、に新しいフィールドを挿入します。 

![Lesson5 Chapter3 Step4a](images/Lesson5Chapter3Step4a.JPG)
![Lesson5 Chapter3 Step4b](images/Lesson5Chapter3Step4b.JPG)



新しく作成されたフィールドで、次の図に示すように、現在の Game オブジェクトを空のフィールドに追加し、EyeTrackingTutorialDemo > RotateTarget () を選択します。 これで、視線追跡により、3D オブジェクトを見つめると回転するように構成できました。 

5. エアタップによって、または "select" と言ったときに、選択時に gazed される "ブリップが発生 target" の機能を追加します。 手順4と同様に、次の図に示すように、EyeTrackingTarget コンポーネントの game オブジェクトの Select () フィールドに割り当てることによって、EyeTrackingTutorialDemo > をトリガーします。 これで構成が完了すると、エアタップや音声コマンドの "select" などの選択アクションをトリガーするたびに、game オブジェクトにわずかなブリップが発生が見られます。 
    ![Lesson5 Chapter3 Step5](images/Lesson5Chapter3Step5.JPG)
6. HoloLens 2 向けにビルドする前に、視線追跡機能が適切に構成されていることを確かめます。 このドキュメントの執筆時点では、Unity には、視線追跡機能に対して、宝石入力を設定する機能がまだありません。 この機能の設定は、監視が HoloLens 2 で動作するために必要です。 次の Mixed Reality ツールキット ドキュメントにある指示に従って、視線入力機能を有効にしてください。 https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_BasicSetup.html#testing-your-unity-app-on-a-hololens-2 


## <a name="congratulations"></a>結論

アプリケーションに基本的な監視機能が正常に追加されました。 これらの操作は、視線追跡が持つ可能性のほんの一部にすぎません。 また、レッスン5では、音声コマンド、パンジェスチャ、視線追跡などの高度な入力機能について学習しました。 

[次のレッスン: 7. 旧暦モジュールサンプルアプリケーションの作成](mrlearning-base-ch6.md)

