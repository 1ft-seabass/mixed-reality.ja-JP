---
title: Mixed Reality アプリケーションでのサウンドの使用
description: 空間サウンドは、mixed reality アプリケーションでの immersion、アクセシビリティ、UX の設計を行うための強力なツールです。
author: kegodin
ms.author: kegodin
ms.date: 11/02/2019
ms.topic: article
keywords: Windows Mixed Reality、空間サウンド、デザイン、スタイル
ms.openlocfilehash: c069095808eaa9d31b1ffa41dbaa29c9f635837b
ms.sourcegitcommit: 2e54d0aff91dc31aa0020c865dada3ae57ae0ffc
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 11/06/2019
ms.locfileid: "73641063"
---
# <a name="using-sound-in-mixed-reality-applications"></a><span data-ttu-id="398c2-104">Mixed Reality アプリケーションでのサウンドの使用</span><span class="sxs-lookup"><span data-stu-id="398c2-104">Using Sound in Mixed Reality Applications</span></span>

<span data-ttu-id="398c2-105">サウンドを使用して、ユーザーのアプリケーション状態のメンタルモデルを通知し、補強します。</span><span class="sxs-lookup"><span data-stu-id="398c2-105">Use sound to inform and reinforce the user's mental model of application state.</span></span> <span data-ttu-id="398c2-106">必要に応じて spatialization を使用して、サウンドを混合世界に配置します。</span><span class="sxs-lookup"><span data-stu-id="398c2-106">Use spatialization, when appropriate, to place sounds into the mixed world.</span></span> <span data-ttu-id="398c2-107">この方法で聴覚とビジュアルを接続することで、多くの相互作用を直感的に deepens し、ユーザーの信頼度を高めることができます。</span><span class="sxs-lookup"><span data-stu-id="398c2-107">Connecting the auditory and the visual in this way deepens the intuitive nature of many interactions and leads to increased user confidence.</span></span>

<br>

<iframe width="940" height="530" src="https://www.youtube.com/embed/aB3TDjYklmo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## <a name="when-should-i-add-sounds"></a><span data-ttu-id="398c2-108">サウンドを追加するタイミング</span><span class="sxs-lookup"><span data-stu-id="398c2-108">When should I add sounds?</span></span>
<span data-ttu-id="398c2-109">混合現実アプリケーションでは、物理インターフェイスがないため、多くの場合、2D 画面のアプリケーションよりも音が大きくなります。</span><span class="sxs-lookup"><span data-stu-id="398c2-109">Mixed reality applications often have a greater need for sounds than applications on a 2D screen, due to the lack of a physical interface.</span></span> <span data-ttu-id="398c2-110">ユーザーに通知する場合や、対話を補強する場合は、サウンドを追加する必要があります。</span><span class="sxs-lookup"><span data-stu-id="398c2-110">Sounds should be added when they inform the user or reinforce interactions.</span></span>

### <a name="inform-and-reinforce"></a><span data-ttu-id="398c2-111">通知と補強</span><span class="sxs-lookup"><span data-stu-id="398c2-111">Inform and reinforce</span></span>
* <span data-ttu-id="398c2-112">通知など、ユーザーによって開始されていないイベントについては、変更が発生したことをユーザーに通知するためにサウンドを追加することを検討してください。</span><span class="sxs-lookup"><span data-stu-id="398c2-112">For events not initiated by the user, such as notifications, consider adding sounds to inform the user that a change occurred.</span></span>
* <span data-ttu-id="398c2-113">相互作用には複数の段階があります。</span><span class="sxs-lookup"><span data-stu-id="398c2-113">Interactions may have several stages.</span></span> <span data-ttu-id="398c2-114">ステージの遷移を補強するには、サウンドを使用することを検討してください。</span><span class="sxs-lookup"><span data-stu-id="398c2-114">Consider using sounds to reinforce stage transitions.</span></span>

<span data-ttu-id="398c2-115">相互作用、イベント、および推奨されるサウンド特性の例については、以下を参照してください。</span><span class="sxs-lookup"><span data-stu-id="398c2-115">See below for examples of interactions, events, and suggested sound characteristics.</span></span>

### <a name="exercise-restraint"></a><span data-ttu-id="398c2-116">演習ガイド</span><span class="sxs-lookup"><span data-stu-id="398c2-116">Exercise restraint</span></span>
<span data-ttu-id="398c2-117">ユーザーは、オーディオ情報に対して無制限の容量を使用できません。</span><span class="sxs-lookup"><span data-stu-id="398c2-117">Users don't have an unlimited capacity for audio information:</span></span>
* <span data-ttu-id="398c2-118">各サウンドは、特定の重要な情報を伝達します。</span><span class="sxs-lookup"><span data-stu-id="398c2-118">Each sound should communicate a specific, valuable pieces of information</span></span>
* <span data-ttu-id="398c2-119">ユーザーに通知することを意図したサウンドを再生する場合は、一時的に他のサウンドの音量を下げる</span><span class="sxs-lookup"><span data-stu-id="398c2-119">When playing sounds meant to inform the user, temporarily reduce the volume of other sounds</span></span>
* <span data-ttu-id="398c2-120">ボタンをポイントしたときのサウンド (下記参照) では、音が過剰にトリガーされないように遅延時間を追加します。</span><span class="sxs-lookup"><span data-stu-id="398c2-120">For button hover sounds (see below), add a time delay to prevent excessive triggering of sounds</span></span>

### <a name="dont-rely-solely-on-sounds"></a><span data-ttu-id="398c2-121">サウンドだけに依存しない</span><span class="sxs-lookup"><span data-stu-id="398c2-121">Don't rely solely on sounds</span></span>
<span data-ttu-id="398c2-122">サウンドは、ユーザーが音声を聞くことはできますが、サウンドがオフの場合でもアプリケーションが使用可能であることを確認しておくと便利です。</span><span class="sxs-lookup"><span data-stu-id="398c2-122">Sounds used well will be valuable when your users can hear them, but ensure your application is usable even with the sound off.</span></span>
* <span data-ttu-id="398c2-123">ユーザーの聴覚が不自由である可能性がある</span><span class="sxs-lookup"><span data-stu-id="398c2-123">Users may be hearing impaired</span></span>
* <span data-ttu-id="398c2-124">アプリケーションは、大きな環境で使用できます。</span><span class="sxs-lookup"><span data-stu-id="398c2-124">Your application may be used in a loud environment</span></span>
* <span data-ttu-id="398c2-125">ユーザーは、デバイスオーディオを無効にするためのプライバシーまたはその他の理由を持っている可能性があります。</span><span class="sxs-lookup"><span data-stu-id="398c2-125">Users may have privacy or other reasons to disable the device audio</span></span>

## <a name="how-should-i-sonify-interactions"></a><span data-ttu-id="398c2-126">相互作用を sonify するにはどうすればよいですか。</span><span class="sxs-lookup"><span data-stu-id="398c2-126">How should I sonify interactions?</span></span>
<span data-ttu-id="398c2-127">混合現実の対話型には、ジェスチャ、直接操作、音声などがあります。</span><span class="sxs-lookup"><span data-stu-id="398c2-127">Interaction types in mixed reality include gesture, direct manipulation, and voice.</span></span> <span data-ttu-id="398c2-128">次の推奨される特性を使用して、これらのインタラクションのサウンドを選択または設計します。</span><span class="sxs-lookup"><span data-stu-id="398c2-128">Use the following suggested characteristics to select or design sounds for these interactions.</span></span>

### <a name="gesture-interactions"></a><span data-ttu-id="398c2-129">ジェスチャの相互作用</span><span class="sxs-lookup"><span data-stu-id="398c2-129">Gesture interactions</span></span>
<span data-ttu-id="398c2-130">Mixed reality では、ユーザーはカーソルを使用してボタンを操作できます。</span><span class="sxs-lookup"><span data-stu-id="398c2-130">In mixed reality, users can interact with buttons using a cursor.</span></span> <span data-ttu-id="398c2-131">ボタンの操作は、通常、ユーザーがボタンを押したときではなくボタンを離したときに実行され、ユーザーが操作をキャンセルできるようにします。</span><span class="sxs-lookup"><span data-stu-id="398c2-131">Button actions are generally performed when the user has released the button, rather than when it has been pressed, to allow the user a chance to cancel the interaction.</span></span> <span data-ttu-id="398c2-132">サウンドを使用して、これらのステージを補強します。</span><span class="sxs-lookup"><span data-stu-id="398c2-132">Use sounds to reinforce these stages.</span></span> <span data-ttu-id="398c2-133">また、離れた場所にあるボタンをユーザーがターゲットにできるようにするには、カーソルをポイントする音を使用することを検討してください。</span><span class="sxs-lookup"><span data-stu-id="398c2-133">Also, to assist users in targeting distant buttons, consider using a cursor hover sound.</span></span>
* <span data-ttu-id="398c2-134">ボタンを押す音には、短い tactile のクリックが必要です。</span><span class="sxs-lookup"><span data-stu-id="398c2-134">Button press sounds should have a short, tactile click.</span></span> <span data-ttu-id="398c2-135">例: [MRTK_ButtonPress](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MixedRealityToolkit.SDK/StandardAssets/Audio/MRTK_ButtonPress.wav)</span><span class="sxs-lookup"><span data-stu-id="398c2-135">Example: [MRTK_ButtonPress.wav](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MixedRealityToolkit.SDK/StandardAssets/Audio/MRTK_ButtonPress.wav)</span></span>
* <span data-ttu-id="398c2-136">ボタンの押されていない音には、同様の tactile 感が必要です。</span><span class="sxs-lookup"><span data-stu-id="398c2-136">Button unpress sounds should have a similar tactile feel.</span></span> <span data-ttu-id="398c2-137">ピッチと押されたピッチを持つと、完了の意味がわかります。</span><span class="sxs-lookup"><span data-stu-id="398c2-137">Having a raised pitch versus the press sound reinforces the sense of completion.</span></span> <span data-ttu-id="398c2-138">例: [MRTK_ButtonUnpress](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MixedRealityToolkit.SDK/StandardAssets/Audio/MRTK_ButtonUnpress.wav)</span><span class="sxs-lookup"><span data-stu-id="398c2-138">Example: [MRTK_ButtonUnpress.wav](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MixedRealityToolkit.SDK/StandardAssets/Audio/MRTK_ButtonUnpress.wav)</span></span>
* <span data-ttu-id="398c2-139">ホバーサウンドの場合は、低周波数の thud やバンプなど、微妙で脅威のないサウンドを使用することを検討してください。</span><span class="sxs-lookup"><span data-stu-id="398c2-139">For hover sounds, consider using a subtle and non-threatening sound such as a low-frequency thud or bump.</span></span>


### <a name="direct-manipulation"></a><span data-ttu-id="398c2-140">直接操作</span><span class="sxs-lookup"><span data-stu-id="398c2-140">Direct manipulation</span></span>
<span data-ttu-id="398c2-141">HoloLens 2 では、独自の追跡はユーザーインターフェイス要素の直接操作をサポートしています。</span><span class="sxs-lookup"><span data-stu-id="398c2-141">On HoloLens 2, articulated hand tracking supports direct manipulation of user interface elements.</span></span> <span data-ttu-id="398c2-142">サウンドは、物理的なフィードバックがない場合の重要な交換です。</span><span class="sxs-lookup"><span data-stu-id="398c2-142">Sounds are important replacements for the lack of physical feedback.</span></span>

<span data-ttu-id="398c2-143">ユーザーがキー移動の一番下に到達したことを物理的に示すことがないため、直接操作では**ボタンの押下**音が重要です。</span><span class="sxs-lookup"><span data-stu-id="398c2-143">A **button press** sound is important in direct manipulation because the user lacks physical indication of when they've reached the bottom of the key travel.</span></span> <span data-ttu-id="398c2-144">キー移動の視覚的なインジケーターは、小規模、軽度、occluded になることがあります。</span><span class="sxs-lookup"><span data-stu-id="398c2-144">Visual indicators of key travel can be small, subtle, and occluded.</span></span> <span data-ttu-id="398c2-145">ジェスチャによる対話と同様に、ボタンを押すには、tactile のような短い音が必要です。また、押されていない場合は、[ピッチ] をクリックした場合と同様のクリックが発生します。</span><span class="sxs-lookup"><span data-stu-id="398c2-145">As with gesture interactions, button presses should have a short, tactile sound like a click, and unpresses should have a similar click with raised pitch.</span></span>
* <span data-ttu-id="398c2-146">例: [MRTK_ButtonPress](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MixedRealityToolkit.SDK/StandardAssets/Audio/MRTK_ButtonPress.wav)</span><span class="sxs-lookup"><span data-stu-id="398c2-146">Example: [MRTK_ButtonPress.wav](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MixedRealityToolkit.SDK/StandardAssets/Audio/MRTK_ButtonPress.wav)</span></span>
* <span data-ttu-id="398c2-147">例: [MRTK_ButtonUnpress](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MixedRealityToolkit.SDK/StandardAssets/Audio/MRTK_ButtonUnpress)</span><span class="sxs-lookup"><span data-stu-id="398c2-147">Example: [MRTK_ButtonUnpress.wav](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MixedRealityToolkit.SDK/StandardAssets/Audio/MRTK_ButtonUnpress)</span></span>

<span data-ttu-id="398c2-148">直接操作で**グラブ**または**リリース**を確認することは、視覚的に通信するのは困難です。</span><span class="sxs-lookup"><span data-stu-id="398c2-148">Confirming a **grab** or **release** in direct manipulation is difficult to communicate visually.</span></span> <span data-ttu-id="398c2-149">多くの場合、ユーザーの手は視覚効果の高い方法であり、ハードハンドオブジェクトには "グラブ" という実際の視覚的な類似性がありません。</span><span class="sxs-lookup"><span data-stu-id="398c2-149">The user's hand will often be in the way of any visual effect, and hard-bodied objects lack a real-world visual analogue of "grabbing".</span></span> <span data-ttu-id="398c2-150">これに対し、サウンドは、成功したグラブとリリースの相互作用を効果的に伝えることができます。</span><span class="sxs-lookup"><span data-stu-id="398c2-150">In contrast, sounds can effectively communicate successful grab and release interactions.</span></span>
* <span data-ttu-id="398c2-151">グラブアクションには、オブジェクトの周りを閉じる指の概念を evokes する、少し muffled tactile サウンドが必要です。</span><span class="sxs-lookup"><span data-stu-id="398c2-151">Grab actions should have a short, somewhat muffled tactile sound that evokes the idea of fingers closing around an object.</span></span> <span data-ttu-id="398c2-152">場合によっては、音が出たときの動きを通知する音が "whoosh" サウンドによって示されることもあります。</span><span class="sxs-lookup"><span data-stu-id="398c2-152">Sometimes this is accompanied by a "whoosh" sound leading up to the impact of the sound to communicate the motion of the hand when grabbing.</span></span> <span data-ttu-id="398c2-153">例: [MRTK_Move_Start](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MixedRealityToolkit.SDK/StandardAssets/Audio/MRTK_Move_Start.wav)</span><span class="sxs-lookup"><span data-stu-id="398c2-153">Example: [MRTK_Move_Start.wav](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MixedRealityToolkit.SDK/StandardAssets/Audio/MRTK_Move_Start.wav)</span></span>
* <span data-ttu-id="398c2-154">リリースアクションには同様の短いサウンドと tactile サウンドが必要です。通常は、グラブのサウンドと逆の順序で、影響を与え、"whoosh" によってオブジェクトが所定の位置に向かっていることを通知します。</span><span class="sxs-lookup"><span data-stu-id="398c2-154">Release actions should have a similarly short and tactile sound, usually pitched down from the grab sound and in a reverse order in time, having an impact and then a "whoosh" to communicate the object settling into place.</span></span> <span data-ttu-id="398c2-155">例: [MRTK_Move_End](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MixedRealityToolkit.SDK/StandardAssets/Audio/MRTK_Move_End.wav)</span><span class="sxs-lookup"><span data-stu-id="398c2-155">Example: [MRTK_Move_End.wav](https://github.com/microsoft/MixedRealityToolkit-Unity/tree/mrtk_development/Assets/MixedRealityToolkit.SDK/StandardAssets/Audio/MRTK_Move_End.wav)</span></span>

<span data-ttu-id="398c2-156">**描画**の相互作用には、ユーザーの手の動きによってボリュームが制御される、ループした永続的なサウンドが必要です。また、ユーザーの手が出てきたときには、完全に無音になっています。</span><span class="sxs-lookup"><span data-stu-id="398c2-156">A **drawing** interaction should have a looping, persistent sound that has its volume controlled by the movement of the user's hand, with it being completely silent when the user's hand is still, and at its maximum volume when the user's hand is moving quickly.</span></span>



### <a name="voice-interactions"></a><span data-ttu-id="398c2-157">音声操作</span><span class="sxs-lookup"><span data-stu-id="398c2-157">Voice interactions</span></span>
<span data-ttu-id="398c2-158">音声のやり取りには、微妙な視覚要素があることがよくあります。</span><span class="sxs-lookup"><span data-stu-id="398c2-158">Voice interactions often have subtle visual elements.</span></span> <span data-ttu-id="398c2-159">サウンドを使用して相互作用ステージを補強します。</span><span class="sxs-lookup"><span data-stu-id="398c2-159">Reinforce the interaction stages using sounds.</span></span> <span data-ttu-id="398c2-160">ジェスチャや直接操作サウンドと区別するために、より多くの色調音を選択することを検討してください。</span><span class="sxs-lookup"><span data-stu-id="398c2-160">Consider choosing more tonal sounds to distinguish them from gesture and direct manipulation sounds.</span></span>

* <span data-ttu-id="398c2-161">音声コマンドの確認には、正の音を**使用します**。</span><span class="sxs-lookup"><span data-stu-id="398c2-161">Use a positive-sounding tone for voice command **confirmations**.</span></span> <span data-ttu-id="398c2-162">この時点では、増加している色調と主な音楽の間隔が効果的です。</span><span class="sxs-lookup"><span data-stu-id="398c2-162">Rising tones and major musical intervals are effective at this.</span></span>
* <span data-ttu-id="398c2-163">音声コマンドの**エラー**に対して、より短い、負でない音の調子を使用します。</span><span class="sxs-lookup"><span data-stu-id="398c2-163">Use a shorter, less-positive sounding tone for voice command **failure**.</span></span> <span data-ttu-id="398c2-164">負の音は避けてください。代わりに、percussive のニュートラルサウンドを使用して、アプリケーションが相互作用から移動していることを伝えます。</span><span class="sxs-lookup"><span data-stu-id="398c2-164">Avoid negative sounds; instead, use a more percussive, neutral sound to communicate the application is moving on from the interaction.</span></span>
* <span data-ttu-id="398c2-165">アプリケーションでウェイクワードを使用している場合は、デバイスが**リッスンを開始**したときに短時間で、すぐに聞こえ、アプリケーションがリッスンしている間は微妙なループサウンドを使用します。</span><span class="sxs-lookup"><span data-stu-id="398c2-165">If your application uses a wake word, use a short, gentle tone when the device has **started listening**, and a subtle looping sound while the application listens.</span></span> 

### <a name="notifications"></a><span data-ttu-id="398c2-166">通知</span><span class="sxs-lookup"><span data-stu-id="398c2-166">Notifications</span></span>
<span data-ttu-id="398c2-167">通知は、アプリケーションの状態の変化や、ユーザーによって開始されていないその他のイベント (プロセスの完了、メッセージ、呼び出しなど) を伝えます。</span><span class="sxs-lookup"><span data-stu-id="398c2-167">Notifications communicate application state changes and other events not initiated by the user, such as process completions, messages, and calls.</span></span>

<span data-ttu-id="398c2-168">Mixed reality では、移動するオブジェクトをユーザーのビューのフィールドから移動できます。</span><span class="sxs-lookup"><span data-stu-id="398c2-168">In mixed reality, objects that move can move out of the user's field of view.</span></span> <span data-ttu-id="398c2-169">アニメーション化された**オブジェクト**には、オブジェクトとモーションの速度に依存する spatialized サウンドが付属しています。</span><span class="sxs-lookup"><span data-stu-id="398c2-169">Accompany **animated objects** with a spatialized sound that depends on the object and speed of motion.</span></span>
* <span data-ttu-id="398c2-170">また、アニメーションの最後に spatialized サウンドを再生して、新しい位置をユーザーに通知することもできます。</span><span class="sxs-lookup"><span data-stu-id="398c2-170">It also helps to play a spatialized sound at the end of an animation to inform the user of the new position</span></span>
* <span data-ttu-id="398c2-171">段階的な移動では、移動中に "whoosh" サウンドを使用すると、ユーザーがオブジェクトを追跡できます。</span><span class="sxs-lookup"><span data-stu-id="398c2-171">For gradual movements, a "whoosh" sound during movement will help the user track the object</span></span>

<span data-ttu-id="398c2-172">多くの場合、**メッセージ通知**は数回通知されます。また、場合によっては、連続して発生することもあります。</span><span class="sxs-lookup"><span data-stu-id="398c2-172">**Message notifications** will most likely be heard several times, and sometimes in quick succession.</span></span> <span data-ttu-id="398c2-173">非常に注意してください。または、過酷なことはありません。</span><span class="sxs-lookup"><span data-stu-id="398c2-173">It's important that it doesn't stand out or sound harsh.</span></span> <span data-ttu-id="398c2-174">ここでは、中間範囲の正の色調音が効果的です。</span><span class="sxs-lookup"><span data-stu-id="398c2-174">Mid-range positive tonal sounds are effective here.</span></span>

* <span data-ttu-id="398c2-175">呼び出しは、携帯電話の着信音と同様の品質を持つ必要があります。</span><span class="sxs-lookup"><span data-stu-id="398c2-175">Calls should have similar qualities to a cell phone ringtone.</span></span> <span data-ttu-id="398c2-176">これらは通常、ユーザーが通話に応答するまで再生されるミュージックフレーズをループします。</span><span class="sxs-lookup"><span data-stu-id="398c2-176">These are usually looping musical phrases that play until the user has answered the call.</span></span>
* <span data-ttu-id="398c2-177">音声通信の接続と切断には、短時間の色調音が必要です。</span><span class="sxs-lookup"><span data-stu-id="398c2-177">Voice communication connection and disconnection should have a short, tonal sound.</span></span> <span data-ttu-id="398c2-178">接続サウンドには、接続が成功したことを示す正の音が必要です。また、切断音は、呼び出しの完了を示すニュートラルサウンドである必要があります。</span><span class="sxs-lookup"><span data-stu-id="398c2-178">The connection sound should have a positive tone, indicating the successful connection, while the disconnection sound should be a neutral sound indicating completion of the call.</span></span>

## <a name="spatialization"></a><span data-ttu-id="398c2-179">Spatialization</span><span class="sxs-lookup"><span data-stu-id="398c2-179">Spatialization</span></span>
<span data-ttu-id="398c2-180">Spatialization は、ステレオヘッドホンまたはスピーカーを使用して、混合世界にサウンドを配置します。</span><span class="sxs-lookup"><span data-stu-id="398c2-180">Spatialization uses stereo headphones or speakers to place sounds into the mixed world.</span></span>

### <a name="which-sounds-should-i-spatialize"></a><span data-ttu-id="398c2-181">どのようなサウンドを spatialize ばよいでしょうか。</span><span class="sxs-lookup"><span data-stu-id="398c2-181">Which sounds should I spatialize?</span></span>
<span data-ttu-id="398c2-182">空間位置を持つイベントに関連付けられている場合は、サウンドを spatialized する必要があります。</span><span class="sxs-lookup"><span data-stu-id="398c2-182">A sound should be spatialized when it's associated with an event that has a spatial location.</span></span> <span data-ttu-id="398c2-183">これには、UI、埋めを行う AI 音声、および視覚的インジケーターが含まれます。</span><span class="sxs-lookup"><span data-stu-id="398c2-183">This includes UI, embodied AI voices, and visual indicators.</span></span>

<span data-ttu-id="398c2-184">Spatializing**ユーザーインターフェイス**要素は、ヘッドにロックされているステレオサウンドの数を制限することで、ユーザーの sonic "space" をまとめするのに役立ちます。</span><span class="sxs-lookup"><span data-stu-id="398c2-184">Spatializing **user interface** elements helps declutter the user's sonic "space" by limiting the number of stereo sounds locked to their heads.</span></span> <span data-ttu-id="398c2-185">特に直接操作の対話では、音声フィードバックが spatialized されると、タッチ、グラブ、および解放がより自然になります。</span><span class="sxs-lookup"><span data-stu-id="398c2-185">Especially in direct manipulation interactions, touching, grabbing, and releasing feels more natural when audio feedback is spatialized.</span></span> <span data-ttu-id="398c2-186">ただし、これらの要素の距離の減衰については、以下を参照してください。</span><span class="sxs-lookup"><span data-stu-id="398c2-186">However, see below regarding distance attenuation for these elements.</span></span>

<span data-ttu-id="398c2-187">Spatializing の**視覚的なインジケーター**と埋めを行う AI の音声は、ユーザーがビューのフィールドの外部にあるときに、直感的にユーザーに通知します。</span><span class="sxs-lookup"><span data-stu-id="398c2-187">Spatializing **visual indicators** and **_embodied_ AI voices** intuitively informs users when they are outside the field of view.</span></span>
    
<span data-ttu-id="398c2-188">これに対して、  **_faceless_ AI の音声**と、適切に定義された空間の場所を持たないその他の要素の spatialization は避けてください。</span><span class="sxs-lookup"><span data-stu-id="398c2-188">In contrast, avoid spatialization for **_faceless_ AI voices**, and other elements without a well-defined spatial location.</span></span> <span data-ttu-id="398c2-189">関連するビジュアル要素のない Spatialization は、ユーザーが見つけられない視覚的な要素があると考えることができないようにします。</span><span class="sxs-lookup"><span data-stu-id="398c2-189">Spatialization without a related visual element can distract users into thinking there is a visual element that they can't find.</span></span>

<span data-ttu-id="398c2-190">Spatialization を追加すると、CPU コストが発生します。</span><span class="sxs-lookup"><span data-stu-id="398c2-190">Adding spatialization will come with some CPU cost.</span></span> <span data-ttu-id="398c2-191">多くのアプリケーションは同時に2つのサウンドを再生します。</span><span class="sxs-lookup"><span data-stu-id="398c2-191">Many applications will have, at most, two sounds playing simultaneously.</span></span> <span data-ttu-id="398c2-192">この場合、spatialization のコストはごくわずかです。</span><span class="sxs-lookup"><span data-stu-id="398c2-192">The cost of spatialization in that case can be negligible.</span></span> <span data-ttu-id="398c2-193">MRTK のフレームレートモニターを使用して、spatialization を追加した場合の影響を判断できます。</span><span class="sxs-lookup"><span data-stu-id="398c2-193">You can use the MRTK frame rate monitor to judge the impact of adding spatialization.</span></span> 

### <a name="when-and-how-should-i-apply-distance-based-attenuation"></a><span data-ttu-id="398c2-194">距離ベースの減衰を適用するタイミングと方法</span><span class="sxs-lookup"><span data-stu-id="398c2-194">When and how should I apply distance-based attenuation?</span></span>
<span data-ttu-id="398c2-195">物理的な世界では、遠く離れている音はより静かです。</span><span class="sxs-lookup"><span data-stu-id="398c2-195">In the physical world, sounds that are farther away are quieter.</span></span> <span data-ttu-id="398c2-196">オーディオエンジンは、ソースの距離に基づいてこの減衰をモデル化できます。</span><span class="sxs-lookup"><span data-stu-id="398c2-196">Your audio engine can model this attenuation based on the source distance.</span></span> <span data-ttu-id="398c2-197">関連情報を通信するときは、距離ベースの減衰を使用します。</span><span class="sxs-lookup"><span data-stu-id="398c2-197">Use distance-based attenuation when it communicates relevant information.</span></span>

<span data-ttu-id="398c2-198">**視覚的なインジケーター**、アニメーション化された**ホログラム**、およびその他の情報音への距離は、通常、ユーザーに関連します。</span><span class="sxs-lookup"><span data-stu-id="398c2-198">The distances to **visual indicators**, **animated holograms**, and other informative sounds are usually relevant to the user.</span></span> <span data-ttu-id="398c2-199">距離ベースの減衰を使用して、このキューを直感的に提供します。</span><span class="sxs-lookup"><span data-stu-id="398c2-199">Use distance-based attenuation to intuitively provide this cue.</span></span>
* <span data-ttu-id="398c2-200">各ソースの減衰曲線を、混合ワールドスペースのサイズに合わせて調整します。</span><span class="sxs-lookup"><span data-stu-id="398c2-200">Adjust the attenuation curve for each source to fit the size of your mixed world spaces.</span></span> <span data-ttu-id="398c2-201">オーディオエンジンの既定の曲線は、多くの場合、非常に大きい (最大ハーフ kilometer) スペース用です。</span><span class="sxs-lookup"><span data-stu-id="398c2-201">Your audio engine's default curve is often meant for very large (up to half-kilometer) spaces.</span></span>

<span data-ttu-id="398c2-202">ボタンやその他の対話の段階的な**段階**を補強する音は、減衰が適用されないようにする必要があります。</span><span class="sxs-lookup"><span data-stu-id="398c2-202">Sounds that reinforce the **progressive stages of buttons** and other interactions shouldn't have attenuation applied.</span></span> <span data-ttu-id="398c2-203">これらのサウンドの強化された効果は、通常、ボタンへの距離を伝えるよりも重要です。</span><span class="sxs-lookup"><span data-stu-id="398c2-203">The reinforcing effects of these sounds are generally more important than communicating the distance to the button.</span></span> <span data-ttu-id="398c2-204">バリエーションは、特にキーボードを使用すると、多くのボタンのクリックが連続して聞こえます。</span><span class="sxs-lookup"><span data-stu-id="398c2-204">Variations can be distracting, especially with keyboards, where many button clicks will be heard in succession.</span></span>

### <a name="which-spatialization-technology-should-i-use"></a><span data-ttu-id="398c2-205">どの spatialization テクノロジを使用すればよいでしょうか。</span><span class="sxs-lookup"><span data-stu-id="398c2-205">Which spatialization technology should I use?</span></span>
<span data-ttu-id="398c2-206">ヘッドホンまたは HoloLens スピーカーを使用する場合は、HRTF (head 関連の転送関数) ベースの spatialization テクノロジを使用します。</span><span class="sxs-lookup"><span data-stu-id="398c2-206">When using headphones or the HoloLens speakers, use HRTF (head-related transfer function)-based spatialization technologies.</span></span> <span data-ttu-id="398c2-207">これらは、物理的な世界でのヘッドの周りにおけるサウンド伝達をモデル化します。</span><span class="sxs-lookup"><span data-stu-id="398c2-207">They model the sound propagation around the head in the physical world.</span></span> <span data-ttu-id="398c2-208">サウンドソースが一番上にある場合でも、サウンドは減衰と遅延によって遠くの耳に伝達されます。</span><span class="sxs-lookup"><span data-stu-id="398c2-208">Even when a sound source is far on one side of the head, sound propagates to the distant ear with some attenuation and delay.</span></span> <span data-ttu-id="398c2-209">これに対して、スピーカーパンは減衰にのみ依存し、サウンドが右側にあるときは左の耳に合計の減衰を適用します (逆の場合もあります)。</span><span class="sxs-lookup"><span data-stu-id="398c2-209">Speaker panning, in contrast, relies only on attenuation, and applies total attenuation in the left ear when sounds are on the right side (and vice-versa).</span></span> <span data-ttu-id="398c2-210">これは、通常の聴覚のリスナーでは不快になる可能性があり、1つの耳で聴覚障害があるリスナーにはアクセスできません。</span><span class="sxs-lookup"><span data-stu-id="398c2-210">This can be uncomfortable for normal-hearing listeners, and inaccessible for listeners with hearing impairment in one ear.</span></span>

## <a name="next-steps"></a><span data-ttu-id="398c2-211">次のステップ</span><span class="sxs-lookup"><span data-stu-id="398c2-211">Next steps</span></span>
* [<span data-ttu-id="398c2-212">Unity で空間サウンドを使用する</span><span class="sxs-lookup"><span data-stu-id="398c2-212">Use spatial sound in Unity</span></span>](spatial-sound-in-unity.md)
* [<span data-ttu-id="398c2-213">Roboraid のケーススタディ</span><span class="sxs-lookup"><span data-stu-id="398c2-213">Case study of Roboraid</span></span>](case-study-using-spatial-sound-in-roboraid.md)
* [<span data-ttu-id="398c2-214">HoloTour のケーススタディ</span><span class="sxs-lookup"><span data-stu-id="398c2-214">Case study of HoloTour</span></span>](case-study-spatial-sound-design-for-holotour.md)

