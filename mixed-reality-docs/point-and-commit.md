---
title: 手を使ったポイントとコミット
description: ポイントとコミットの入力モデルの概要
author: caseymeekhof
ms.author: cmeekhof
ms.date: 04/05/2019
ms.topic: article
ms.localizationpriority: high
keywords: Mixed Reality, 対話, 設計, hololens, 手, 遠隔, ポイントとコミット
ms.openlocfilehash: 4e19a7fd95bac42283ce3e3176a1363afda8f220
ms.sourcegitcommit: d8700260f349a09c53948e519bd6d8ed6f9bc4b4
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 06/27/2019
ms.locfileid: "67414537"
---
# <a name="point-and-commit-with-hands"></a>手を使ったポイントとコミット
手を使ったポイントとコミットは、ユーザーが遠くにある 2D コンテンツや 3D オブジェクトをターゲットに設定したり、選択したり、操作したりすることを可能にする入力モデルです。 この「遠隔」対話技術は Mixed Reality に固有のものであり、人間が現実の世界と自然に対話するためのものではありません。 たとえば、スーパー ヒーロー映画 *X-Men* のキャラクター [Magneto ](https://en.wikipedia.org/wiki/Magneto_(comics)) は、遠くにある物体に手を伸ばして操作することができます。 こうしたことは現実世界では行えません。 HoloLens (AR) と Mixed Reality (MR) を使用することで、この魔法の力をユーザーに付与してホログラフィック コンテンツをただ楽しむだけでなく、ユーザーの対話をより効果的かつ効率的にするために現実世界の物理的制約を打ち破ることができます。

## <a name="device-support"></a>デバイスのサポート

<table>
<colgroup>
    <col width="33%" />
    <col width="22%" />
    <col width="22%" />
    <col width="22%" />
</colgroup>
<tr>
     <td><strong>入力モデル</strong></td>
     <td><a href="hololens-hardware-details.md"><strong>HoloLens (第 1 世代)</strong></a></td>
     <td><strong>HoloLens 2</strong></td>
     <td><a href="immersive-headset-hardware-details.md"><strong>イマーシブ ヘッドセット</strong></a></td>
</tr>
<tr>
     <td>手を使ったポイントとコミット</td>
     <td>❌ サポート外</td>
     <td>✔️ 推奨</td>
     <td>✔️ 推奨</td>
</tr>
</table>


ポイントとコミットは、ハンズ ファーと呼ばれることもあります。これは、新しい多関節ハンド トラッキング システムを利用した新機能の 1 つです。 この入力モデルは、モーション コントローラーを使用したイマーシブ ヘッドセットの主要な入力モデルでもあります。

## <a name="hand-rays"></a>手の光線

HoloLens 2 では、ユーザーの手のひらの中心から放出される手の光線を考案しました。 この光線は、手の延長と見なされます。 光線がターゲット オブジェクトと交わる場所を示すために、光線の終端にドーナツ型のカーソルが取り付けられています。 カーソルが届いているオブジェクトは、手から出されるジェスチャ コマンドを受け取ることができます。

この基本的なジェスチャ コマンドは、親指と人差し指を使ってエアタップ アクションを実行してトリガーされます。 手の光線を使用してポイントし、エアタップを使用してコミットすることで、ユーザーはボタンまたはハイパーリンクを有効にすることができます。 ユーザーは、より複合的なジェスチャを使うことで、Web コンテンツをナビゲートしたり、遠くから 3D オブジェクトを操作したりすることができます。 以下に説明および図示されているように、手の光線の視覚的なデザインも、これらのポイントとコミット状態に合わせて変化します。 

* *ポイント*状態の光線は破線で表され、カーソルはドーナツ型になります。
* *コミット*状態になると光線は実線に変わり、カーソルは小さくなってドットになります。

![手の光線のポインティングとコミットの状態](images/Hand-Rays-720px.jpg)<br>
*手の光線のポインティング (左) とコミット (右) の状態*

## <a name="transition-between-near-and-far"></a>近くと遠くの切り替え

「人差し指で指す」ことで光線を方向付けるなどの特定のジェスチャを使用する代わりに、手のひらの中心から光線が出るように設計しました。これにより、5 本の指を解放して、より操作的なジェスチャ (ピンチやグラブなど) を行うために取っておくことができます。 この設計では、メンタル モデルを 1 つだけ作りました。これにより、近くでも遠くでもまったく同じ一連の手のジェスチャで対話することができます。 同じグラブ ジェスチャで、距離が異なるオブジェクトを操作できます。 光線の呼び出しは、次のように近さに基づいて自動で行われます。

*  腕の長さ (約 50 cm) の範囲内にオブジェクトが入ると光線は自動的に消え、近接の対話が勧められます。
*  オブジェクトとの距離が 50 cm を超えると、光線が点灯します。 切り替えはスムーズかつシームレスに行われます。

![近くでも遠くでも同じ一連の手のジェスチャが使用されます](images/Transition-Between-Near-And-Far-720px.jpg)<br>
*近くでも遠くでも同じ一連の手のジェスチャが使用されます。*

## <a name="2d-slate-interaction"></a>2D スレートとの対話

2D スレートは、Web ブラウザーなどの 2D アプリ コンテンツをホストするホログラフィック コンテナーです。 2D スレートとの遠隔対話の設計概念は、手の光線を使ってターゲット設定し、エアタップで選択するというものです。 手の光線でターゲット設定した後、ユーザーはエアタップしてハイパーリンクまたはボタンをトリガーできます。 片手で「エアタップ アンド ドラッグ」して、スレートのコンテンツを上下にスクロールすることができます。 両手を使ってエアタップ アンド ドラッグするという相対的な動きにより、スレートのコンテンツを拡大縮小することができます。

手の光線を隅や端にターゲット設定すると、最も近くにある操作アフォーダンスが表示されます。 ユーザーは操作アフォーダンスを「グラブ アンド ドラッグ」することで、隅のアフォーダンスによって均等に拡大縮小したり、端のアフォーダンスによってスレートをリフローしたりできます。 2D スレートの上部にあるホロバーをグラブ アンド ドラッグすることで、ユーザーはスレート全体を移動できます。

![2D スレートとの対話](images/2D-Slate-Interaction-Far-720px.jpg)

2D スレートの操作方法は、次のとおりです。<br>

* ユーザーは、手の光線を隅または端にポイントして、最も近くにある操作アフォーダンスを表示します。 
* アフォーダンスに操作ジェスチャを適用すれば、ユーザーは隅のアフォーダンスによって均等に拡大縮小したり、端のアフォーダンスによってスレートをリフローしたりできます。 
* 2D スレートの上部にあるホロバーに操作ジェスチャを適用することで、ユーザーはスレート全体を移動できます。<br>

<br>

## <a name="3d-object-manipulation"></a>3D オブジェクトの操作

直接操作では、ユーザーは、アフォーダンスをベースとする操作とアフォーダンスをベースとしない操作の 2 つの方法で 3D オブジェクトを操作できます。 ポイントとコミットのモデルでは、ユーザーは手の光線を使ってまったく同じ作業を行えます。 学ばなければならないことは他にありません。<br>

### <a name="affordance-based-manipulation"></a>アフォーダンスをベースとする操作
ユーザーは手の光線を使用して、境界ボックスと操作アフォーダンスをポイントし、表示します。 ユーザーは操作ジェスチャを境界ボックスに適用してオブジェクト全体を移動したり、端のアフォーダンスに適用して回転させたり、隅のアフォーダンスに適用して均等に拡大縮小したりすることができます。 <br>

![アフォーダンスをベースとする操作](images/3D-Object-Manipulation-Far-720px.jpg) <br>


### <a name="non-affordance-based-manipulation"></a>アフォーダンスをベースとしない操作
ユーザーは手の光線を使ってポイントし、境界ボックスを表示した後、直接操作ジェスチャを適用します。 片手を使用する場合、オブジェクトの移動と回転は手の動きと向きに関連付けられます。 ユーザーが両手を使用すると、両手の相対的な動きに応じてそれを移動、拡大縮小、回転できます。<br>

<br>

## <a name="instinctual-gestures"></a>本能的なジェスチャ
ポイントとコミットについての本能的なジェスチャの概念は、[手による直接操作](direct-manipulation.md)の概念と似ています。 ユーザーが 3D オブジェクトに対して実行するジェスチャは、UI アフォーダンスの設計によって導かれます。 たとえば、小さな制御点の場合にはユーザーは親指と人差し指でピンチするよう誘導されるのに対し、大きなオブジェクトの場合は 5 本の指すべてを使ってつかむかもしれません。

![本能的なジェスチャ](images/Instinctual-Gestures-Far-720px.jpg)<br>

## <a name="symmetric-design-between-hands-and-6-dof-controller"></a>手と 6 DoF コントローラーの間の対称設計 
遠くにあるものと対話する場合のポイントとコミットの概念は当初、Mixed Reality ポータル (MRP) 向けに考案され、定義されました。MRP では、ユーザーはイマーシブ ヘッドセットを装着し、モーション コントローラーを介して 3D オブジェクトとやり取りします。 モーション コントローラーは、遠くにあるオブジェクトをポイントして操作するために光線を放ちます。 コントローラーにはボタンがあって、さまざまな操作をさらにコミットします。 光線の対話モデルを利用して、それを両手で利用することにしました。 この対称設計により、MRP に精通しているユーザーは HoloLens 2 を使用するとき、遠くにあるものをポイントして操作するための別の対話モデルを学ぶ必要がなくなります (逆も同様です)。    

![手と 6 DoF コントローラーの間の対称設計](images/Symmetric-Design-For-Rays-720px.jpg)<br>


## <a name="see-also"></a>関連項目
* [頭の視線入力とコミット](gaze-and-commit.md)
* [手で直接操作](direct-manipulation.md)
* [本能的な操作](interaction-fundamentals.md)

