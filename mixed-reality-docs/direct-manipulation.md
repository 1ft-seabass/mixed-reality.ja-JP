---
title: 手で直接操作
description: 直接操作入力モデルの概要
author: caseymeekhof
ms.author: cmeekhof
ms.date: 04/02/2019
ms.topic: article
ms.localizationpriority: high
keywords: Mixed Reality, 視線入力, 視線入力ターゲット設定, 対話, 設計, 手に近い, HoloLens
ms.openlocfilehash: 8047d7549309d293b805dc43e44da99f9139e5c6
ms.sourcegitcommit: d8700260f349a09c53948e519bd6d8ed6f9bc4b4
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 06/27/2019
ms.locfileid: "67414444"
---
# <a name="direct-manipulation-with-hands"></a>手で直接操作
直接操作は、ホログラムに手で直接触れる入力モデルです。 直接操作の背景にある考え方は、オブジェクトを現実の世界と同じように動かすことです。 ボタンを押してオンにしたり、オブジェクトをつかんで手に取ったりできます。2D コンテンツは仮想タッチスクリーンのように動作します。 このため、直接操作はユーザーにとって学びやすく、楽しくもあります。 直接操作は、「近接」入力モデルと考えられており、手の届く範囲にあるコンテンツとの対話に最適です。

直接操作はアフォーダンスをベースとしているので、操作が簡単です。 ユーザーは象徴的なジェスチャを学ぶ必要はありません。 すべての対話は、触ったりつかんだりできる視覚的要素を中心に構築されています。

## <a name="device-support"></a>デバイスのサポート

<table>
<colgroup>
    <col width="33%" />
    <col width="22%" />
    <col width="22%" />
    <col width="22%" />
</colgroup>
<tr>
     <td><strong>入力モデル</strong></td>
     <td><a href="hololens-hardware-details.md"><strong>HoloLens (第 1 世代)</strong></a></td>
     <td><strong>HoloLens 2</strong></td>
     <td><a href="immersive-headset-hardware-details.md"><strong>イマーシブ ヘッドセット</strong></a></td>
</tr>
<tr>
     <td>手で直接操作</td>
     <td>❌ サポート外</td>
     <td>✔️ 推奨</td>
     <td>➕ 別の選択肢である<a href="point-and-commit.md">手を使ったポイントとコミット</a>を推奨。</td>
    
</tr>
</table>


直接操作は HoloLens 2 の主要な入力モデルであり、新しい多関節ハンド トラッキング システムを利用しています。 この入力モデルは、イマーシブ ヘッドセットでもモーション コントローラー経由で利用できますが、オブジェクト操作以外の対話の主要な手段としてはお勧めできません。 HoloLens (第 1 世代) では直接操作を利用できません。


## <a name="collidable-fingertip"></a>接触可能な指先

HoloLens 2 では、ユーザーの手が、左右の手の骨格モデルとして認識および解釈されます。 ホログラムに直接手で触れるという概念を実現するためには、それぞれの手の骨格モデルの 5 本の指先に 5 つのコライダーを取り付けることが理想的と考えられました。 しかし、触覚的フィードバックがないため、10 本の接触可能な指先とホログラムとの間で、期待に反する予測不可能な衝突が発生してしまいました。 

そこで、両方の人差し指だけにコライダーを付けることをお勧めします。 それでも、接触可能な人差し指の指先は、下の画像に示すように、他の指を含むさまざまなタッチ ジェスチャのアクティブ タッチ ポイントとして機能します。たとえば、指 1 本の押し、指 1 本のタップ、指 2 本の押し、指 5 本の押しなどです。

![接触可能な指先の画像](images/Collidable-Fingertip-720px.jpg)

### <a name="sphere-collider"></a>スフィア コライダー

ランダムな汎用シェイプを使用する代わりに、スフィア コライダーを使用することをお勧めします。 次に、これを視覚的にレンダリングすることで、近接ターゲット設定のためにより優れた手掛かりを与えます。 タッチ精度を上げるには、スフィアの直径を人差し指の太さに合わせる必要があります。 hand API を呼び出すことで、指の太さの変数を簡単に取得できます。

### <a name="fingertip-cursor"></a>指先カーソル

人差し指の指先に接触可能なスフィアをレンダリングすることに加え、高度な指先カーソルも作成されました。これにより、近接ターゲット設定のエクスペリエンスが向上します。 これは、人差し指に付随するドーナツ型のカーソルです。 これは距離に応じて対象に反応して向きやサイズが変化します。詳しくは、以下のとおりです。

* 人差し指をホログラムに近づけると、カーソルは常にホログラムの表面と平行になり、近づくにつれて徐々にサイズが小さくなります。
* 指が表面に触れるとカーソルは直ちにドットにまで縮小し、タッチ イベントが発生します。

次に示されているように、ユーザーは、対話型のフィードバックによって、ハイパーリンクのトリガーやボタンの押下など、高い精度で近接ターゲット設定のタスクを実行できます。 

![指先カーソルの画像](images/Fingertip-Cursor-720px.jpg)

## <a name="bounding-box-with-proximity-shader"></a>近接シェーダーを備えた境界ボックス

触覚的フィードバックがないことを補うため、ホログラム自体にも視覚および音声の両方のフィードバックを提供する機能が必要です。 そこで、近接シェーダーを備えた境界ボックスという概念が考案されました。 境界ボックスは、3D オブジェクトを囲む最小の立体領域です。 境界ボックスには、近接シェーダーと呼ばれる対話的なレンダリング メカニズムがあります。 近接シェーダーは次のように動作します。

* 人差し指が一定範囲内にある場合、指先スポットライトが境界ボックスの表面に投影されます。
* 指先が表面に近づくと、距離に応じてスポットライトが縮小します。
* 指先が表面に触れると直ちに、境界ボックス全体の色が変わったり、視覚的効果が生じたりして、タッチ状態が反映されます。
* また、効果音が鳴るようにしてタッチの視覚的フィードバックを増強できます。

![近接シェーダーを備えた境界ボックスの画像](images/Bounding-Box-With-Proximity-Shader-720px.jpg)

## <a name="pressable-button"></a>押しボタン

ユーザーは接触可能な指先で、押しボタンなど基本的なホログラフィック UI コンポーネントと対話できます。 押しボタンは、直接指で押せるように調整されたホログラフィック ボタンです。 押しボタンの場合もそれを押したときの感覚がないので、触覚フィードバックに関連した問題を処理するためのメカニズムがいくつか備えられています。

* 1 つ目のメカニズムは、近接シェーダーを備えた境界ボックスです。これについては、前のセクションで詳しく説明しました。 これにより、ユーザーがボタンに近づいて接触するとき、接近の感覚が向上します。
* 2 つ目のメカニズムは、押し下げの感覚です。 押し下げの感覚により、指先がボタンに接触した後、押し下げるという感覚が生まれます。 指先と一緒に、深さ軸に沿って、重みを伴ってボタンが動くメカニズムです。 指定された深さに達したとき (トリガー時) か、その深さを超えた後で離したとき (リリース時) にボタンをトリガーすることができます。
* ボタンがトリガーされたときに効果音が鳴るようにしてフィードバックを増強する必要があります。

![押しボタンの画像](images/Pressable-Button-720px.jpg)

## <a name="2d-slate-interaction"></a>2D スレートとの対話

2D スレートは、Web ブラウザーなどの 2D アプリ コンテンツをホストするホログラフィック コンテナーです。 直接操作による 2D スレートとの対話の設計概念は、物理的なタッチ画面との対話という概念的モデルを利用するというものです。

スレートとの接触による対話は、次のように行います。

* 人差し指を使ってハイパーリンクまたはボタンを押します。
* 人差し指を使ってスレート コンテンツを上下にスクロールします。
* ユーザーは 2 本の人差し指を使用して、指の相対的な動きに応じてスレートのコンテンツを拡大縮小します。

![2D スレートの画像](images/2D-Slate-Interaction-720px.jpg)

2D スレート本体の操作方法は、次のとおりです。

* 隅や端に手に近づけて、一番近くにある操作アフォーダンスを表示します。
* 操作アフォーダンスをつかみ、均等に拡大縮小する場合は隅のアフォーダンスを、リフローを行う場合は端のアフォーダンスをつかみます。
* 2D スレートの上部にあるホロバーをつかむことで、スレート全体を動かすことができます。

![スレート操作の画像](images/Manipulate-2d-slate-720px.jpg)

## <a name="3d-object-manipulation"></a>3D オブジェクトの操作

HoloLens 2 では、各 3D オブジェクトに境界ボックスを適用することで、ユーザーが 3D ホログラフィック オブジェクトを手で直接操作することができます。 境界ボックスは、その近接シェーダーによって奥行きを感知しやすくします。 境界ボックスには、3D オブジェクト操作のための 2 つの設計アプローチがあります。

### <a name="affordance-based-manipulation"></a>アフォーダンスをベースとする操作

アフォーダンスをベースとする操作により、境界ボックスとその周囲の操作アフォーダンスを通じて 3D オブジェクトを操作できます。 ユーザーの手が 3D オブジェクトに近づくと直ちに、境界ボックスおよび最も近いアフォーダンスが表示されます。 ユーザーは、境界ボックスをつかんでオブジェクト全体を移動したり、端のアフォーダンスをつかんで回転させたり、隅のアフォーダンスをつかんで均等に拡大縮小したりすることができます。

![3D オブジェクト操作の画像](images/3D-Object-Manipulation-720px.jpg)

### <a name="non-affordance-based-manipulation"></a>アフォーダンスをベースとしない操作

アフォーダンスをベースとしない操作では、アフォーダンスは境界ボックスにアタッチされません。 ユーザーが行えるのは、境界ボックスを表示した後、直接対話することだけです。 境界ボックスを片手でつかむと、オブジェクトの移動と回転は手の動きと向きに関連付けられます。 ユーザーがオブジェクトを両手でつかむと、両手の相対的な動きに応じてそのオブジェクトを移動、拡大縮小、回転できます。

特定の操作では正確さが求められます。 **アフォーダンスをベースとする操作**を使用することをお勧めします。細かい調整を行うことができるためです。 融通が利く操作の場合は、**アフォーダンスをベースとしない操作**を使用することをお勧めします。即興性のある、遊び心を加えたエクスペリエンスが許されるためです。

## <a name="instinctual-gestures"></a>本能的なジェスチャ

HoloLens (第 1 世代) では、ブルームやエアタップなど、いくつかの定義済みジェスチャをユーザーが学ぶ必要がありました。 HoloLens 2 では、ユーザーが象徴的なジェスチャを覚える必要はありません。 ユーザーがホログラムやコンテンツと対話するときに必要とされるユーザー ジェスチャは、どれも本能的なものです。 本能的なジェスチャを実現するには、ユーザーがジェスチャを実行するよう、UI アフォーダンスのデザインを通して支援するという方法を使用します。

たとえば、2 本の指でピンチしてオブジェクトまたは制御点をつかむようユーザーに促す場合、オブジェクトまたは制御点は小さいはずです。 5 本の指でつかむようユーザーに促す場合、オブジェクトまたは制御点は比較的大きいはずです。 ボタンも同様です。小さいボタンならユーザーは 1 本の指でしか押せませんが、大きなボタンならユーザーは手のひらで押すよう促されます。

![](images/Instinctual-Gestures-720px.jpg)

## <a name="symmetric-design-between-hands-and-6-dof-controllers"></a>手と 6 DoF コントローラーの間の対称設計

AR の手と VR のモーション コントローラーとの間には、対話の類似点があることにお気付きかもしれません。 どちらの入力も、それぞれの環境で直接操作をトリガーするために使用できます。 HoloLens 2 で近くのものを手でグラブ アンド ドラッグする操作は、WMR のモーション コントローラーのグラブ ボタンによる実行内容とほとんど同じです。 こうしてユーザーは、2 つのプラットフォームの間の操作に習熟することができます。この知識は、アプリケーションを一方から他方に移植する場合に役立つ可能性があります。

## <a name="optimize-with-eye-tracking"></a>視線追跡の使用による最適化

直接操作が思い通りに機能する場合は魅力的に感じられるかもしれません。 しかし、手をどこに動かしても意図に反してホログラムがトリガーされるばかりになると、即座にフラストレーションの元となります。 視線追跡は、ユーザーの意図をより的確に識別するうえで役立つ場合があります。

* **いつ**:意図に反して操作応答がトリガーされることが少なくなります。 視線追跡により、ユーザーの現在の関心事を理解しやすくなります。
たとえば、ホログラフィック テキスト (説明書) を読んでいるときに、現実世界の仕事道具を取るために手を伸ばしたとします。

そのときうっかり、それまでは気付いてさえいなかったいくつかの対話型ホログラフィック ボタンを横切って手を動かしてしまいました (おそらく、ユーザーの視野 (FOV) にさえ入っていなかったのかもしれません)。

  つまり:ユーザーがしばらくの間ホログラムを見ていないにもかかわらず、それに対するタッチ イベントまたはグリップ イベントが検出された場合、ユーザーは実際にはそのホログラムと対話するつもりはなかった可能性があります。

* **どちら**:アクティブ化の誤検知への対応以外に、つかんだり突いたりするホログラムを識別しやすくなるという別の例もあります。特にいくつかのホログラムが互いに近接して配置されている場合、こちらの視点から正確な交点がはっきりと見えない場合があるためです。

  HoloLens 2 の視線追跡には、目の視線入力を識別する精度にある程度の限界はありますが、手入力で対話する際は、奥行きの差により、近接の対話に非常に役立ちます。 このことは、たとえば操作ウィジェットをつかむときに手がホログラムの後ろにあるのか前にあるのかを判断するのが難しい場合があることを意味します。

* **どこ**:クイック スロー ジェスチャで、ユーザーの視線に関する情報を使用します。 ホログラムをつかみ、目標とする場所のだいたいの方角に向かって放り投げたとします。  

    これでうまくいくこともあるかもしれませんが、ジェスチャの手の動きが速いと、目標とする場所が極めて不正確になる可能性があります。 このシナリオでは、視線追跡を含めることでジェスチャの精度を向上させることができます。

## <a name="see-also"></a>関連項目

* [頭の視線入力とコミット](gaze-and-commit.md)
* [手を使ったポイントとコミット](point-and-commit.md)
* [本能的な操作](interaction-fundamentals.md)

