---
title: 手で直接操作
description: 直接操作入力モデルの概要
author: caseymeekhof
ms.author: cmeekhof
ms.date: 04/02/2019
ms.topic: article
ms.localizationpriority: high
keywords: Mixed Reality, 視線入力, 視線入力ターゲット設定, 対話, 設計, 手に近い, HoloLens
ms.openlocfilehash: 6e3512eab4070680c48ee8e95240a17e9925822f
ms.sourcegitcommit: f20beea6a539d04e1d1fc98116f7601137eebebe
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 06/05/2019
ms.locfileid: "66402391"
---
# <a name="direct-manipulation-with-hands"></a>手で直接操作
直接操作は、ホログラムに手で直接触れる入力モデルです。 直接操作の目標は、オブジェクトを現実の世界と同じように動かすことです。 ボタンを押してオンにしたり、オブジェクトをつかんで手に取ったりできます。2D コンテンツは仮想タッチスクリーンのように動作します。  そのため、直接操作はユーザーにとって学びやすく、楽しくもあります。  これは「近接」入力モデルと考えられており、手の届く範囲にあるコンテンツとの対話に最適です。

直接操作はアフォーダンスをベースとしているので、操作が簡単です。 ユーザーは象徴的なジェスチャを学ぶ必要はありません。 すべての対話は、触ったりつかんだりできる視覚的要素を中心に構築されています。

## <a name="device-support"></a>デバイスのサポート


| 入力モデル | [HoloLens (第 1 世代)](hololens-hardware-details.md) | HoloLens 2 |[イマーシブ ヘッドセット](immersive-headset-hardware-details.md)|
|:-------- | :-------| :--------| :------------|
| 手で直接操作 | ❌ サポート外 | ✔️ 推奨 | ➕ 別の選択肢である[手を使ったポイントとコミット](point-and-commit.md)を推奨。

直接操作は HoloLens 2 の主要な入力モデルであり、新しい多関節ハンド トラッキング システムを利用しています。 この入力モデルは、イマーシブ ヘッドセットでもモーション コントローラー経由で利用できますが、オブジェクト操作以外の対話の主要な手段としてはお勧めできません。  HoloLens (第 1 世代) では直接操作を利用できません。


## <a name="collidable-fingertip"></a>接触可能な指先

HoloLens 2 では、ユーザーの実際の手が左右の骨格モデルとして認識および解釈されます。 ホログラムに直接手で触れるという概念を実現するためには、それぞれの手の骨格モデルの 5 本の指先に 5 つのコライダーを取り付けることが理想的と考えられました。 しかし、実際には、触覚的フィードバックがないため、10 本の接触可能な指先とホログラムとの間で、期待に反する予測不可能な衝突が発生してしまいました。 

そこで、両方の人差し指だけにコライダーを付けることをお勧めします。 それでも、接触可能な人差し指の指先は、下の画像に示すように、他の指を含むさまざまなタッチ ジェスチャのアクティブ タッチ ポイントとして機能します。たとえば、指 1 本の押し、指 1 本のタップ、指 2 本の押し、指 5 本の押しなどです。

![接触可能な指先の画像](images/Collidable-Fingertip-720px.jpg)

### <a name="sphere-collider"></a>スフィア コライダー

ランダムな汎用シェイプを使用する代わりにスフィア コライダーを使用し、これを視覚的にレンダリングすることで、近接ターゲット設定のためにより優れた手掛かりを与えるようにお勧めします。 タッチ精度を上げるには、スフィアの直径を人差し指の太さに合わせる必要があります。 hand API を呼び出すことで、指の太さの変数を簡単に取得できます。

### <a name="fingertip-cursor"></a>指先カーソル

人差し指の指先に接触可能なスフィアをレンダリングすることに加え、指先カーソルという高度なソリューションも開発されました。これにより、対話的に近接ターゲット設定するエクスペリエンスが向上します。 これは、人差し指に付随するドーナツ型のカーソルです。 これは距離に応じて対象に反応して向きやサイズが変化します。詳しくは、以下のとおりです。

* 人差し指をホログラムに近づけると、カーソルは常にホログラムの表面と平行になり、近づくにつれて徐々にサイズが小さくなります。
* 指が表面に触れるとカーソルは直ちにドットにまで縮小し、タッチ イベントが発生します。

ユーザーはこの対話型のフィードバックによって、Web コンテンツのハイパーリンクのトリガーやボタンの押下など、高い精度で近接ターゲット設定するタスクを実行できます。 

![指先カーソルの画像](images/Fingertip-Cursor-720px.jpg)

## <a name="bounding-box-with-proximity-shader"></a>近接シェーダーを備えた境界ボックス

触覚的フィードバックがないことを補うため、ホログラム自体にも視覚および音声の両方のフィードバックを提供する機能が必要です。 そこで、近接シェーダーを備えた境界ボックスという概念が考案されました。 境界ボックスは、3D オブジェクトを囲む最小の立体領域です。 境界ボックスには、近接シェーダーと呼ばれる対話的なレンダリング メカニズムがあります。 近接シェーダーは次のように動作します。

* 人差し指が一定範囲内にある場合、指先スポットライトが境界ボックスの表面に投影されます。
* 指先が表面に近づくと、距離に応じてスポットライトが集光します。
* 指先が表面に触れると直ちに、境界ボックス全体の色が変わったり、視覚的効果が生じたりして、タッチ状態が反映されます。
* 指先が表面に触れている間、効果音が鳴るようにしてタッチの視覚的フィードバックを増強できます。

![近接シェーダーを備えた境界ボックスの画像](images/Bounding-Box-With-Proximity-Shader-720px.jpg)

## <a name="pressable-button"></a>押しボタン

ユーザーは接触可能な指先で、ごく基本的なホログラフィック UI コンポーネントである押しボタンと対話することができます。 押しボタンは、直接指で押せるように調整されたホログラフィック ボタンです。 押しボタンの場合もそれを押したときの感覚がないので、触覚フィードバックに関連した問題を処理するためのメカニズムがいくつか備えられています。

* 1 つ目のメカニズムは、近接シェーダーを備えた境界ボックスです。これについては、前のセクションで詳しく説明しました。 ボタンに近づいて接触したことをユーザーが感知できるよう、接近の感覚を向上させるうえで役に立ちます。
* 2 つ目のメカニズムは、押し下げの感覚です。 指先でボタンに触れた後に、押した感覚を与えます。 指先と一緒に、深さ軸に沿って、重みを伴ってボタンが動くメカニズムです。 指定された深さに達したとき (トリガー時) か、その深さを超えた後で離したとき (リリース時) にボタンをトリガーすることができます。
* ボタンがトリガーされたときに効果音が鳴るようにしてフィードバックを増強する必要があります。

![押しボタンの画像](images/Pressable-Button-720px.jpg)

## <a name="2d-slate-interaction"></a>2D スレートとの対話

2D スレートは、Web ブラウザーなどの 2D アプリ コンテンツをホストするホログラフィック コンテナーです。 直接操作による 2D スレートとの対話の設計概念は、物理的なタッチ画面との対話という概念的モデルを利用するというものです。

スレートとの接触による対話は、次のように行います。

* 人差し指を使ってハイパーリンクまたはボタンを押します。
* 人差し指を使ってスレート コンテンツを上下にスクロールします。
* ユーザーは 2 本の人差し指を使って、指の相対的な動きに応じてスレートのコンテンツを拡大縮小します。

![2D スレートの画像](images/2D-Slate-Interaction-720px.jpg)

2D スレート本体の操作方法は、次のとおりです。

* 隅や端に手に近づけて、一番近くにある操作アフォーダンスを表示します。
* 操作アフォーダンスをつかみ、均等に拡大縮小する場合は隅のアフォーダンスを、リフローを行う場合は端のアフォーダンスをつかみます。
* 2D スレートの上部にあるホロバーをつかむことで、スレート全体を動かすことができます。

![スレート操作の画像](images/Manipulate-2d-slate-720px.jpg)

## <a name="3d-object-manipulation"></a>3D オブジェクトの操作

HoloLens 2 では、各 3D オブジェクトに境界ボックスを適用することで、ユーザーが 3D ホログラフィック オブジェクトを手で直接操作することができます。 境界ボックスは、その近接シェーダーによって奥行きを感知しやすくします。 境界ボックスには、3D オブジェクト操作のための 2 つの設計アプローチがあります。

### <a name="affordance-based-manipulation"></a>アフォーダンスをベースとする操作

境界ボックスとその周囲の操作アフォーダンスによって 3D オブジェクトを操作できます。 ユーザーの手が 3D オブジェクトに近づくと直ちに、境界ボックスおよび最も近いアフォーダンスが表示されます。 ユーザーは、境界ボックスをつかんでオブジェクト全体を移動したり、端のアフォーダンスをつかんで回転させたり、隅のアフォーダンスをつかんで均等に拡大縮小したりすることができます。

![3D オブジェクト操作の画像](images/3D-Object-Manipulation-720px.jpg)

### <a name="non-affordance-based-manipulation"></a>アフォーダンスをベースとしない操作

このメカニズムでは、境界ボックスにアフォーダンスが付属しません。 ユーザーが行えるのは、境界ボックスを表示した後、直接対話することだけです。 境界ボックスを片手でつかむと、オブジェクトの移動と回転は手の動きと向きに関連付けられます。 ユーザーがオブジェクトを両手でつかむと、両手の相対的な動きに応じてそのオブジェクトを移動、拡大縮小、回転できます。

正確さが求められる操作では、**アフォーダンスをベースとする操作**をお勧めします。アフォーダンスをベースとする操作では細かい調整が行えるからです。 融通が利く操作の場合は、**アフォーダンスをベースとしない操作**をお勧めします。即興性のある、遊び心を加えたエクスペリエンスが許されるからです。

## <a name="instinctual-gestures"></a>本能的なジェスチャ

HoloLens (第 1 世代) では、ブルームやエアタップなど、いくつかの定義済みジェスチャをユーザーが学ぶ必要がありました。 HoloLens 2 では、ユーザーが象徴的なジェスチャを覚える必要はありません。 ユーザーがホログラムやコンテンツと対話するときに必要とされるユーザー ジェスチャは、どれも本能的なものです。 本能的なジェスチャを実現するには、ユーザーがジェスチャを実行するよう、UI アフォーダンスのデザインを通して手引きするという方法を使用します。

たとえば、2 本の指でピンチしてオブジェクトまたは制御点をつかむよう促す場合、オブジェクトまたは制御点は小さいはずです。 5 本の指でつかむよう促す場合、オブジェクトまたは制御点は比較的大きいはずです。 ボタンも同様です。小さいボタンならユーザーは 1 本の指でしか押せませんが、大きなボタンならユーザーは手のひらで押すよう促されます。

![](images/Instinctual-Gestures-720px.jpg)

## <a name="symmetric-design-between-hands-and-6-dof-controllers"></a>手と 6 DoF コントローラーの間の対称設計

AR の手と VR のモーション コントローラーとの間には、対話の類似点があることにお気付きかもしれません。 どちらの入力も、それぞれの環境で直接操作をトリガーするために使用できます。 HoloLens 2 で近くのものを手でグラブ アンド ドラッグする操作は、WMR のモーション コントローラーのグラブ ボタンによる実行内容とほとんど同じです。 こうしてユーザーは、2 つのプラットフォームの間の操作に習熟することができます。この知識は、アプリを一方から他方に移植する場合に役立つかもしれません。

## <a name="optimize-with-eye-tracking"></a>視線追跡の使用による最適化

直接操作が思い通りに機能する場合は魅力的に感じられるかもしれませんが、手をどこに動かしても意図に反してホログラムがトリガーされるばかりになると、即座にフラストレーションの元となります。
視線追跡は、ユーザーの意図をより的確に識別するうえで役立つ場合があります。

* **いつ**:誤って操作応答がトリガーされることが少なくなります。 視線追跡により、ユーザーの現在の関心事を理解しやすくなります。
たとえば、ホログラフィック テキスト (説明書) を読んでいるときに、現実世界の仕事道具を取るために手を伸ばしたとします。

そのときうっかり、それまでは気付いてさえいなかったいくつかの対話型ホログラフィック ボタンを横切って手を動かしてしまいました (おそらく、ユーザーの視野 (FOV) にさえ入っていなかったのかもしれません)。

  つまり:ユーザーがしばらくの間ホログラムを見ていないにもかかわらず、それに対するタッチ イベントまたはグリップ イベントが検出された場合、ユーザーは実際にはそのホログラムと対話するつもりはなかった可能性があります。

* **どちら**:アクティブ化の誤検知への対応以外に、つかんだり突いたりするホログラムを識別しやすくなるという別の例もあります。特にいくつかのホログラムが互いに近接して配置されている場合、こちらの視点から正確な交点がはっきりと見えない場合があるためです。

  HoloLens 2 の視線追跡には、目の視線入力を識別する精度にある程度の限界はありますが、手入力で対話する際は、奥行きの差により、近接の対話に非常に役立ちます。  このことは、たとえば操作ウィジェットをつかむときに手がホログラムの後ろにあるのか前にあるのかを判断するのが難しい場合があることを意味します。

* **どこ**:クイック スロー ジェスチャで、ユーザーの視線に関する情報を使用します。 ホログラムをつかみ、目標とする場所のだいたいの方角に向かって放り投げたとします。  

    これでうまくいくこともあるかもしれませんが、ジェスチャの手の動きが速いと、目標とする場所が極めて不正確になる可能性があります。 視線追跡はこのような状況で役立つ場合があり、手で放り投げるベクトルを目的の位置へ修正することができます。

## <a name="see-also"></a>関連項目

* [頭の視線入力とコミット](gaze-and-commit.md)
* [手を使ったポイントとコミット](point-and-commit.md)
* [本能的な操作](interaction-fundamentals.md)

