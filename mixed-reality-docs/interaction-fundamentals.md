---
title: マルチモーダル操作の概要
description: マルチモーダル操作の概要
author: shengkait
ms.author: shengkait
ms.date: 04/11/2019
ms.topic: article
ms.localizationpriority: high
keywords: Mixed Reality, 視線入力, 視線入力ターゲット設定, 対話, 設計, HoloLens, MMR, マルチモーダル
ms.openlocfilehash: bea205edf484a55db701e8e0d1a233234882a272
ms.sourcegitcommit: 9b6949d7cd2e67e6bde9b32aebeaeea325baa6c4
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 06/04/2019
ms.locfileid: "66516020"
---
# <a name="introducing-instinctual-interactions"></a>本能的な操作の概要

シンプルで本能的な操作の理念は、Microsoft Mixed Reality プラットフォーム全体に織り込まれています。  アプリケーションのデザイナーや開発者が顧客向けに簡単で直感的な操作を提供できるように、3 つの手順を使用しています。 

1 つ目として、驚くべきセンサーと、手の追跡、視線追跡、自然言語などの入力のテクノロジをまとめることで、シームレスなマルチモーダル操作モデルを実現できるようにしました。  調査に基づくと、本能的なエクスペリエンスを作成する鍵となるのは、単一の入力をベースとせず、マルチモーダルで設計や開発を行うことです。

2 つ目として、HoloLens 2 と HoloLens (第 1 世代) のことを意味するのか、HoloLens と VR のことを意味するのかにはよらず、多くの開発者が複数のデバイスをターゲットにしていることを認識しています。  そのため、デバイスによらない操作モデルを設計しています (入力テクノロジはデバイスによって異なります)。  たとえば、6DOF コントローラーによる Windows イマーシブ ヘッドセットの遠隔インタラクションや、HoloLens 2 での遠隔インタラクションは、どちらも同じアフォーダンスとパターンを使用しているので、クロス デバイス アプリケーションで簡単に活用できるようになっています。 これは、開発者やデザイナーにとって便利であるだけでなく、エンドユーザーにとって自然です。 

最後に、MR では効果的、魅力的で魔法のような何千もの操作が実現できますが、ユーザーが成功と優れたエクスペリエンスを実感できる最善の方法は、アプリケーションで意図的にエンドツーエンドの単一操作モデルを使用することであることがわかっています。  そのため、この操作ガイドに次の 3 つのことを含めました。
* このガイダンスは、この 3 つの主要な操作モデルと、それぞれに必要なコンポーネントとパターンを中心とした構造にしています。
* このプラットフォームが提供するその他のメリットに関する補足的なガイダンスを含めます。
* シナリオに適した操作モデルの選択に役立つガイダンスを含めます。

## <a name="multimodal-interaction-models"></a>マルチモーダル操作モデル

これまで顧客とともに調査や作業を行ってきた結果から、3 つの主要な操作モデルは大半の Mixed Reality エクスペリエンスに適したものであることがわかりました。

多くの点で、この操作モデルはユーザーのフローを完了するためのメンタル モデルです。  各操作モデルは、一連の顧客ニーズのために最適化されていて、それぞれが便利な強力かつそれ自体で使用できます。 

次の表は、簡単な概要です。  各操作モデルを使用するための詳細情報は、イメージとコード サンプルを含むページにリンクしています。 

<br>
<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><strong>Model</strong></td>
        <td><strong>シナリオ例</strong></td>
        <td><strong>適した使用方法</strong></td>
        <td><strong>ハードウェア</strong></td>
    </tr>
    <tr>
        <td><a href="hands-and-tools.md">手とモーション コントローラー</a></td>
        <td>空間レイアウトやデザインなどの 3D 空間エクスペリエンス、コンテンツの操作、またはシミュレーション。</td>
        <td>音声、視線追跡、頭の視線入力と組み合わせると、新しいユーザーに最適。 習得が容易。 手の追跡と 6 DoF コントローラーで一貫性のある UX。</td>
        <td>HoloLens 2<br>イマーシブ ヘッドセット</td>
    </tr>
    <tr>
        <td><a href="hands-free.md">ハンズフリー</a></td>
        <td>仕事を通じた学習、メンテナンスなど、ユーザーの手が占有されている場合のコンテキスト対応のエクスペリエンス。</td>
        <td>いくらかの学習が必要。 手が使えない場合、音声や自然言語と組み合わせる。</td>
        <td>HoloLens 2<br>HoloLens (第 1 世代)<br>イマーシブ ヘッドセット</td>
    </tr>
    <tr>
        <td><a href="gaze-and-commit.md">頭の視線入力とコミット</a></td>
        <td>3D プレゼンテーション、デモなどのクリック スルー エクスペリエンス。</td>
        <td>移動を除く HMD のトレーニングが必要。 アクセシビリティ コントローラーに最適。 HoloLens (第 1 世代) に最適。</td>
        <td>HoloLens 2<br>HoloLens (第 1 世代)<br>イマーシブ ヘッドセット<br>モバイル AR</td>
    </tr>
</table>
<br>

エクスペリエンスの操作でギャップや穴をなくす最善の方法は、1 つのモデルのガイダンスに最初から最後まで従うことです。 

設計と開発を高速化するため、各モデルの説明には、詳細な情報とイメージやコード サンプルへのリンクを含めています。

まず、以下のセクションでは、これらの操作モデルからいずれかを選択して実装する手順について説明します。  
 
### <a name="by-the-end-of-this-page-you-will-understand-our-guidance-on"></a>このページでは、以下についてのガイダンスを理解することができます。
 
* 顧客の操作モデルの選択
* 操作モデルのガイダンスの使用
* 操作モデル間の遷移
* 次の手順の設計


## <a name="choose-an-interaction-model-for-your-customer"></a>顧客の操作モデルを選択する


ほとんどの場合、開発者や作成者は、ユーザーに提供する操作エクスペリエンスの種類について、既にいくつかのアイデアを持っています。
顧客中心の設計アプローチをお勧めするために、以下のガイダンスに従って、顧客向けに最適化された操作モデルを選択することをお勧めします。

### <a name="why-follow-this-guidance"></a>ガイダンスに従う理由

* 操作モデルは、物理効果、認識効果、直感性、学習性など、主観的および客観的な基準でテストされます。 
* 操作が異なるため、操作モデル間でビジュアルおよびオーディオ アフォーダンスやオブジェクトの動作は異なる可能性があります。  
* 複数の操作モデルの一部を組み合わせると、アフォーダンスが競合するリスクが生まれます。たとえば、手の光線と頭の視線入力のカーソルが同時に表示されると、ユーザーが混乱します。

アフォーダンスと動作を最適化する例を操作モデルごとに示します。  新しいユーザーが「システムが動作していることはどうすればわかりますか、何ができるかはどうすればわかりますか。自分がしたことをシステムが理解していることはどうすればわかりますか」といった同じような質問をしているのをよく見かけます。

<br>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><strong>Model</strong></td>
        <td><strong>動作していることはどうすればわかりますか?</strong></td>
        <td><strong>何ができるかはどうすればわかりますか?</strong></td>
        <td><strong>自分が何をしたかはどうすればわかりますか?</strong></td>
    </tr>
    <tr>
        <td><a href="hands-and-tools.md">手とモーション コントローラー</a></td>
        <td>手のメッシュが見える、指先アフォーダンスまたは手やコントローラーの光線が見える。</td>
        <td>手を近づけると、グラブ可能なハンドルや境界ボックスが表示される。</td>
        <td>音が聞こえ、グラブやリリースのアニメーションが見える。</td>
    </tr>
    <tr>
        <td><a href="gaze-and-commit.md">頭の視線入力とコミット</a></td>
        <td>視野の中央にカーソルが見える。</td>
        <td>特定のオブジェクトに重ねると、頭の視線入力カーソルの状態が変わる。</td>
        <td>行動を行うと、視覚または音声でわかる。</td>
    </tr>   
    <tr>
        <td><a href="hands-free.md">ハンズフリー (頭の視線入力とドウェル)</a></td>
        <td>視野の中央にカーソルが見える。</td>
        <td>インタラクティブなオブジェクトにドウェルすると、進行状況のインジケーターが見える。</td>
        <td>行動を行うと、視覚または音声でわかる。</td>
    </tr>
    <tr>
        <td><a href="hands-free.md">ハンズフリー (音声コマンド)</a></td>
        <td>リスニング インジケーターとシステムが聞いた音を表示するキャプションが見える。</td>
        <td>音声プロンプトとヒントが聞こえる。  「何を言えますか?」と言うと フィードバックが得られる。</td>
        <td>コマンドを与えると、視覚または音声でわかる。必要な場合は不明瞭解消用の UX が提供される。</a></td>
    </tr>
</table>

### <a name="below-are-the-questions-that-weve-found-help-teams-select-an-interaction-model"></a>ヘルプ チームが操作モデルを選択する際に使用している質問を次に示します。
 
1.  Q:ユーザーがホログラムにタッチして細かい操作を行うことはありますか?<br><br>
A:その場合は、厳密なターゲット指定や、手またはモーション コントローラーによる操作を行うために、手とツールの操作モデルを確認します。
 
2.  Q:ユーザーは、現実世界でタスクを行うために、手を空けておく必要がありますか?<br><br>
A:その場合は、ハンズフリー操作モデルを確認します。このモデルは、視線入力または音声ベースの操作で優れたハンズフリー エクスペリエンスを提供します。
 
3.  Q:ユーザーには Mixed Reality アプリケーションの操作を学習する時間はありますか? それとも、最低限の学習で操作を行う必要がありますか?<br><br>
A:ユーザーが手で操作を行うことができ、最低限の学習で最も直感的に操作を行いたい場合は、手とツールのモデルをお勧めします。
 
4.  Q:ユーザーがポイントしたり操作したりする際、モーション コントローラーを使用しますか?<br><br>
A:手とツールのモデルには、モーション コントローラーを使ってすばらしいエクスペリエンスを実現するためのガイダンスがすべて含まれています。
 
5.  Q:ユーザーは、アクセシビリティ コントローラーやクリッカーなどの一般的な Bluetooth コントローラーを使用しますか?<br><br>
A:すべての非追跡コントローラーには、頭の視線入力とコミットのモデルをお勧めします。  ユーザーが単純な「ターゲット指定とコミット」機構によるエクスペリエンス全体を利用できるように設計されています。 
 
6.  Q:ユーザーは、UI コントロールが詰まったレイアウトを操作するのではなく、「クリックスルー」によってのみエクスペリエンスを進行させることができますか (たとえば、3D スライド ショーのような環境) ?<br><br>
A:ユーザーが多くの UI を制御する必要がない場合は、頭の視線入力とコミットを使うと、ターゲットの指定について悩むことなく学習できるオプションを提供できます。 
 
7.  Q:ユーザーは HoloLens (第 1 世代) と HoloLens 2/Windows イマーシブ (VR ヘッドセット) の両方を使用しますか?<br><br>
A:頭の視点入力とコミットは HoloLens (第 1 世代) の操作モデルであるため、HoloLens (第 1 世代) をサポートする作成者は、ユーザーが HoloLens (第 1 世代) ヘッドセットを使う可能性があるすべての機能やモードで、頭の視線入力とコミットを使用することをお勧めします。  複数の世代の HoloLens で優れたエクスペリエンスを作成する詳しい方法については、*操作モデルの遷移*について取り上げた次のセクションを参照してください。
 
8.  Q:通常は移動可能 (広い領域をカバーする、またはスペース間を移動する) なユーザーと、1 つのスペースで作業することが多いユーザーを比較するとどうなりますか?<br><br>
A:どの操作モデルでも、これらのユーザーに対応できます。  

> [!NOTE]
> アプリの設計に特化したガイダンスは、[近日中に公開](index.md#news-and-notes)します。


## <a name="transition-interaction-models"></a>操作モデルの遷移
複数の操作モデルが必要になるユース ケースもあります。  たとえば、アプリの「作成フロー」で手とモーション コントローラー操作モデルを利用しつつ、現場技術者向けにハンズフリー モードを使う場合などです。  

エクスペリエンスに複数の操作モデルが必要な場合、ある操作モデルから別の操作モデルに遷移する際に、多くのエンドユーザーが困難を感じることがわかっています。特に、Mixed Reality を初めて使用するユーザーはそれが顕著です。

> [!Note]
> デザイナーや開発者が MR で難しくなる可能性がある選択を行う際に役立つように、現在、複数の操作モデルを使用するための詳細ガイダンスの作成を進めています。
 

## <a name="see-also"></a>関連項目
* [頭の視線入力とコミット](gaze-and-commit.md)
* [ヘッド視線入力とドウェル](gaze-and-dwell.md)
* [手で直接操作](direct-manipulation.md)
* [手を使ったポイントとコミット](point-and-commit.md)
* [ジェスチャ](gestures.md)
* [音声コマンド](voice-design.md)
* [モーション コントローラー](motion-controllers.md)
* [立体音響の設計](spatial-sound-design.md)
* [空間マッピングの設計](spatial-mapping-design.md)
* [快適性](comfort.md)

