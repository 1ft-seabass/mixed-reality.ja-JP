---
title: マルチ モーダルな相互作用の概要
description: マルチ モーダルな相互作用の概要
author: shengkait
ms.author: shengkait
ms.date: 04/11/2019
ms.topic: article
ms.localizationpriority: high
keywords: 実際には、視線の先、対象とする操作、視線の先を混合設計、hololens、MMR、マルチ モーダル
ms.openlocfilehash: 9d0e639d7474c7e8728282acfa8d288cfeec7043
ms.sourcegitcommit: c20563b8195c0c374a927b96708d958b127ffc8f
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 05/21/2019
ms.locfileid: "65974905"
---
# <a name="introducing-instinctual-interactions"></a>Instinctual 相互作用の概要

シンプルで instinctual の相互作用の理念はハードウェアのソフトウェアから、Microsoft Mixed Reality (MMR) プラットフォーム全体でウォーブンします。

これらの instinctual 相互作用は、シームレスなマルチ モーダルな対話モデルでの徹底解剖の追跡、手の追跡、視線、および自然言語を含む、すべての利用可能な入力テクノロジを利用します。 調査、設計および開発に基づき multimodals、および 1 つの入力に基づいては重要な直感的な解決のエクスペリエンスを作成するときにします。

Instinctual 相互作用モデルは、デバイスの種類も自然配置します。  たとえば、コント ローラーの自由度が 6、イマーシブ ヘッドセットの相手側の対話と HoloLens 2 での相手側の対話は、同じアフォー、パターン、および動作を使用します。  だけでなく、この便利の開発者とデザイナーが、エンドユーザーに自然な感覚です。


最後に、何千もの効率が高く、魅力的であることと、魔法のような相互作用を設定 MR で可能であることを意図的に採用 1 回の操作モデルでは、エンド ツー エンドを認識している間に、アプリケーションはユーザーが成功したことを確認する最善の方法と優れたエクスペリエンスを実現します。  そのために、この操作ガイドの次の 3 つ含まれています。
* この 3 つの主要な対話モデルとコンポーネント、および各に必要なパターンのガイダンスを構成しましたしました
* 当社のプラットフォームを提供するその他の特典に関する補足的なガイダンスが掲載されています
* シナリオでは、適切な対話モデルを選択できるようにするためのガイダンスが掲載されています

## <a name="multimodal-interaction-models"></a>マルチ モーダルな相互作用モデル

マイクロソフトの調査と日付に顧客と連携に基づいて、多数の複合現実エクスペリエンスに合わせて次の 3 つの主要な対話モデルが見つかりました。  

これらの相互作用モデル、フローを完了するため、ユーザーのメンタル モデルと考えます。

これらの相互作用モデルの各は便利な強力かつ独自の権限で使用できるし、一連の顧客のニーズのすべて最適化されています。 グラフの下、シナリオ、例、および各相互作用モデルの利点を表示します。  

**[モデル]** | **[手およびツール](https://docs.microsoft.com/en-us/windows/mixed-reality/hands-and-tools)** | **[楽します。](https://docs.microsoft.com/en-us/windows/mixed-reality/hands-free)** | **[視線入力とコミット](https://docs.microsoft.com/en-us/windows/mixed-reality/gaze-and-commit?)**
|--------- | --------------| ------------| ---------|
**シナリオ例** | 3D 空間エクスペリエンス、spatial などのレイアウトとデザイン、コンテンツの操作、またはシミュレーション | コンテキスト対応のエクスペリエンスをユーザーの手占有されているなど、ジョブのメンテナンスを学習します。| クリックスルー エクスペリエンス、3 D のプレゼンテーション、デモなど
**サイズに合わせて** | 追跡またはヘッド視線の先を新しいユーザーは、結合された wit の音声に適していますに注目します。 習得が。 追跡と 6 の自由度のコント ローラーの間で一貫性のある UX。 | いくつか必要な学習します。 手が音声と自然言語でうまく使用できないペアである場合 | Mobile ではなく HMDs のトレーニングが必要です。 アクセス可能なコント ローラーに最も適した HoloLens に最適な (第 1 世代) |
**ハードウェア** | HoloLens 2 イマーシブ ヘッドセット | HoloLens 2 HoloLens (第 1 世代) イマーシブ ヘッドセット | HoloLens 2 イマーシブ ヘッドセット | HoloLens 2 HoloLens (第 1 世代) イマーシブ ヘッドセット Mobile AR |

各対話モデルでシームレスに使用できるすべての入力を使用するための詳細については、図と、Unity MRTK からサンプルのコンテンツへのリンクと、次のページで です。


## <a name="choose-an-interaction-model-for-your-customer"></a>お客様の相互作用モデルを選択します。


ほとんどの場合、開発者および作成者もが既にあるいくつかのアイデアの相互作用のエクスペリエンス、ユーザーが希望の種類に注意してください。
設計する顧客中心のアプローチをぜひお勧めします以下のガイダンスに従って、顧客向けに最適化された相互作用モデルを選択します。

### <a name="why-follow-this-guidance"></a>このガイダンスに従うなぜでしょうか。

* 目標と物理的および cognitive 労力、intuitiveness、learnability などの主観的な基準に、相互作用モデルがテストされます。 
* 相互作用が異なるため、ビジュアルおよびオーディオ アフォーとオブジェクトの動作異なる可能性がありますも相互作用モデル。  
* 複数の操作モデルの一部をまとめて結合の重荷となっており、ユーザーが混乱する同時手光線と head 注視カーソルなどの競合アフォーのリスクを作成します。

相互作用モデルごとにアフォーと動作を最適化する方法の例をいくつかを示します。  よく見られる新しいユーザーのような質問については、としてなど"知る方法は、システムが動作している知る方法は何ができるかを知る方法は私が先ほどが認識されるとでしょうか"。

<br>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><strong>[モデル]</strong></td>
        <td><strong>知る方法が動作しますか?</strong></td>
        <td><strong>何ができるかを知る方法</strong></td>
        <td><strong>先ほど行った何かを確認する方法</strong></td>
    </tr>
    <tr>
        <td><a href="hands-and-tools.md">手およびツール</a></td>
        <td>メッシュ手の形を表示、指先アフォー ダンスまたは手の形の表示]、[コント ローラー光線します。</td>
        <td>Grabbable ハンドルまたは手が近くにある場合、表示境界ボックスが表示されます。</td>
        <td>音を再生し、グラブとリリースのアニメーションを参照してください。</td>
    </tr>
    <tr>
        <td><a href="gaze-and-commit.md">頭の視線入力とコミット</a></td>
        <td>フィールドのビューの中央にカーソルが参照してください。</td>
        <td>Head 注視カーソルでは、特定のオブジェクトの上に置いたときの状態を変更します。</td>
        <td>私を参照してください/処理を行うときに、音声と視覚的に確認メッセージを聞きます。</td>
    </tr>   
    <tr>
        <td><a href="hands-free.md">ハンズフリー (ヘッド注視およびドウェル)</a></td>
        <td>フィールドのビューの中央にカーソルが参照してください。</td>
        <td>進行状況インジケーターが表示されるは、対話型のオブジェクトについて熟考するとします。</td>
        <td>私を参照してください/処理を行うときに、音声と視覚的に確認メッセージを聞きます。</td>
    </tr>
    <tr>
        <td><a href="hands-free.md">楽に (音声コマンドの実行)</a></td>
        <td>インジケーターをリッスンしていると、システムの音を表示するキャプションで表示します。</td>
        <td>音声プロンプトとヒントを取得します。  「どのような音声」言ったとき フィードバックを表示します。</td>
        <td>私を参照してください/をコマンドでは、曖昧性除去必要なときに、UX を取得するか、音声と視覚的に確認メッセージを聞きます。</a></td>
    </tr>
</table>

### <a name="below-are-the-questions-that-weve-found-help-teams-select-an-interaction-model"></a>わかりましたヘルプ チームの選択、相互作用モデル質問を次に示します。
 
1.  Q:ユーザーはホログラムをタッチし、有効桁数ホログラフィック操作を実行しますか。<br><br>
A:そうである場合は、有効桁数を対象として、手やアニメーション コント ローラーを使用した操作の手とツールの対話モデルを確認します。
 
2.  Q:ユーザーは、無料の実際のタスク、手を保持する必要がありますか。<br><br>
A:そうである場合を見てハンズフリー対話モデル注視し、音声ベースの対話を通じての楽に優れたエクスペリエンスを提供します。
 
3.  Q:ユーザーが、複合現実アプリケーションの相互作用の学習に時間または必要がある最下位の学習曲線との対話ことでしょうか。<br><br>
A:最下位の学習曲線と最も直感的な間のやり取りの手とツールのモデルは、ユーザーは、相互作用に手を使用する限り、お勧めします。
 
4.  Q:ユーザーは、ポイント、および操作のモーションのコント ローラーを使用するか。<br><br>
A:手およびツールのモデルには、アニメーション コント ローラーですばらしい体験のすべてのガイダンスが含まれています。
 
5.  Q:アクセシビリティのコント ローラーまたは一般的な Bluetooth コント ローラーの場合、clicker など、ユーザーは使用でしょうか。<br><br>
A:すべての非追跡コント ローラーの Head 注視とコミットのモデルをお勧めします。  単純な「ターゲットとコミット」整備士のエクスペリエンス全体を走査できるようになっています。 
 
6.  Q:自分のユーザーのみ進行状況エクスペリエンスを通じて「クリック」することにより (たとえば、3 d のスライド ショーのような環境で)、密度の高いレイアウトの UI コントロールを移動するとは対照的ですか。<br><br>
A:ユーザーは、UI の多くを制御する必要はありません場合、Head 注視し、コミットでユーザーを対象設定について心配する必要はありません learnable オプションを提供します。 
 
7.  Q:ユーザーが両方 HoloLens を使用して (第 1 世代) と HoloLens 2/Windows 没入型 (VR ヘッドセット)<br><br>
A:Head 注視し、コミットは HoloLens の相互作用モデルであるため (第 1 世代) ことをお勧め creators HoloLens をサポートする (第 1 世代) がヘッド視線の先を使用し、機能やユーザーが、HoloLens で発生するモードをコミット (第 1 世代) ヘッドセット。  次のセクションを参照してくださいで*相互作用モデルの移行*HoloLens の複数の世代の優れたエクスペリエンスの方法の詳細について。
 
8.  Q:については、(大きな領域をカバーするまたはスペース間での移動)、通常、モバイル ユーザーの 1 つのスペースで作業するユーザーとでしょうか。<br><br>
A:相互作用モデルのいずれでも、これらのユーザーの動作します。  

> [!NOTE]
> アプリの設計に固有のガイダンスについて[近日](index.md#news-and-notes)します。


## <a name="transition-interaction-models"></a>遷移の相互作用モデル
場所、ユース ケースが必要があります 1 つ以上の相互作用モデルを使用している場合もあります。  たとえば、フロー、アプリの"作成"手とツールの対話モデルを利用してが楽にモードを現場技術者の雇用します。  

お客様のエクスペリエンスが複数の操作モデルを必要とする場合は、多くのエンドユーザー間 - 初心者様にはエンドユーザーに対して特に 1 つのモデルから移行難易度は発生可能性があります、わかりました。

> [!Note]
> ガイドの設計者や MR で難しい場合がありますの選択は、開発者のため、複数の操作モデルを使用するための詳細ガイダンスに取り組んでいるところです。
 

## <a name="see-also"></a>関連項目
* [頭の視線入力とコミット](gaze-and-commit.md)
* [ヘッド視線入力とドウェル](gaze-and-dwell.md)
* [手で直接操作](direct-manipulation.md)
* [手を使ったポイントとコミット](point-and-commit.md)
* [ジェスチャ](gestures.md)
* [音声コマンド](voice-design.md)
* [モーション コントローラー](motion-controllers.md)
* [立体音響の設計](spatial-sound-design.md)
* [空間マッピングの設計](spatial-mapping-design.md)
* [快適性](comfort.md)

