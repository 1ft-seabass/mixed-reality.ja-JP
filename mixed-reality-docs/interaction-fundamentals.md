---
title: マルチモーダル操作の概要
description: マルチモーダル操作の概要
author: shengkait
ms.author: shengkait
ms.date: 04/11/2019
ms.topic: article
ms.localizationpriority: high
keywords: Mixed Reality, 視線入力, 視線入力ターゲット設定, 対話, 設計, HoloLens, MMR, マルチモーダル
ms.openlocfilehash: 7b04141c832597be4bb58447629e0ef6e248dc2b
ms.sourcegitcommit: d8700260f349a09c53948e519bd6d8ed6f9bc4b4
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 06/27/2019
ms.locfileid: "67415252"
---
# <a name="introducing-instinctual-interactions"></a>本能的な操作の概要

シンプルで本能的な操作の理念は、Mixed Reality プラットフォーム全体に織り込まれています。  アプリケーションのデザイナーや開発者が顧客に簡単で直感的な操作を提供できるように、3 つの手順を使用しています。 

1 つ目として、センサーと入力のテクノロジ (自然言語入力に加え、手の追跡と視線追跡が含まれます) をまとめることで、シームレスなマルチモーダル操作モデルを実現できるようにしました。  調査に基づくと、本能的なエクスペリエンスを作成する鍵となるのは、単一の入力をベースとせず、マルチモーダル フレームワーク内で設計や開発を行うことです。

2 つ目として、多くの開発者が複数の HoloLens デバイス (HoloLens 2 と HoloLens (第 1 世代) 、HoloLens と VR など) をターゲットにしていることを認識しています。  このため、各デバイスで入力テクノロジが異なる場合でも、複数のデバイスで動作するように操作モデルを設計しています。  たとえば、6DoF コントローラーによる Windows イマーシブ ヘッドセットの遠隔操作や、HoloLens 2 での遠隔操作は、どちらも同じアフォーダンスとパターンを使用しているため、エンド ユーザーが自然な感覚で操作できるクロス デバイス アプリケーションを簡単に開発できます。 

Mixed Reality (MR) では効果的、魅力的で魔法のような何千もの操作を実現できますが、ユーザーが成功と優れたエクスペリエンスを実感できる最善の方法は、アプリケーションで意図的にエンドツーエンドの単一操作モデルを使用することであることがわかっています。 そのため、この操作ガイドに次の 3 つのことを含めました。
* このガイダンスは、この 3 つの主要な操作モデルと、それぞれに必要なコンポーネントとパターンを中心とした構造になっています。
* このプラットフォームが提供するその他のメリットに関する補足的なガイダンスが含まれています。
* 開発シナリオに適した操作モデルの選択に役立つガイダンスも含まれています。

## <a name="multimodal-interaction-models"></a>マルチモーダル操作モデル

調査とお客様からのフィードバックに基づき、3 つの主要な操作モデルは大半の Mixed Reality エクスペリエンスに適していることがわかりました。

多くの点で、この操作モデルはユーザーのフローを完了するためのメンタル モデルです。 これらの各操作モデルは、お客様の一連のニーズに合わせて最適化されています。 それぞれ便利で強力であり、それ自体で使用できます。 

次の表は、簡単な概要です。 各操作モデルを使用するための詳細情報は、イメージとコード サンプルを含むページにリンクしています。 

<br>
<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><strong>Model</strong></td>
        <td><strong>シナリオ例</strong></td>
        <td><strong>適した使用方法</strong></td>
        <td><strong>ハードウェア</strong></td>
    </tr>
    <tr>
        <td><a href="hands-and-tools.md">手とモーション コントローラー</a></td>
        <td>空間レイアウトやデザインなどの 3D 空間エクスペリエンス、コンテンツの操作、またはシミュレーション。</td>
        <td>音声、視線追跡、頭の視線入力と組み合わせると、新しいユーザーに最適。 習得が容易。 手の追跡と 6 DoF コントローラーで一貫性のある UX。</td>
        <td>HoloLens 2<br>イマーシブ ヘッドセット</td>
    </tr>
    <tr>
        <td><a href="hands-free.md">ハンズフリー</a></td>
        <td>実地学習、メンテナンスなど、ユーザーの手が占有されている場合のコンテキスト対応のエクスペリエンス。</td>
        <td>いくらかの学習が必要。 手が使用できない場合、デバイスにより音声と自然言語が組み合わされる。</td>
        <td>HoloLens 2<br>HoloLens (第 1 世代)<br>イマーシブ ヘッドセット</td>
    </tr>
    <tr>
        <td><a href="gaze-and-commit.md">頭の視線入力とコミット</a></td>
        <td>3D プレゼンテーション、デモなどのクリック スルー エクスペリエンス。</td>
        <td>移動を除く HMD のトレーニングが必要。 アクセシビリティ コントローラーに最適。 HoloLens (第 1 世代) に最適。</td>
        <td>HoloLens 2<br>HoloLens (第 1 世代)<br>イマーシブ ヘッドセット<br>モバイル AR</td>
    </tr>
</table>
<br>

ユーザー操作エクスペリエンスのギャップや欠陥をなくす最善の方法は、1 つのモデルのガイダンスに最初から最後まで従うことです。 

設計と開発を高速化するために、各モデルの説明には、詳細な情報が含まれており、またイメージとコード サンプルへのリンクが含まれています。

次のセクションでは、これらの操作モデルからいずれかを選択して実装する手順について説明します。  
 
### <a name="by-the-end-of-this-page-you-will-understand-our-guidance-on"></a>このページでは、以下についてのガイダンスを理解することができます。
 
* 顧客の操作モデルの選択
* 操作モデルのガイダンスの使用
* 操作モデル間の遷移
* 次の手順の設計


## <a name="choose-an-interaction-model-for-your-customer"></a>顧客の操作モデルを選択する


通常、開発者と作成者は、顧客が使用できる操作の種類を考慮しています。 顧客中心の設計アプローチを促進するために、次のガイダンスに従って、顧客向けに最適化された操作モデルを選択することをお勧めします。

### <a name="why-follow-this-guidance"></a>ガイダンスに従う理由

* 操作モデルは、物理効果、認識効果、直感性、学習性など、主観的および客観的な基準でテストされます。 
* 操作が異なるため、操作モデル間でビジュアルおよびオーディオ アフォーダンスやオブジェクトの動作が異なる可能性があります。  
* 複数の操作モデルの一部を組み合わせると、アフォーダンスが競合するリスクが発生します。たとえば、手の光線と頭の視線カーソルが同時に表示されると、ユーザーが混乱します。

アフォーダンスと動作を最適化する例を操作モデルごとに示します。  新しいユーザーが「システムが動作していることはどうすればわかりますか、何ができるかはどうすればわかりますか。自分がしたことをシステムが理解していることはどうすればわかりますか」といった同じような質問をしているのをよく見かけます。

<br>

<table>
    <colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    </colgroup>
    <tr>
        <td><strong>Model</strong></td>
        <td><strong>動作していることはどうすればわかりますか?</strong></td>
        <td><strong>何ができるかはどうすればわかりますか?</strong></td>
        <td><strong>自分が何をしたかはどうすればわかりますか?</strong></td>
    </tr>
    <tr>
        <td><a href="hands-and-tools.md">手とモーション コントローラー</a></td>
        <td>手のメッシュが見える、指先アフォーダンスまたは手やコントローラーの光線が見える。</td>
        <td>手を近づけると、グラブ可能なハンドルや境界ボックスが表示される。</td>
        <td>音が聞こえ、グラブやリリースのアニメーションが見える。</td>
    </tr>
    <tr>
        <td><a href="gaze-and-commit.md">頭の視線入力とコミット</a></td>
        <td>視野の中央にカーソルが見える。</td>
        <td>特定のオブジェクトに重ねると、頭の視線入力カーソルの状態が変わる。</td>
        <td>行動を行うと、視覚または音声でわかる。</td>
    </tr>   
    <tr>
        <td><a href="hands-free.md">ハンズフリー (頭の視線入力とドウェル)</a></td>
        <td>視野の中央にカーソルが見える。</td>
        <td>インタラクティブなオブジェクトにドウェルすると、進行状況のインジケーターが見える。</td>
        <td>行動すると、視覚または音声でわかる。</td>
    </tr>
    <tr>
        <td><a href="hands-free.md">ハンズフリー (音声コマンド)</a></td>
        <td>リスニング インジケーターとシステムが聞いた音を表示するキャプションが見える。</td>
        <td>音声プロンプトとヒントが聞こえる。 「何を言えますか?」と言うと フィードバックが得られる。</td>
        <td>コマンドを与えると、視覚または音声でわかる。必要な場合は不明瞭解消用の UX が提供される。</a></td>
    </tr>
</table>

### <a name="below-are-the-questions-that-weve-found-help-teams-select-an-interaction-model"></a>ヘルプ チームが操作モデルを選択する際に使用している質問を次に示します。
 
1.  Q:ユーザーがホログラムにタッチして細かい操作を行うことはありますか?<br><br>
A:その場合は、厳密なターゲット指定や、手またはモーション コントローラーによる操作を行うために、手とモーション コントローラーの操作モデルを確認します。
 
2.  Q:ユーザーは、現実世界で作業を行うために、手を空けておく必要がありますか?<br><br>
A:その場合は、ハンズフリー操作モデルを確認します。このモデルは、視線入力または音声ベースの操作で優れたハンズフリー エクスペリエンスを提供します。
 
3.  Q:ユーザーには MR アプリケーションの操作を学習する時間はありますか? それとも、最低限の学習で操作を行う必要がありますか?<br><br>
A:ユーザーが手で操作を行うことができ、最低限の学習で最も直感的に操作を行いたい場合は、手とモーション コントローラーのモデルをお勧めします。
 
4.  Q:ユーザーがポイントしたり操作したりする際、モーション コントローラーを使用しますか?<br><br>
A:手とモーション コントローラーのモデルには、モーション コントローラーを使用してすばらしいエクスペリエンスを実現するためのガイダンスがすべて含まれています。
 
5.  Q:ユーザーは、アクセシビリティ コントローラーやクリッカーなどの一般的な Bluetooth コントローラーを使用しますか?<br><br>
A:すべての非追跡コントローラーには、頭の視線入力とコミットのモデルをお勧めします。 ユーザーが単純な「ターゲット指定とコミット」機構によるエクスペリエンス全体を利用できるように設計されています。 
 
6.  Q:ユーザーは、UI コントロールが詰まったレイアウトを操作するのではなく、「クリックスルー」によってのみエクスペリエンスを進行させることができますか (たとえば、3D スライド ショーのような環境)?<br><br>
A:ユーザーが多くの UI を制御する必要がない場合は、頭の視線入力とコミットを使うと、ターゲットの指定について悩むことなく学習できるオプションを提供できます。 
 
7.  Q:ユーザーは HoloLens (第 1 世代) と HoloLens 2/Windows Mixed Reality イマーシブ ヘッドセット (VR) の両方を使用しますか?<br><br>
A:頭の視線入力とコミットは HoloLens (第 1 世代) の操作モデルであるため、HoloLens (第 1 世代) をサポートする作成者は、ユーザーが HoloLens (第 1 世代) ヘッドセットを使用する可能性があるすべての機能やモードで、頭の視線入力とコミットを使用することをお勧めします。 複数の世代の HoloLens で優れたエクスペリエンスを作成する詳しい方法については、*操作モデルの遷移*について取り上げた次のセクションを参照してください。
 
8.  Q:通常は移動可能 (広い領域をカバーする、またはスペース間を移動する) なユーザーと、1 つのスペースで作業することが多いユーザーを比較するとどうなりますか?<br><br>
A:どの操作モデルでも、これらのユーザーに対応できます。  

> [!NOTE]
> アプリの設計に特化したガイダンスは、[近日中に公開](index.md#news-and-notes)します。


## <a name="transitioning-interaction-models"></a>操作モデルの遷移
複数の操作モデルが必要になるユース ケースもあります。 たとえば、アプリケーションの作成フローで手とモーション コントローラー操作モデルを利用しつつ、現場技術者向けにハンズフリー モードを使用する場合などです。  

エクスペリエンスに複数の操作モデルが必要な場合、一方のモデルから他方のモデルに遷移するときに、多くのエンド ユーザーが困難を感じるので注意してください。特に、Mixed Reality を初めて使用するユーザーはそれが顕著です。

> [!Note]
> 開発者やデザイナーが使用できるガイダンスの作成に常に取り組んでおり、複数の MR 操作モデルを使用するための方法、タイミング、および理由についてお知らせしています。
 

## <a name="see-also"></a>関連項目
* [頭の視線入力とコミット](gaze-and-commit.md)
* [ヘッド視線入力とドウェル](gaze-and-dwell.md)
* [手で直接操作](direct-manipulation.md)
* [手を使ったポイントとコミット](point-and-commit.md)
* [ジェスチャ](gestures.md)
* [音声コマンド](voice-design.md)
* [モーション コントローラー](motion-controllers.md)
* [立体音響の設計](spatial-sound-design.md)
* [空間マッピングの設計](spatial-mapping-design.md)
* [快適性](comfort.md)

